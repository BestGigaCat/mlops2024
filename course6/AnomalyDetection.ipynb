{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ad3e04a-3b9d-4f2b-81f5-d73ae3d38adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "\n",
    "# Please fill in the following for enabling data capture\n",
    "s3_capture_upload_path = f\"s3://sagemaker-us-west-2-846634201516/monitoring/\"  # example: s3://bucket-name/path/to/endpoint-data-capture/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "654fd764-21c6-4fe1-bc7a-14eca568efac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "# SageMaker session\n",
    "sess = sagemaker.Session()\n",
    "# get session bucket name\n",
    "bucket = sess.default_bucket()\n",
    "# bucket prefix or the subfolder for everything we produce\n",
    "prefix = \"mlops\"\n",
    "# get sagemaker role\n",
    "sagemaker_role = sagemaker.get_execution_role()\n",
    "# s3 client\n",
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "\n",
    "sagemaker_client = boto_session.client(service_name=\"sagemaker\", region_name=region)\n",
    "sagemaker_session = sagemaker.session.Session(\n",
    "    boto_session=boto_session, sagemaker_client=sagemaker_client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88f55ea8-af32-462f-a3c2-c92cccf20be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "------!!CPU times: user 302 ms, sys: 16.6 ms, total: 318 ms\n",
      "Wall time: 4min 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'EndpointName': 'CustomerChurn',\n",
       " 'EndpointArn': 'arn:aws:sagemaker:us-west-2:846634201516:endpoint/CustomerChurn',\n",
       " 'EndpointConfigName': 'CustomerChurn-2024-03-30-22-58-31-454',\n",
       " 'ProductionVariants': [{'VariantName': 'AllTraffic',\n",
       "   'DeployedImages': [{'SpecifiedImage': '433757028032.dkr.ecr.us-west-2.amazonaws.com/xgboost:latest',\n",
       "     'ResolvedImage': '433757028032.dkr.ecr.us-west-2.amazonaws.com/xgboost@sha256:0c8f830ac408e6dee08445fb60392e9c3f05f790a4b3c07ec22327c08f75bcbf',\n",
       "     'ResolutionTime': datetime.datetime(2024, 3, 30, 22, 58, 32, 917000, tzinfo=tzlocal())}],\n",
       "   'CurrentWeight': 1.0,\n",
       "   'DesiredWeight': 1.0,\n",
       "   'CurrentInstanceCount': 1,\n",
       "   'DesiredInstanceCount': 1}],\n",
       " 'DataCaptureConfig': {'EnableCapture': True,\n",
       "  'CaptureStatus': 'Started',\n",
       "  'CurrentSamplingPercentage': 100,\n",
       "  'DestinationS3Uri': 's3://sagemaker-us-west-2-846634201516/monitoring/'},\n",
       " 'EndpointStatus': 'InService',\n",
       " 'CreationTime': datetime.datetime(2024, 3, 30, 22, 54, 21, 707000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2024, 3, 30, 23, 1, 58, 219000, tzinfo=tzlocal()),\n",
       " 'ResponseMetadata': {'RequestId': '79499ef8-6993-4cf5-b42a-1b54c2c705ce',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '79499ef8-6993-4cf5-b42a-1b54c2c705ce',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '861',\n",
       "   'date': 'Sat, 30 Mar 2024 23:02:32 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "endpoint_name = \"CustomerChurn\"\n",
    "predictor = sagemaker.predictor.Predictor(\n",
    "    endpoint_name=endpoint_name, sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "# Change parameters as you would like - adjust sampling percentage,\n",
    "#  chose to capture request or response or both\n",
    "data_capture_config = DataCaptureConfig(\n",
    "    enable_capture=True,\n",
    "    sampling_percentage=100,\n",
    "    destination_s3_uri=s3_capture_upload_path,\n",
    "    kms_key_id=None,\n",
    "    capture_options=[\"REQUEST\", \"RESPONSE\"],\n",
    "    csv_content_types=[\"text/csv\"],\n",
    "    json_content_types=[\"application/json\"],\n",
    ")\n",
    "\n",
    "# Now it is time to apply the new configuration and wait for it to be applied\n",
    "predictor.update_data_capture_config(data_capture_config=data_capture_config)\n",
    "sess.wait_for_endpoint(endpoint=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28c054fa-1e28-4ec9-9b09-3a1c47e70c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline data uri: s3://sagemaker-us-west-2-846634201516/ml_deploy/validation\n",
      "Baseline results uri: s3://sagemaker-us-west-2-846634201516/monitoring/baseline/results\n"
     ]
    }
   ],
   "source": [
    "##'s3://bucketname/path/to/baseline/data' - Where your validation data is\n",
    "baseline_data_uri = f\"s3://sagemaker-us-west-2-846634201516/ml_deploy/validation\"\n",
    "##'s3://bucketname/path/to/baseline/data' - Where the results are to be stored in\n",
    "baseline_results_uri = f\"s3://sagemaker-us-west-2-846634201516/monitoring/baseline/results\"\n",
    "\n",
    "print(\"Baseline data uri: {}\".format(baseline_data_uri))\n",
    "print(\"Baseline results uri: {}\".format(baseline_results_uri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5936d665-9a78-4cbf-b48d-2390d2c016bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "from sagemaker import get_execution_role\n",
    "import datetime\n",
    "\n",
    "role = get_execution_role(sagemaker_session=sess)\n",
    "prefix = \"customerchurn\"\n",
    "\n",
    "datetime_stamp = datetime.datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")\n",
    "\n",
    "my_default_monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=1800,\n",
    "    base_job_name=f\"{prefix}-monitor-{datetime_stamp}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "917f04dc-3ed9-4b64-b5d5-c404e74e11da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name customerchurn-monitor-baseline-2024-03-30-231131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................\u001b[34m2024-03-30 23:16:25.847607: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:25.847644: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:28.201222: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:28.201251: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:28.201276: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-0-107-151.us-west-2.compute.internal): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:28.201682: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:30,119 - __main__ - INFO - All params:{'ProcessingJobArn': 'arn:aws:sagemaker:us-west-2:846634201516:processing-job/customerchurn-monitor-baseline-2024-03-30-231131', 'ProcessingJobName': 'customerchurn-monitor-baseline-2024-03-30-231131', 'Environment': {'dataset_format': '{\"csv\": {\"header\": false, \"output_columns_position\": \"START\"}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}, 'AppSpecification': {'ImageUri': '159807026194.dkr.ecr.us-west-2.amazonaws.com/sagemaker-model-monitor-analyzer', 'ContainerEntrypoint': None, 'ContainerArguments': None}, 'ProcessingInputs': [{'InputName': 'baseline_dataset_input', 'AppManaged': False, 'S3Input': {'LocalPath': '/opt/ml/processing/input/baseline_dataset_input', 'S3Uri': 's3://sagemaker-us-west-2-846634201516/ml_deploy/validation', 'S3DataDistributionType': 'FullyReplicated', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3CompressionType': 'None', 'S3DownloadMode': 'StartOfJob'}, 'DatasetDefinition': None}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'monitoring_output', 'AppManaged': False, 'S3Output': {'LocalPath': '/opt/ml/processing/output', 'S3Uri': 's3://sagemaker-us-west-2-846634201516/monitoring/baseline/results', 'S3UploadMode': 'EndOfJob'}, 'FeatureStoreOutput': None}], 'KmsKeyId': None}, 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1, 'InstanceType': 'ml.m5.large', 'VolumeSizeInGB': 20, 'VolumeKmsKeyId': None}}, 'RoleArn': 'arn:aws:iam::846634201516:role/service-role/AmazonSageMaker-ExecutionRole-20240122T185424', 'StoppingCondition': {'MaxRuntimeInSeconds': 1800}}\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:30,119 - __main__ - INFO - Current Environment:{'dataset_format': '{\"csv\": {\"header\": false, \"output_columns_position\": \"START\"}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:30,119 - __main__ - INFO - categorical_drift_method:None\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:30,119 - DefaultDataAnalyzer - INFO - Performing analysis with input: {\"dataset_source\": \"/opt/ml/processing/input/baseline_dataset_input\", \"dataset_format\": {\"csv\": {\"header\": false, \"output_columns_position\": \"START\"}}, \"output_path\": \"/opt/ml/processing/output\", \"monitoring_input_type\": null, \"analysis_type\": null, \"problem_type\": null, \"inference_attribute\": null, \"probability_attribute\": null, \"ground_truth_attribute\": null, \"probability_threshold_attribute\": null, \"positive_label\": null, \"exclude_features_attribute\": null, \"record_preprocessor_script\": null, \"post_analytics_processor_script\": null, \"baseline_constraints\": null, \"baseline_statistics\": null, \"data_quality_monitoring_config\": {\"evaluate_constraints\": \"Enabled\", \"emit_metrics\": \"Enabled\", \"datatype_check_threshold\": 1.0, \"domain_content_threshold\": 1.0, \"distribution_constraints\": {\"perform_comparison\": \"Enabled\", \"comparison_threshold\": 0.1, \"comparison_method\": \"Robust\", \"categorical_comparison_threshold\": 0.1, \"categorical_drift_method\": \"LInfinity\"}}, \"start_time\": null, \"end_time\": null, \"metric_time\": null, \"cloudwatch_metrics_directory\": \"/opt/ml/output/metrics/cloudwatch\", \"publish_cloudwatch_metrics\": \"Disabled\", \"sagemaker_endpoint_name\": null, \"sagemaker_monitoring_schedule_name\": null, \"output_message_file\": \"/opt/ml/output/message\", \"detect_outliers\": null, \"detect_drift\": null, \"image_data\": null, \"report_enabled\": false, \"auto_ml_job_detail\": null}\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:30,119 - DefaultDataAnalyzer - INFO - Bootstrapping yarn\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:30,119 - bootstrap - INFO - Copy aws jars\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:30,558 - bootstrap - INFO - Copy cluster config\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:30,559 - bootstrap - INFO - Write runtime cluster config\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:30,559 - bootstrap - INFO - Resource Config is: {'current_host': 'algo-1', 'hosts': ['algo-1']}\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:30,571 - bootstrap - INFO - Finished Yarn configuration files setup.\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:30,571 - bootstrap - INFO - Starting spark process for master node algo-1\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:30,571 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs namenode -format -force\u001b[0m\n",
      "\u001b[34mWARNING: /usr/hadoop-3.0.0/logs does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:32,195 INFO namenode.NameNode: STARTUP_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG: Starting NameNode\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   host = algo-1/10.0.107.151\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   args = [-format, -force]\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   version = 3.0.0\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   classpath = /usr/hadoop-3.0.0/etc/hadoop:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/junit-4.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/aws-java-sdk-bundle-1.11.199.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-aws-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-kms-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okio-1.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-math-2.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/htrace-core-3.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-server-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jamon-runtime-2.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-protocol-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop2-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-annotations-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/fst-2.50.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-common-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-procedure-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/joni-2.1.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jcodings-1.0.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-csv-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/disruptor-3.3.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-prefix-tree-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-runtime-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-client-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-api-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-el-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-2.2.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-client-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-compiler-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/servlet-api-2.5-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/findbugs-annotations-1.3.9-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-api-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/had\u001b[0m\n",
      "\u001b[34moop/yarn/hadoop-yarn-server-resourcemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-registry-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-router-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.0.0.jar\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r c25427ceca461ee979d30edd7a4b0f50718e6533; compiled by 'andrew' on 2017-12-08T19:16Z\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   java = 1.8.0_392\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:32,221 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:32,227 INFO namenode.NameNode: createNameNode [-format, -force]\u001b[0m\n",
      "\u001b[34mFormatting using clusterid: CID-1b9c8023-2bb8-4b16-aed7-712d2423f925\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,187 INFO namenode.FSEditLog: Edit logging is async:true\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,210 INFO namenode.FSNamesystem: KeyProvider: null\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,211 INFO namenode.FSNamesystem: fsLock is fair: true\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,215 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,231 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,231 INFO namenode.FSNamesystem: supergroup          = supergroup\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,231 INFO namenode.FSNamesystem: isPermissionEnabled = true\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,232 INFO namenode.FSNamesystem: HA Enabled: false\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,290 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,310 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,310 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,315 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,318 INFO blockmanagement.BlockManager: The block deletion will start around 2024 Mar 30 23:16:33\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,320 INFO util.GSet: Computing capacity for map BlocksMap\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,320 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,323 INFO util.GSet: 2.0% max memory 1.3 GB = 27.6 MB\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,323 INFO util.GSet: capacity      = 2^22 = 4194304 entries\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,382 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,386 INFO Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,386 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,386 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,387 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,387 INFO blockmanagement.BlockManager: defaultReplication         = 3\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,387 INFO blockmanagement.BlockManager: maxReplication             = 512\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,387 INFO blockmanagement.BlockManager: minReplication             = 1\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,387 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,387 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,387 INFO blockmanagement.BlockManager: encryptDataTransfer        = false\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,388 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,426 INFO util.GSet: Computing capacity for map INodeMap\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,426 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,427 INFO util.GSet: 1.0% max memory 1.3 GB = 13.8 MB\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,427 INFO util.GSet: capacity      = 2^21 = 2097152 entries\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,428 INFO namenode.FSDirectory: ACLs enabled? false\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,428 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,428 INFO namenode.FSDirectory: XAttrs enabled? true\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,428 INFO namenode.NameNode: Caching file names occurring more than 10 times\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,434 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,440 INFO util.GSet: Computing capacity for map cachedBlocks\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,440 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,440 INFO util.GSet: 0.25% max memory 1.3 GB = 3.5 MB\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,440 INFO util.GSet: capacity      = 2^19 = 524288 entries\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,449 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,449 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,449 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,453 INFO namenode.FSNamesystem: Retry cache on namenode is enabled\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,453 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,456 INFO util.GSet: Computing capacity for map NameNodeRetryCache\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,456 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,457 INFO util.GSet: 0.029999999329447746% max memory 1.3 GB = 424.4 KB\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,457 INFO util.GSet: capacity      = 2^16 = 65536 entries\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,488 INFO namenode.FSImage: Allocated new BlockPoolId: BP-549131963-10.0.107.151-1711840593479\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,502 INFO common.Storage: Storage directory /opt/amazon/hadoop/hdfs/namenode has been successfully formatted.\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,514 INFO namenode.FSImageFormatProtobuf: Saving image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 using no compression\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,623 INFO namenode.FSImageFormatProtobuf: Image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 of size 389 bytes saved in 0 seconds.\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,641 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,650 INFO namenode.NameNode: SHUTDOWN_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSHUTDOWN_MSG: Shutting down NameNode at algo-1/10.0.107.151\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:33,659 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:35,722 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode, return code 1\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:35,722 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:37,837 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode, return code 1\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:37,838 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34mWARNING: /var/log/yarn/ does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:40,321 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager, return code 1\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:40,326 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:42,725 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager, return code 1\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:42,726 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:45,182 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver, return code 1\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:45,183 - DefaultDataAnalyzer - INFO - Total number of hosts in the cluster: 1\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:55,187 - DefaultDataAnalyzer - INFO - Running command: bin/spark-submit --master yarn --deploy-mode client --conf spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider --conf spark.serializer=org.apache.spark.serializer.KryoSerializer /opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar --analytics_input /tmp/spark_job_config.json\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:57,635 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:58,202 INFO Main: Start analyzing with args: --analytics_input /tmp/spark_job_config.json\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:58,263 INFO Main: Analytics input path: DataAnalyzerParams(/tmp/spark_job_config.json,yarn)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:58,283 INFO FileUtil: Read file from path /tmp/spark_job_config.json.\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:59,032 INFO spark.SparkContext: Running Spark version 3.3.0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:59,063 INFO resource.ResourceUtils: ==============================================================\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:59,063 INFO resource.ResourceUtils: No custom resources configured for spark.driver.\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:59,063 INFO resource.ResourceUtils: ==============================================================\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:59,064 INFO spark.SparkContext: Submitted application: SageMakerDataAnalyzer\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:59,114 INFO resource.ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 5684, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:59,130 INFO resource.ResourceProfile: Limiting resource is cpus at 1 tasks per executor\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:59,132 INFO resource.ResourceProfileManager: Added ResourceProfile id: 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:59,218 INFO spark.SecurityManager: Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:59,218 INFO spark.SecurityManager: Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:59,219 INFO spark.SecurityManager: Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:59,219 INFO spark.SecurityManager: Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:59,220 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:59,784 INFO util.Utils: Successfully started service 'sparkDriver' on port 43049.\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:59,851 INFO spark.SparkEnv: Registering MapOutputTracker\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:59,922 INFO spark.SparkEnv: Registering BlockManagerMaster\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:59,957 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\u001b[0m\n",
      "\u001b[34m2024-03-30 23:16:59,958 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:00,017 INFO spark.SparkEnv: Registering BlockManagerMasterHeartbeat\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:00,074 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-c5517ea2-f3e0-40f0-8a36-6d886d227e89\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:00,111 INFO memory.MemoryStore: MemoryStore started with capacity 1458.6 MiB\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:00,181 INFO spark.SparkEnv: Registering OutputCommitCoordinator\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:00,234 INFO spark.SparkContext: Added JAR file:/opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar at spark://10.0.107.151:43049/jars/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar with timestamp 1711840619025\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:01,061 INFO client.RMProxy: Connecting to ResourceManager at /10.0.107.151:8032\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:01,923 INFO conf.Configuration: resource-types.xml not found\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:01,924 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:01,931 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (7751 MB per container)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:01,932 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:01,932 INFO yarn.Client: Setting up container launch context for our AM\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:01,933 INFO yarn.Client: Setting up the launch environment for our AM container\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:01,940 INFO yarn.Client: Preparing resources for our AM container\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:02,047 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:04,348 INFO yarn.Client: Uploading resource file:/tmp/spark-5d276ba1-b346-400a-bdc9-b39c7125e9e9/__spark_libs__3909801721027127516.zip -> hdfs://10.0.107.151/user/root/.sparkStaging/application_1711840601944_0001/__spark_libs__3909801721027127516.zip\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:06,727 INFO yarn.Client: Uploading resource file:/tmp/spark-5d276ba1-b346-400a-bdc9-b39c7125e9e9/__spark_conf__6664790553995255618.zip -> hdfs://10.0.107.151/user/root/.sparkStaging/application_1711840601944_0001/__spark_conf__.zip\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:06,793 INFO spark.SecurityManager: Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:06,794 INFO spark.SecurityManager: Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:06,794 INFO spark.SecurityManager: Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:06,794 INFO spark.SecurityManager: Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:06,795 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:06,834 INFO yarn.Client: Submitting application application_1711840601944_0001 to ResourceManager\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:07,241 INFO impl.YarnClientImpl: Submitted application application_1711840601944_0001\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:08,246 INFO yarn.Client: Application report for application_1711840601944_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:08,252 INFO yarn.Client: \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: [Sat Mar 30 23:17:08 +0000 2024] Scheduler has assigned a container for AM, waiting for AM container to be launched\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: -1\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1711840626944\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1711840601944_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:09,255 INFO yarn.Client: Application report for application_1711840601944_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:10,259 INFO yarn.Client: Application report for application_1711840601944_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:11,288 INFO yarn.Client: Application report for application_1711840601944_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:12,293 INFO yarn.Client: Application report for application_1711840601944_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:13,297 INFO yarn.Client: Application report for application_1711840601944_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:14,301 INFO yarn.Client: Application report for application_1711840601944_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:15,100 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> algo-1, PROXY_URI_BASES -> http://algo-1:8088/proxy/application_1711840601944_0001), /proxy/application_1711840601944_0001\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:15,304 INFO yarn.Client: Application report for application_1711840601944_0001 (state: RUNNING)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:15,305 INFO yarn.Client: \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: 10.0.107.151\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: -1\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1711840626944\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1711840601944_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:15,307 INFO cluster.YarnClientSchedulerBackend: Application application_1711840601944_0001 has started running.\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:15,349 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40635.\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:15,349 INFO netty.NettyBlockTransferService: Server created on 10.0.107.151:40635\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:15,351 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:15,366 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.0.107.151, 40635, None)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:15,371 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.0.107.151:40635 with 1458.6 MiB RAM, BlockManagerId(driver, 10.0.107.151, 40635, None)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:15,374 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.0.107.151, 40635, None)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:15,378 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.0.107.151, 40635, None)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:15,617 INFO util.log: Logging initialized @20195ms to org.sparkproject.jetty.util.log.Slf4jLog\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:17,359 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:21,997 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.107.151:56546) with ID 1,  ResourceProfileId 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:22,256 INFO storage.BlockManagerMasterEndpoint: Registering block manager algo-1:40133 with 2.8 GiB RAM, BlockManagerId(1, algo-1, 40133, None)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:30,905 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000000000(ns)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:31,017 WARN spark.SparkContext: Spark is not running in local mode, therefore the checkpoint directory must not be on the local filesystem. Directory '/tmp' appears to be on the local filesystem.\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:31,058 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:31,062 INFO internal.SharedState: Warehouse path is 'file:/usr/spark-3.3.0/spark-warehouse'.\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:31,979 INFO datasources.InMemoryFileIndex: It took 39 ms to list leaf files for 1 paths.\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:32,193 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 417.0 KiB, free 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:32,509 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 39.2 KiB, free 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:32,512 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.107.151:40635 (size: 39.2 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:32,520 INFO spark.SparkContext: Created broadcast 0 from csv at DatasetReader.scala:99\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:32,974 INFO input.FileInputFormat: Total input files to process : 1\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:32,981 INFO input.FileInputFormat: Total input files to process : 1\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:32,985 INFO input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 479130\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:33,077 INFO spark.SparkContext: Starting job: csv at DatasetReader.scala:99\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:33,100 INFO scheduler.DAGScheduler: Got job 0 (csv at DatasetReader.scala:99) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:33,101 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (csv at DatasetReader.scala:99)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:33,102 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:33,105 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:33,121 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at csv at DatasetReader.scala:99), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:33,194 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.3 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:33,198 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:33,199 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.107.151:40635 (size: 4.2 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:33,207 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:33,231 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at csv at DatasetReader.scala:99) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:33,232 INFO cluster.YarnScheduler: Adding task set 0.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:33,337 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4668 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:33,652 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on algo-1:40133 (size: 4.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:34,732 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on algo-1:40133 (size: 39.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:35,189 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1914 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:35,191 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:35,201 INFO scheduler.DAGScheduler: ResultStage 0 (csv at DatasetReader.scala:99) finished in 2.038 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:35,206 INFO scheduler.DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:35,208 INFO cluster.YarnScheduler: Killing all running tasks in stage 0: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:35,211 INFO scheduler.DAGScheduler: Job 0 finished: csv at DatasetReader.scala:99, took 2.133298 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:35,457 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on algo-1:40133 in memory (size: 4.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:35,475 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on 10.0.107.151:40635 in memory (size: 4.2 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:35,496 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on 10.0.107.151:40635 in memory (size: 39.2 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:35,502 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on algo-1:40133 in memory (size: 39.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:38,060 INFO datasources.FileSourceStrategy: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:38,062 INFO datasources.FileSourceStrategy: Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:38,066 INFO datasources.FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 98 more fields>\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:38,113 WARN util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:38,398 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 416.5 KiB, free 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:38,424 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 39.1 KiB, free 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:38,425 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.0.107.151:40635 (size: 39.1 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:38,428 INFO spark.SparkContext: Created broadcast 2 from head at DataAnalyzer.scala:124\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:38,449 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:38,522 INFO spark.SparkContext: Starting job: head at DataAnalyzer.scala:124\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:38,524 INFO scheduler.DAGScheduler: Got job 1 (head at DataAnalyzer.scala:124) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:38,524 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (head at DataAnalyzer.scala:124)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:38,524 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:38,526 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:38,529 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[11] at head at DataAnalyzer.scala:124), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:38,623 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 35.7 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:38,631 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:38,631 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.0.107.151:40635 (size: 13.4 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:38,637 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:38,638 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[11] at head at DataAnalyzer.scala:124) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:38,638 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:38,642 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:38,739 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on algo-1:40133 (size: 13.4 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:40,342 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on algo-1:40133 (size: 39.1 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:40,713 INFO storage.BlockManagerInfo: Added rdd_7_0 in memory on algo-1:40133 (size: 175.4 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:41,042 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 2403 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:41,042 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:41,043 INFO scheduler.DAGScheduler: ResultStage 1 (head at DataAnalyzer.scala:124) finished in 2.509 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:41,044 INFO scheduler.DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:41,047 INFO cluster.YarnScheduler: Killing all running tasks in stage 1: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:41,047 INFO scheduler.DAGScheduler: Job 1 finished: head at DataAnalyzer.scala:124, took 2.525276 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:41,755 INFO codegen.CodeGenerator: Code generated in 452.127885 ms\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:42,528 INFO scheduler.DAGScheduler: Registering RDD 16 (collect at AnalysisRunner.scala:326) as input to shuffle 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:42,533 INFO scheduler.DAGScheduler: Got map stage job 2 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:42,534 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 2 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:42,534 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:42,537 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:42,541 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[16] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:42,578 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 131.0 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:42,582 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 39.9 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:42,582 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.0.107.151:40635 (size: 39.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:42,584 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:42,588 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[16] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:42,588 INFO cluster.YarnScheduler: Adding task set 2.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:42,598 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:42,633 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on algo-1:40133 (size: 39.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:44,196 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1601 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:44,196 INFO cluster.YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:44,198 INFO scheduler.DAGScheduler: ShuffleMapStage 2 (collect at AnalysisRunner.scala:326) finished in 1.652 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:44,198 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:44,199 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:44,199 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:44,201 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:44,379 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:44,384 INFO scheduler.DAGScheduler: Got job 3 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:44,384 INFO scheduler.DAGScheduler: Final stage: ResultStage 4 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:44,384 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:44,384 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:44,385 INFO scheduler.DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[19] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:44,403 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 183.5 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:44,406 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 50.2 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:44,407 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.0.107.151:40635 (size: 50.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:44,408 INFO spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:44,409 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[19] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:44,410 INFO cluster.YarnScheduler: Adding task set 4.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:44,413 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:44,443 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on algo-1:40133 (size: 50.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:44,515 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:44,871 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 459 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:44,871 INFO cluster.YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:44,872 INFO scheduler.DAGScheduler: ResultStage 4 (collect at AnalysisRunner.scala:326) finished in 0.479 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:44,878 INFO scheduler.DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:44,879 INFO cluster.YarnScheduler: Killing all running tasks in stage 4: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:44,880 INFO scheduler.DAGScheduler: Job 3 finished: collect at AnalysisRunner.scala:326, took 0.500497 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:44,928 INFO codegen.CodeGenerator: Code generated in 40.248356 ms\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:45,388 INFO codegen.CodeGenerator: Code generated in 55.129828 ms\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:45,487 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:45,489 INFO scheduler.DAGScheduler: Got job 4 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:45,489 INFO scheduler.DAGScheduler: Final stage: ResultStage 5 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:45,489 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:45,490 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:45,492 INFO scheduler.DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[29] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:45,507 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 54.9 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:45,510 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 20.8 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:45,511 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.0.107.151:40635 (size: 20.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:45,517 INFO spark.SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:45,518 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[29] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:45,518 INFO cluster.YarnScheduler: Adding task set 5.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:45,522 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:45,537 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on algo-1:40133 (size: 20.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,025 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 504 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,028 INFO scheduler.DAGScheduler: ResultStage 5 (treeReduce at KLLRunner.scala:107) finished in 0.535 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,029 INFO scheduler.DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,030 INFO cluster.YarnScheduler: Removed TaskSet 5.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,030 INFO cluster.YarnScheduler: Killing all running tasks in stage 5: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,030 INFO scheduler.DAGScheduler: Job 4 finished: treeReduce at KLLRunner.scala:107, took 0.543151 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,137 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on algo-1:40133 in memory (size: 20.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,138 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on 10.0.107.151:40635 in memory (size: 20.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,190 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on 10.0.107.151:40635 in memory (size: 13.4 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,193 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on algo-1:40133 in memory (size: 13.4 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,253 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on algo-1:40133 in memory (size: 50.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,268 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on 10.0.107.151:40635 in memory (size: 50.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,330 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on algo-1:40133 in memory (size: 39.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,332 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on 10.0.107.151:40635 in memory (size: 39.9 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,772 INFO codegen.CodeGenerator: Code generated in 180.494059 ms\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,789 INFO scheduler.DAGScheduler: Registering RDD 34 (collect at AnalysisRunner.scala:326) as input to shuffle 1\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,790 INFO scheduler.DAGScheduler: Got map stage job 5 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,790 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 6 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,791 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,791 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,792 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[34] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,803 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 90.7 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,806 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,807 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.0.107.151:40635 (size: 27.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,808 INFO spark.SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,809 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[34] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,809 INFO cluster.YarnScheduler: Adding task set 6.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,811 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 5) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,828 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on algo-1:40133 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,979 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 6.0 (TID 5) in 169 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,979 INFO cluster.YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,980 INFO scheduler.DAGScheduler: ShuffleMapStage 6 (collect at AnalysisRunner.scala:326) finished in 0.185 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,981 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,981 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,981 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:46,981 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,298 INFO codegen.CodeGenerator: Code generated in 159.974794 ms\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,314 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,315 INFO scheduler.DAGScheduler: Got job 6 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,316 INFO scheduler.DAGScheduler: Final stage: ResultStage 8 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,316 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,316 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,317 INFO scheduler.DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[37] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,329 INFO memory.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 66.2 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,332 INFO memory.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,333 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.0.107.151:40635 (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,334 INFO spark.SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,334 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[37] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,334 INFO cluster.YarnScheduler: Adding task set 8.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,335 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 8.0 (TID 6) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,349 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on algo-1:40133 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,356 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,434 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 8.0 (TID 6) in 99 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,435 INFO cluster.YarnScheduler: Removed TaskSet 8.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,436 INFO scheduler.DAGScheduler: ResultStage 8 (collect at AnalysisRunner.scala:326) finished in 0.112 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,439 INFO scheduler.DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,439 INFO cluster.YarnScheduler: Killing all running tasks in stage 8: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,440 INFO scheduler.DAGScheduler: Job 6 finished: collect at AnalysisRunner.scala:326, took 0.126342 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,549 INFO codegen.CodeGenerator: Code generated in 66.544777 ms\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,810 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,820 INFO scheduler.DAGScheduler: Registering RDD 45 (countByKey at ColumnProfiler.scala:592) as input to shuffle 2\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,821 INFO scheduler.DAGScheduler: Got job 7 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,821 INFO scheduler.DAGScheduler: Final stage: ResultStage 10 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,821 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,822 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 9)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,825 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[45] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,840 INFO memory.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 47.1 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,843 INFO memory.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,844 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.0.107.151:40635 (size: 18.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,847 INFO spark.SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,848 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[45] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,848 INFO cluster.YarnScheduler: Adding task set 9.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,853 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 9.0 (TID 7) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:47,866 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on algo-1:40133 (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,481 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 9.0 (TID 7) in 1628 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,482 INFO cluster.YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,483 INFO scheduler.DAGScheduler: ShuffleMapStage 9 (countByKey at ColumnProfiler.scala:592) finished in 1.655 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,484 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,485 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,485 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 10)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,486 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,486 INFO scheduler.DAGScheduler: Submitting ResultStage 10 (ShuffledRDD[46] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,489 INFO memory.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 5.1 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,491 INFO memory.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,491 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.0.107.151:40635 (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,493 INFO spark.SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,493 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (ShuffledRDD[46] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,495 INFO cluster.YarnScheduler: Adding task set 10.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,497 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 10.0 (TID 8) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,509 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on algo-1:40133 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,516 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,567 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 10.0 (TID 8) in 71 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,568 INFO cluster.YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,569 INFO scheduler.DAGScheduler: ResultStage 10 (countByKey at ColumnProfiler.scala:592) finished in 0.082 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,570 INFO scheduler.DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,571 INFO cluster.YarnScheduler: Killing all running tasks in stage 10: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,571 INFO scheduler.DAGScheduler: Job 7 finished: countByKey at ColumnProfiler.scala:592, took 1.756144 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,824 INFO scheduler.DAGScheduler: Registering RDD 51 (collect at AnalysisRunner.scala:326) as input to shuffle 3\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,825 INFO scheduler.DAGScheduler: Got map stage job 8 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,825 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 11 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,825 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,826 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,827 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[51] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,839 INFO memory.MemoryStore: Block broadcast_11 stored as values in memory (estimated size 100.0 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,842 INFO memory.MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,843 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.0.107.151:40635 (size: 32.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,844 INFO spark.SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,845 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[51] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,845 INFO cluster.YarnScheduler: Adding task set 11.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,847 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 11.0 (TID 9) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:49,861 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on algo-1:40133 (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,094 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 11.0 (TID 9) in 247 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,094 INFO cluster.YarnScheduler: Removed TaskSet 11.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,096 INFO scheduler.DAGScheduler: ShuffleMapStage 11 (collect at AnalysisRunner.scala:326) finished in 0.266 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,097 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,100 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,100 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,100 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,165 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,166 INFO scheduler.DAGScheduler: Got job 9 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,167 INFO scheduler.DAGScheduler: Final stage: ResultStage 13 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,167 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,167 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,173 INFO scheduler.DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[54] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,188 INFO memory.MemoryStore: Block broadcast_12 stored as values in memory (estimated size 184.6 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,192 INFO memory.MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 50.2 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,193 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.0.107.151:40635 (size: 50.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,197 INFO spark.SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,198 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[54] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,198 INFO cluster.YarnScheduler: Adding task set 13.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,199 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 13.0 (TID 10) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,210 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on algo-1:40133 (size: 50.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,226 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,484 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 13.0 (TID 10) in 285 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,484 INFO cluster.YarnScheduler: Removed TaskSet 13.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,485 INFO scheduler.DAGScheduler: ResultStage 13 (collect at AnalysisRunner.scala:326) finished in 0.310 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,488 INFO scheduler.DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,489 INFO cluster.YarnScheduler: Killing all running tasks in stage 13: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,490 INFO scheduler.DAGScheduler: Job 9 finished: collect at AnalysisRunner.scala:326, took 0.324286 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,763 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,764 INFO scheduler.DAGScheduler: Got job 10 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,765 INFO scheduler.DAGScheduler: Final stage: ResultStage 14 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,765 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,766 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,771 INFO scheduler.DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[64] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,771 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on algo-1:40133 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,777 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on 10.0.107.151:40635 in memory (size: 27.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,794 INFO memory.MemoryStore: Block broadcast_13 stored as values in memory (estimated size 54.8 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,798 INFO memory.MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,802 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.0.107.151:40635 (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,802 INFO spark.SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,803 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[64] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,803 INFO cluster.YarnScheduler: Adding task set 14.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,806 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 14.0 (TID 11) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,822 INFO storage.BlockManagerInfo: Removed broadcast_12_piece0 on 10.0.107.151:40635 in memory (size: 50.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,825 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on algo-1:40133 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,828 INFO storage.BlockManagerInfo: Removed broadcast_12_piece0 on algo-1:40133 in memory (size: 50.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,884 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on 10.0.107.151:40635 in memory (size: 18.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,905 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on algo-1:40133 in memory (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,934 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 14.0 (TID 11) in 128 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,941 INFO scheduler.DAGScheduler: ResultStage 14 (treeReduce at KLLRunner.scala:107) finished in 0.167 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,942 INFO scheduler.DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,943 INFO cluster.YarnScheduler: Removed TaskSet 14.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,943 INFO cluster.YarnScheduler: Killing all running tasks in stage 14: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,943 INFO scheduler.DAGScheduler: Job 10 finished: treeReduce at KLLRunner.scala:107, took 0.179892 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,979 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on algo-1:40133 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:50,982 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on 10.0.107.151:40635 in memory (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,029 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on algo-1:40133 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,038 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on 10.0.107.151:40635 in memory (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,112 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on algo-1:40133 in memory (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,121 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on 10.0.107.151:40635 in memory (size: 32.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,254 INFO scheduler.DAGScheduler: Registering RDD 69 (collect at AnalysisRunner.scala:326) as input to shuffle 4\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,255 INFO scheduler.DAGScheduler: Got map stage job 11 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,255 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 15 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,255 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,256 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,256 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[69] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,262 INFO memory.MemoryStore: Block broadcast_14 stored as values in memory (estimated size 90.7 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,263 INFO memory.MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,264 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.0.107.151:40635 (size: 27.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,265 INFO spark.SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,268 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[69] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,269 INFO cluster.YarnScheduler: Adding task set 15.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,270 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 15.0 (TID 12) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,285 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on algo-1:40133 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,322 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 15.0 (TID 12) in 51 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,323 INFO cluster.YarnScheduler: Removed TaskSet 15.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,324 INFO scheduler.DAGScheduler: ShuffleMapStage 15 (collect at AnalysisRunner.scala:326) finished in 0.065 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,325 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,325 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,326 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,326 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,423 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,425 INFO scheduler.DAGScheduler: Got job 12 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,425 INFO scheduler.DAGScheduler: Final stage: ResultStage 17 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,425 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,425 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,426 INFO scheduler.DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[72] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,430 INFO memory.MemoryStore: Block broadcast_15 stored as values in memory (estimated size 66.2 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,432 INFO memory.MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,433 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on 10.0.107.151:40635 (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,433 INFO spark.SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,434 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[72] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,434 INFO cluster.YarnScheduler: Adding task set 17.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,435 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 17.0 (TID 13) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,451 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on algo-1:40133 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,456 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,465 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 17.0 (TID 13) in 30 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,466 INFO cluster.YarnScheduler: Removed TaskSet 17.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,469 INFO scheduler.DAGScheduler: ResultStage 17 (collect at AnalysisRunner.scala:326) finished in 0.041 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,470 INFO scheduler.DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,470 INFO cluster.YarnScheduler: Killing all running tasks in stage 17: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,471 INFO scheduler.DAGScheduler: Job 12 finished: collect at AnalysisRunner.scala:326, took 0.047123 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,552 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,554 INFO scheduler.DAGScheduler: Registering RDD 80 (countByKey at ColumnProfiler.scala:592) as input to shuffle 5\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,554 INFO scheduler.DAGScheduler: Got job 13 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,554 INFO scheduler.DAGScheduler: Final stage: ResultStage 19 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,555 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,555 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 18)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,556 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[80] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,562 INFO memory.MemoryStore: Block broadcast_16 stored as values in memory (estimated size 47.1 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,564 INFO memory.MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,565 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.0.107.151:40635 (size: 18.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,566 INFO spark.SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,566 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[80] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,567 INFO cluster.YarnScheduler: Adding task set 18.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,569 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 18.0 (TID 14) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,579 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on algo-1:40133 (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,686 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 18.0 (TID 14) in 118 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,686 INFO cluster.YarnScheduler: Removed TaskSet 18.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,687 INFO scheduler.DAGScheduler: ShuffleMapStage 18 (countByKey at ColumnProfiler.scala:592) finished in 0.130 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,687 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,687 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,687 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 19)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,688 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,688 INFO scheduler.DAGScheduler: Submitting ResultStage 19 (ShuffledRDD[81] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,690 INFO memory.MemoryStore: Block broadcast_17 stored as values in memory (estimated size 5.1 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,691 INFO memory.MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,692 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.0.107.151:40635 (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,693 INFO spark.SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,694 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (ShuffledRDD[81] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,694 INFO cluster.YarnScheduler: Adding task set 19.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,696 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 19.0 (TID 15) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,707 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on algo-1:40133 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,711 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,734 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 19.0 (TID 15) in 39 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,734 INFO cluster.YarnScheduler: Removed TaskSet 19.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,735 INFO scheduler.DAGScheduler: ResultStage 19 (countByKey at ColumnProfiler.scala:592) finished in 0.046 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,736 INFO scheduler.DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,737 INFO cluster.YarnScheduler: Killing all running tasks in stage 19: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:51,739 INFO scheduler.DAGScheduler: Job 13 finished: countByKey at ColumnProfiler.scala:592, took 0.186140 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,012 INFO scheduler.DAGScheduler: Registering RDD 86 (collect at AnalysisRunner.scala:326) as input to shuffle 6\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,013 INFO scheduler.DAGScheduler: Got map stage job 14 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,013 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 20 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,014 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,016 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,016 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[86] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,029 INFO memory.MemoryStore: Block broadcast_18 stored as values in memory (estimated size 100.0 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,031 INFO memory.MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,034 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.0.107.151:40635 (size: 32.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,034 INFO spark.SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,035 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[86] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,035 INFO cluster.YarnScheduler: Adding task set 20.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,037 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 20.0 (TID 16) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,056 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on algo-1:40133 (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,235 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 20.0 (TID 16) in 199 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,236 INFO cluster.YarnScheduler: Removed TaskSet 20.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,237 INFO scheduler.DAGScheduler: ShuffleMapStage 20 (collect at AnalysisRunner.scala:326) finished in 0.211 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,238 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,239 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,239 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,239 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,335 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,336 INFO scheduler.DAGScheduler: Got job 15 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,336 INFO scheduler.DAGScheduler: Final stage: ResultStage 22 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,337 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,337 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,337 INFO scheduler.DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[89] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,346 INFO memory.MemoryStore: Block broadcast_19 stored as values in memory (estimated size 184.6 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,351 INFO memory.MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,352 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.0.107.151:40635 (size: 50.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,352 INFO spark.SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,353 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[89] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,353 INFO cluster.YarnScheduler: Adding task set 22.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,354 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 22.0 (TID 17) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,365 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on algo-1:40133 (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,377 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,503 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 22.0 (TID 17) in 149 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,504 INFO scheduler.DAGScheduler: ResultStage 22 (collect at AnalysisRunner.scala:326) finished in 0.164 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,505 INFO scheduler.DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,506 INFO cluster.YarnScheduler: Removed TaskSet 22.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,507 INFO cluster.YarnScheduler: Killing all running tasks in stage 22: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,508 INFO scheduler.DAGScheduler: Job 15 finished: collect at AnalysisRunner.scala:326, took 0.172627 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,688 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,689 INFO scheduler.DAGScheduler: Got job 16 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,690 INFO scheduler.DAGScheduler: Final stage: ResultStage 23 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,690 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,691 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,691 INFO scheduler.DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[99] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,699 INFO memory.MemoryStore: Block broadcast_20 stored as values in memory (estimated size 54.8 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,704 INFO memory.MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,707 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on 10.0.107.151:40635 (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,708 INFO spark.SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,708 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[99] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,709 INFO cluster.YarnScheduler: Adding task set 23.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,711 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 23.0 (TID 18) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,724 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on algo-1:40133 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,772 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 23.0 (TID 18) in 61 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,773 INFO scheduler.DAGScheduler: ResultStage 23 (treeReduce at KLLRunner.scala:107) finished in 0.081 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,774 INFO scheduler.DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,775 INFO cluster.YarnScheduler: Removed TaskSet 23.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,775 INFO cluster.YarnScheduler: Killing all running tasks in stage 23: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:52,775 INFO scheduler.DAGScheduler: Job 16 finished: treeReduce at KLLRunner.scala:107, took 0.086755 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,043 INFO storage.BlockManagerInfo: Removed broadcast_19_piece0 on algo-1:40133 in memory (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,059 INFO storage.BlockManagerInfo: Removed broadcast_19_piece0 on 10.0.107.151:40635 in memory (size: 50.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,067 INFO scheduler.DAGScheduler: Registering RDD 104 (collect at AnalysisRunner.scala:326) as input to shuffle 7\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,068 INFO scheduler.DAGScheduler: Got map stage job 17 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,068 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 24 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,068 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,069 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,069 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[104] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,079 INFO memory.MemoryStore: Block broadcast_21 stored as values in memory (estimated size 90.7 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,081 INFO memory.MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,081 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on 10.0.107.151:40635 (size: 27.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,082 INFO spark.SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,093 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[104] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,094 INFO cluster.YarnScheduler: Adding task set 24.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,096 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 24.0 (TID 19) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,101 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on 10.0.107.151:40635 in memory (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,115 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on algo-1:40133 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,147 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on algo-1:40133 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,149 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 24.0 (TID 19) in 54 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,149 INFO cluster.YarnScheduler: Removed TaskSet 24.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,150 INFO scheduler.DAGScheduler: ShuffleMapStage 24 (collect at AnalysisRunner.scala:326) finished in 0.079 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,151 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,151 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,152 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,152 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,213 INFO storage.BlockManagerInfo: Removed broadcast_18_piece0 on 10.0.107.151:40635 in memory (size: 32.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,222 INFO storage.BlockManagerInfo: Removed broadcast_18_piece0 on algo-1:40133 in memory (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,266 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,268 INFO scheduler.DAGScheduler: Got job 18 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,268 INFO scheduler.DAGScheduler: Final stage: ResultStage 26 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,268 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,268 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on algo-1:40133 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,269 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,270 INFO scheduler.DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[107] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,274 INFO memory.MemoryStore: Block broadcast_22 stored as values in memory (estimated size 66.2 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,274 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on 10.0.107.151:40635 in memory (size: 27.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,276 INFO memory.MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,276 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on 10.0.107.151:40635 (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,277 INFO spark.SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,278 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[107] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,278 INFO cluster.YarnScheduler: Adding task set 26.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,280 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 26.0 (TID 20) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,296 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on algo-1:40133 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,315 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,332 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 26.0 (TID 20) in 53 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,332 INFO cluster.YarnScheduler: Removed TaskSet 26.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,333 INFO scheduler.DAGScheduler: ResultStage 26 (collect at AnalysisRunner.scala:326) finished in 0.062 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,333 INFO scheduler.DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,333 INFO cluster.YarnScheduler: Killing all running tasks in stage 26: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,334 INFO scheduler.DAGScheduler: Job 18 finished: collect at AnalysisRunner.scala:326, took 0.067949 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,364 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on 10.0.107.151:40635 in memory (size: 18.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,374 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on algo-1:40133 in memory (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,405 INFO storage.BlockManagerInfo: Removed broadcast_17_piece0 on 10.0.107.151:40635 in memory (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,411 INFO storage.BlockManagerInfo: Removed broadcast_17_piece0 on algo-1:40133 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,436 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,438 INFO scheduler.DAGScheduler: Registering RDD 115 (countByKey at ColumnProfiler.scala:592) as input to shuffle 8\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,438 INFO scheduler.DAGScheduler: Got job 19 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,438 INFO scheduler.DAGScheduler: Final stage: ResultStage 28 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,438 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 27)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,439 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 27)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,439 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[115] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,450 INFO memory.MemoryStore: Block broadcast_23 stored as values in memory (estimated size 47.1 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,451 INFO memory.MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,452 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on 10.0.107.151:40635 (size: 18.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,453 INFO spark.SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,453 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[115] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,453 INFO cluster.YarnScheduler: Adding task set 27.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,455 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 27.0 (TID 21) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,455 INFO storage.BlockManagerInfo: Removed broadcast_20_piece0 on 10.0.107.151:40635 in memory (size: 20.7 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,467 INFO storage.BlockManagerInfo: Removed broadcast_20_piece0 on algo-1:40133 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,471 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on algo-1:40133 (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,521 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 27.0 (TID 21) in 67 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,521 INFO cluster.YarnScheduler: Removed TaskSet 27.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,522 INFO scheduler.DAGScheduler: ShuffleMapStage 27 (countByKey at ColumnProfiler.scala:592) finished in 0.082 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,522 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,522 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,523 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 28)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,523 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,523 INFO scheduler.DAGScheduler: Submitting ResultStage 28 (ShuffledRDD[116] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,528 INFO memory.MemoryStore: Block broadcast_24 stored as values in memory (estimated size 5.1 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,530 INFO memory.MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,531 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on 10.0.107.151:40635 (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,532 INFO spark.SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,532 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (ShuffledRDD[116] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,533 INFO cluster.YarnScheduler: Adding task set 28.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,535 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 28.0 (TID 22) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,552 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on algo-1:40133 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,562 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,589 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on 10.0.107.151:40635 in memory (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,598 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 28.0 (TID 22) in 63 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,599 INFO cluster.YarnScheduler: Removed TaskSet 28.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,599 INFO scheduler.DAGScheduler: ResultStage 28 (countByKey at ColumnProfiler.scala:592) finished in 0.075 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,600 INFO scheduler.DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,600 INFO cluster.YarnScheduler: Killing all running tasks in stage 28: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,600 INFO scheduler.DAGScheduler: Job 19 finished: countByKey at ColumnProfiler.scala:592, took 0.163816 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,617 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on algo-1:40133 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,796 INFO scheduler.DAGScheduler: Registering RDD 121 (collect at AnalysisRunner.scala:326) as input to shuffle 9\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,796 INFO scheduler.DAGScheduler: Got map stage job 20 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,796 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 29 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,797 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,797 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,798 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[121] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,802 INFO memory.MemoryStore: Block broadcast_25 stored as values in memory (estimated size 100.0 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,804 INFO memory.MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,806 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on 10.0.107.151:40635 (size: 32.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,806 INFO spark.SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,808 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[121] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,808 INFO cluster.YarnScheduler: Adding task set 29.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,810 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 29.0 (TID 23) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:53,822 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on algo-1:40133 (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,023 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 29.0 (TID 23) in 213 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,023 INFO cluster.YarnScheduler: Removed TaskSet 29.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,024 INFO scheduler.DAGScheduler: ShuffleMapStage 29 (collect at AnalysisRunner.scala:326) finished in 0.226 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,025 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,025 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,025 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,027 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,099 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,101 INFO scheduler.DAGScheduler: Got job 21 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,101 INFO scheduler.DAGScheduler: Final stage: ResultStage 31 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,101 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,101 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,101 INFO scheduler.DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[124] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,107 INFO memory.MemoryStore: Block broadcast_26 stored as values in memory (estimated size 184.6 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,111 INFO memory.MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,111 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on 10.0.107.151:40635 (size: 50.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,112 INFO spark.SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,113 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[124] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,113 INFO cluster.YarnScheduler: Adding task set 31.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,115 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 31.0 (TID 24) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,129 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on algo-1:40133 (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,147 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,282 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 31.0 (TID 24) in 167 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,282 INFO cluster.YarnScheduler: Removed TaskSet 31.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,283 INFO scheduler.DAGScheduler: ResultStage 31 (collect at AnalysisRunner.scala:326) finished in 0.181 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,286 INFO scheduler.DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,286 INFO cluster.YarnScheduler: Killing all running tasks in stage 31: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,287 INFO scheduler.DAGScheduler: Job 21 finished: collect at AnalysisRunner.scala:326, took 0.187511 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,427 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,428 INFO scheduler.DAGScheduler: Got job 22 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,429 INFO scheduler.DAGScheduler: Final stage: ResultStage 32 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,429 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,429 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,430 INFO scheduler.DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[134] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,439 INFO memory.MemoryStore: Block broadcast_27 stored as values in memory (estimated size 54.8 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,440 INFO memory.MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,441 INFO storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on 10.0.107.151:40635 (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,441 INFO spark.SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,442 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[134] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,442 INFO cluster.YarnScheduler: Adding task set 32.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,444 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 32.0 (TID 25) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,454 INFO storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on algo-1:40133 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,486 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 32.0 (TID 25) in 42 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,486 INFO cluster.YarnScheduler: Removed TaskSet 32.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,487 INFO scheduler.DAGScheduler: ResultStage 32 (treeReduce at KLLRunner.scala:107) finished in 0.056 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,487 INFO scheduler.DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,487 INFO cluster.YarnScheduler: Killing all running tasks in stage 32: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,488 INFO scheduler.DAGScheduler: Job 22 finished: treeReduce at KLLRunner.scala:107, took 0.060394 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,699 INFO scheduler.DAGScheduler: Registering RDD 139 (collect at AnalysisRunner.scala:326) as input to shuffle 10\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,699 INFO scheduler.DAGScheduler: Got map stage job 23 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,700 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 33 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,700 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,700 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,701 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[139] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,707 INFO memory.MemoryStore: Block broadcast_28 stored as values in memory (estimated size 90.7 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,708 INFO memory.MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,709 INFO storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on 10.0.107.151:40635 (size: 27.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,710 INFO spark.SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,711 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[139] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,711 INFO cluster.YarnScheduler: Adding task set 33.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,713 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 33.0 (TID 26) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,724 INFO storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on algo-1:40133 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,739 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 33.0 (TID 26) in 27 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,739 INFO cluster.YarnScheduler: Removed TaskSet 33.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,740 INFO scheduler.DAGScheduler: ShuffleMapStage 33 (collect at AnalysisRunner.scala:326) finished in 0.037 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,740 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,740 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,740 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,740 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,789 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,790 INFO scheduler.DAGScheduler: Got job 24 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,791 INFO scheduler.DAGScheduler: Final stage: ResultStage 35 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,791 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,791 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,791 INFO scheduler.DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[142] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,794 INFO memory.MemoryStore: Block broadcast_29 stored as values in memory (estimated size 66.2 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,796 INFO memory.MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,797 INFO storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on 10.0.107.151:40635 (size: 19.2 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,798 INFO spark.SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,798 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[142] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,798 INFO cluster.YarnScheduler: Adding task set 35.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,800 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 35.0 (TID 27) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,811 INFO storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on algo-1:40133 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,819 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 10 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,838 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 35.0 (TID 27) in 38 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,838 INFO cluster.YarnScheduler: Removed TaskSet 35.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,838 INFO scheduler.DAGScheduler: ResultStage 35 (collect at AnalysisRunner.scala:326) finished in 0.045 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,840 INFO scheduler.DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,840 INFO cluster.YarnScheduler: Killing all running tasks in stage 35: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,841 INFO scheduler.DAGScheduler: Job 24 finished: collect at AnalysisRunner.scala:326, took 0.050894 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,964 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,965 INFO storage.BlockManagerInfo: Removed broadcast_25_piece0 on algo-1:40133 in memory (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,973 INFO scheduler.DAGScheduler: Registering RDD 150 (countByKey at ColumnProfiler.scala:592) as input to shuffle 11\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,979 INFO scheduler.DAGScheduler: Got job 25 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,979 INFO scheduler.DAGScheduler: Final stage: ResultStage 37 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,973 INFO storage.BlockManagerInfo: Removed broadcast_25_piece0 on 10.0.107.151:40635 in memory (size: 32.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,980 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 36)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,980 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 36)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,983 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[150] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:54,999 INFO memory.MemoryStore: Block broadcast_30 stored as values in memory (estimated size 47.1 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,005 INFO storage.BlockManagerInfo: Removed broadcast_27_piece0 on 10.0.107.151:40635 in memory (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,006 INFO memory.MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,010 INFO storage.BlockManagerInfo: Removed broadcast_27_piece0 on algo-1:40133 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,011 INFO storage.BlockManagerInfo: Added broadcast_30_piece0 in memory on 10.0.107.151:40635 (size: 18.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,011 INFO spark.SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,012 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[150] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,012 INFO cluster.YarnScheduler: Adding task set 36.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,014 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 36.0 (TID 28) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,039 INFO storage.BlockManagerInfo: Added broadcast_30_piece0 in memory on algo-1:40133 (size: 18.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,057 INFO storage.BlockManagerInfo: Removed broadcast_23_piece0 on 10.0.107.151:40635 in memory (size: 18.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,070 INFO storage.BlockManagerInfo: Removed broadcast_23_piece0 on algo-1:40133 in memory (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,123 INFO storage.BlockManagerInfo: Removed broadcast_22_piece0 on 10.0.107.151:40635 in memory (size: 19.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,126 INFO storage.BlockManagerInfo: Removed broadcast_22_piece0 on algo-1:40133 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,162 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 36.0 (TID 28) in 149 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,162 INFO cluster.YarnScheduler: Removed TaskSet 36.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,163 INFO scheduler.DAGScheduler: ShuffleMapStage 36 (countByKey at ColumnProfiler.scala:592) finished in 0.178 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,163 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,164 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,164 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 37)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,164 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,165 INFO scheduler.DAGScheduler: Submitting ResultStage 37 (ShuffledRDD[151] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,166 INFO memory.MemoryStore: Block broadcast_31 stored as values in memory (estimated size 5.1 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,168 INFO memory.MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,168 INFO storage.BlockManagerInfo: Added broadcast_31_piece0 in memory on 10.0.107.151:40635 (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,169 INFO spark.SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,169 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (ShuffledRDD[151] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,170 INFO cluster.YarnScheduler: Adding task set 37.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,171 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 37.0 (TID 29) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,173 INFO storage.BlockManagerInfo: Removed broadcast_28_piece0 on 10.0.107.151:40635 in memory (size: 27.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,182 INFO storage.BlockManagerInfo: Removed broadcast_28_piece0 on algo-1:40133 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,186 INFO storage.BlockManagerInfo: Removed broadcast_26_piece0 on 10.0.107.151:40635 in memory (size: 50.3 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,191 INFO storage.BlockManagerInfo: Removed broadcast_26_piece0 on algo-1:40133 in memory (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,198 INFO storage.BlockManagerInfo: Removed broadcast_21_piece0 on 10.0.107.151:40635 in memory (size: 27.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,200 INFO storage.BlockManagerInfo: Removed broadcast_21_piece0 on algo-1:40133 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,204 INFO storage.BlockManagerInfo: Removed broadcast_24_piece0 on 10.0.107.151:40635 in memory (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,205 INFO storage.BlockManagerInfo: Added broadcast_31_piece0 in memory on algo-1:40133 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,207 INFO storage.BlockManagerInfo: Removed broadcast_24_piece0 on algo-1:40133 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,212 INFO storage.BlockManagerInfo: Removed broadcast_29_piece0 on 10.0.107.151:40635 in memory (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,219 INFO storage.BlockManagerInfo: Removed broadcast_29_piece0 on algo-1:40133 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,220 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,253 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 37.0 (TID 29) in 82 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,253 INFO cluster.YarnScheduler: Removed TaskSet 37.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,254 INFO scheduler.DAGScheduler: ResultStage 37 (countByKey at ColumnProfiler.scala:592) finished in 0.089 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,255 INFO scheduler.DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,255 INFO cluster.YarnScheduler: Killing all running tasks in stage 37: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,256 INFO scheduler.DAGScheduler: Job 25 finished: countByKey at ColumnProfiler.scala:592, took 0.290147 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,452 INFO scheduler.DAGScheduler: Registering RDD 156 (collect at AnalysisRunner.scala:326) as input to shuffle 12\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,453 INFO scheduler.DAGScheduler: Got map stage job 26 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,453 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 38 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,453 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,454 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,454 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[156] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,460 INFO memory.MemoryStore: Block broadcast_32 stored as values in memory (estimated size 100.0 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,465 INFO memory.MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,465 INFO storage.BlockManagerInfo: Added broadcast_32_piece0 in memory on 10.0.107.151:40635 (size: 32.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,466 INFO spark.SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,466 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[156] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,467 INFO cluster.YarnScheduler: Adding task set 38.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,469 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 38.0 (TID 30) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,482 INFO storage.BlockManagerInfo: Added broadcast_32_piece0 in memory on algo-1:40133 (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,641 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 38.0 (TID 30) in 173 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,642 INFO scheduler.DAGScheduler: ShuffleMapStage 38 (collect at AnalysisRunner.scala:326) finished in 0.186 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,643 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,644 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,643 INFO cluster.YarnScheduler: Removed TaskSet 38.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,644 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,644 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,693 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,694 INFO scheduler.DAGScheduler: Got job 27 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,695 INFO scheduler.DAGScheduler: Final stage: ResultStage 40 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,695 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 39)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,695 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,696 INFO scheduler.DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[159] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,705 INFO memory.MemoryStore: Block broadcast_33 stored as values in memory (estimated size 184.6 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,708 INFO memory.MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 50.2 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,709 INFO storage.BlockManagerInfo: Added broadcast_33_piece0 in memory on 10.0.107.151:40635 (size: 50.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,710 INFO spark.SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,711 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[159] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,711 INFO cluster.YarnScheduler: Adding task set 40.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,713 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 40.0 (TID 31) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,730 INFO storage.BlockManagerInfo: Added broadcast_33_piece0 in memory on algo-1:40133 (size: 50.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,744 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,862 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 40.0 (TID 31) in 150 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,862 INFO cluster.YarnScheduler: Removed TaskSet 40.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,863 INFO scheduler.DAGScheduler: ResultStage 40 (collect at AnalysisRunner.scala:326) finished in 0.165 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,864 INFO scheduler.DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,865 INFO cluster.YarnScheduler: Killing all running tasks in stage 40: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,865 INFO scheduler.DAGScheduler: Job 27 finished: collect at AnalysisRunner.scala:326, took 0.171927 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,988 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,989 INFO scheduler.DAGScheduler: Got job 28 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,989 INFO scheduler.DAGScheduler: Final stage: ResultStage 41 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,989 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,989 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,990 INFO scheduler.DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[169] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,994 INFO memory.MemoryStore: Block broadcast_34 stored as values in memory (estimated size 54.8 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,995 INFO memory.MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,996 INFO storage.BlockManagerInfo: Added broadcast_34_piece0 in memory on 10.0.107.151:40635 (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,996 INFO spark.SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,997 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[169] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,997 INFO cluster.YarnScheduler: Adding task set 41.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:55,998 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 41.0 (TID 32) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,016 INFO storage.BlockManagerInfo: Added broadcast_34_piece0 in memory on algo-1:40133 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,056 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 41.0 (TID 32) in 58 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,059 INFO scheduler.DAGScheduler: ResultStage 41 (treeReduce at KLLRunner.scala:107) finished in 0.068 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,059 INFO scheduler.DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,059 INFO cluster.YarnScheduler: Removed TaskSet 41.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,059 INFO cluster.YarnScheduler: Killing all running tasks in stage 41: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,060 INFO scheduler.DAGScheduler: Job 28 finished: treeReduce at KLLRunner.scala:107, took 0.071496 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,186 INFO scheduler.DAGScheduler: Registering RDD 174 (collect at AnalysisRunner.scala:326) as input to shuffle 13\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,186 INFO scheduler.DAGScheduler: Got map stage job 29 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,186 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 42 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,186 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,186 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,187 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 42 (MapPartitionsRDD[174] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,192 INFO memory.MemoryStore: Block broadcast_35 stored as values in memory (estimated size 90.7 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,193 INFO memory.MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,194 INFO storage.BlockManagerInfo: Added broadcast_35_piece0 in memory on 10.0.107.151:40635 (size: 27.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,194 INFO spark.SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,195 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[174] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,195 INFO cluster.YarnScheduler: Adding task set 42.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,197 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 42.0 (TID 33) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,207 INFO storage.BlockManagerInfo: Added broadcast_35_piece0 in memory on algo-1:40133 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,244 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 42.0 (TID 33) in 48 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,244 INFO cluster.YarnScheduler: Removed TaskSet 42.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,245 INFO scheduler.DAGScheduler: ShuffleMapStage 42 (collect at AnalysisRunner.scala:326) finished in 0.058 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,245 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,245 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,246 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,246 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,340 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,341 INFO scheduler.DAGScheduler: Got job 30 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,341 INFO scheduler.DAGScheduler: Final stage: ResultStage 44 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,341 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 43)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,341 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,342 INFO scheduler.DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[177] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,344 INFO memory.MemoryStore: Block broadcast_36 stored as values in memory (estimated size 66.2 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,346 INFO memory.MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,346 INFO storage.BlockManagerInfo: Added broadcast_36_piece0 in memory on 10.0.107.151:40635 (size: 19.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,347 INFO spark.SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,347 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[177] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,347 INFO cluster.YarnScheduler: Adding task set 44.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,348 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 44.0 (TID 34) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,367 INFO storage.BlockManagerInfo: Added broadcast_36_piece0 in memory on algo-1:40133 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,374 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 13 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,381 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 44.0 (TID 34) in 33 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,382 INFO cluster.YarnScheduler: Removed TaskSet 44.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,382 INFO scheduler.DAGScheduler: ResultStage 44 (collect at AnalysisRunner.scala:326) finished in 0.039 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,386 INFO scheduler.DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,386 INFO cluster.YarnScheduler: Killing all running tasks in stage 44: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,387 INFO scheduler.DAGScheduler: Job 30 finished: collect at AnalysisRunner.scala:326, took 0.047080 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,511 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,513 INFO scheduler.DAGScheduler: Registering RDD 185 (countByKey at ColumnProfiler.scala:592) as input to shuffle 14\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,513 INFO scheduler.DAGScheduler: Got job 31 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,514 INFO scheduler.DAGScheduler: Final stage: ResultStage 46 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,514 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 45)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,514 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 45)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,517 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 45 (MapPartitionsRDD[185] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,525 INFO memory.MemoryStore: Block broadcast_37 stored as values in memory (estimated size 47.1 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,526 INFO memory.MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,527 INFO storage.BlockManagerInfo: Added broadcast_37_piece0 in memory on 10.0.107.151:40635 (size: 18.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,529 INFO spark.SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,529 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[185] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,529 INFO cluster.YarnScheduler: Adding task set 45.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,532 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 45.0 (TID 35) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,542 INFO storage.BlockManagerInfo: Added broadcast_37_piece0 in memory on algo-1:40133 (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,619 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 45.0 (TID 35) in 86 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,619 INFO cluster.YarnScheduler: Removed TaskSet 45.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,620 INFO scheduler.DAGScheduler: ShuffleMapStage 45 (countByKey at ColumnProfiler.scala:592) finished in 0.103 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,621 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,621 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,621 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 46)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,622 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,622 INFO scheduler.DAGScheduler: Submitting ResultStage 46 (ShuffledRDD[186] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,623 INFO memory.MemoryStore: Block broadcast_38 stored as values in memory (estimated size 5.1 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,625 INFO memory.MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,626 INFO storage.BlockManagerInfo: Added broadcast_38_piece0 in memory on 10.0.107.151:40635 (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,626 INFO spark.SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,627 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (ShuffledRDD[186] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,627 INFO cluster.YarnScheduler: Adding task set 46.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,628 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 46.0 (TID 36) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,639 INFO storage.BlockManagerInfo: Added broadcast_38_piece0 in memory on algo-1:40133 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,645 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 14 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,662 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 46.0 (TID 36) in 34 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,663 INFO cluster.YarnScheduler: Removed TaskSet 46.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,663 INFO scheduler.DAGScheduler: ResultStage 46 (countByKey at ColumnProfiler.scala:592) finished in 0.040 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,664 INFO scheduler.DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,664 INFO cluster.YarnScheduler: Killing all running tasks in stage 46: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,665 INFO scheduler.DAGScheduler: Job 31 finished: countByKey at ColumnProfiler.scala:592, took 0.153210 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,866 INFO scheduler.DAGScheduler: Registering RDD 191 (collect at AnalysisRunner.scala:326) as input to shuffle 15\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,866 INFO scheduler.DAGScheduler: Got map stage job 32 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,866 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 47 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,866 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,867 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,867 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 47 (MapPartitionsRDD[191] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,871 INFO memory.MemoryStore: Block broadcast_39 stored as values in memory (estimated size 100.0 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,874 INFO memory.MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,874 INFO storage.BlockManagerInfo: Added broadcast_39_piece0 in memory on 10.0.107.151:40635 (size: 32.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,876 INFO spark.SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,876 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 47 (MapPartitionsRDD[191] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,876 INFO cluster.YarnScheduler: Adding task set 47.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,877 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 47.0 (TID 37) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:56,888 INFO storage.BlockManagerInfo: Added broadcast_39_piece0 in memory on algo-1:40133 (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,081 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 47.0 (TID 37) in 204 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,081 INFO cluster.YarnScheduler: Removed TaskSet 47.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,082 INFO scheduler.DAGScheduler: ShuffleMapStage 47 (collect at AnalysisRunner.scala:326) finished in 0.214 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,085 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,086 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,086 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,086 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,135 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,136 INFO scheduler.DAGScheduler: Got job 33 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,136 INFO scheduler.DAGScheduler: Final stage: ResultStage 49 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,136 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 48)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,136 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,137 INFO scheduler.DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[194] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,145 INFO memory.MemoryStore: Block broadcast_40 stored as values in memory (estimated size 184.6 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,149 INFO memory.MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 50.2 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,149 INFO storage.BlockManagerInfo: Added broadcast_40_piece0 in memory on 10.0.107.151:40635 (size: 50.2 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,150 INFO spark.SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,150 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[194] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,150 INFO cluster.YarnScheduler: Adding task set 49.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,151 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 49.0 (TID 38) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,164 INFO storage.BlockManagerInfo: Added broadcast_40_piece0 in memory on algo-1:40133 (size: 50.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,177 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,289 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 49.0 (TID 38) in 138 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,290 INFO cluster.YarnScheduler: Removed TaskSet 49.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,291 INFO scheduler.DAGScheduler: ResultStage 49 (collect at AnalysisRunner.scala:326) finished in 0.154 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,292 INFO scheduler.DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,293 INFO cluster.YarnScheduler: Killing all running tasks in stage 49: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,294 INFO scheduler.DAGScheduler: Job 33 finished: collect at AnalysisRunner.scala:326, took 0.158406 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,445 INFO storage.BlockManagerInfo: Removed broadcast_31_piece0 on algo-1:40133 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,458 INFO storage.BlockManagerInfo: Removed broadcast_31_piece0 on 10.0.107.151:40635 in memory (size: 3.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,464 INFO storage.BlockManagerInfo: Removed broadcast_39_piece0 on 10.0.107.151:40635 in memory (size: 32.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,465 INFO storage.BlockManagerInfo: Removed broadcast_39_piece0 on algo-1:40133 in memory (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,475 INFO storage.BlockManagerInfo: Removed broadcast_30_piece0 on 10.0.107.151:40635 in memory (size: 18.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,476 INFO storage.BlockManagerInfo: Removed broadcast_30_piece0 on algo-1:40133 in memory (size: 18.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,484 INFO storage.BlockManagerInfo: Removed broadcast_32_piece0 on 10.0.107.151:40635 in memory (size: 32.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,486 INFO storage.BlockManagerInfo: Removed broadcast_32_piece0 on algo-1:40133 in memory (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,490 INFO storage.BlockManagerInfo: Removed broadcast_34_piece0 on 10.0.107.151:40635 in memory (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,492 INFO storage.BlockManagerInfo: Removed broadcast_34_piece0 on algo-1:40133 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,498 INFO storage.BlockManagerInfo: Removed broadcast_40_piece0 on 10.0.107.151:40635 in memory (size: 50.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,499 INFO storage.BlockManagerInfo: Removed broadcast_40_piece0 on algo-1:40133 in memory (size: 50.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,504 INFO storage.BlockManagerInfo: Removed broadcast_36_piece0 on 10.0.107.151:40635 in memory (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,508 INFO storage.BlockManagerInfo: Removed broadcast_36_piece0 on algo-1:40133 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,513 INFO storage.BlockManagerInfo: Removed broadcast_35_piece0 on 10.0.107.151:40635 in memory (size: 27.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,515 INFO storage.BlockManagerInfo: Removed broadcast_35_piece0 on algo-1:40133 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,522 INFO storage.BlockManagerInfo: Removed broadcast_33_piece0 on algo-1:40133 in memory (size: 50.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,523 INFO storage.BlockManagerInfo: Removed broadcast_33_piece0 on 10.0.107.151:40635 in memory (size: 50.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,530 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,530 INFO storage.BlockManagerInfo: Removed broadcast_37_piece0 on 10.0.107.151:40635 in memory (size: 18.8 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,533 INFO scheduler.DAGScheduler: Got job 34 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,535 INFO scheduler.DAGScheduler: Final stage: ResultStage 50 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,535 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,536 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,536 INFO storage.BlockManagerInfo: Removed broadcast_37_piece0 on algo-1:40133 in memory (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,537 INFO scheduler.DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[204] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,542 INFO storage.BlockManagerInfo: Removed broadcast_38_piece0 on algo-1:40133 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,545 INFO storage.BlockManagerInfo: Removed broadcast_38_piece0 on 10.0.107.151:40635 in memory (size: 3.0 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,555 INFO memory.MemoryStore: Block broadcast_41 stored as values in memory (estimated size 54.8 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,556 INFO memory.MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,557 INFO storage.BlockManagerInfo: Added broadcast_41_piece0 in memory on 10.0.107.151:40635 (size: 20.7 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,557 INFO spark.SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,560 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[204] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,561 INFO cluster.YarnScheduler: Adding task set 50.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,562 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 50.0 (TID 39) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,575 INFO storage.BlockManagerInfo: Added broadcast_41_piece0 in memory on algo-1:40133 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,626 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 50.0 (TID 39) in 64 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,626 INFO cluster.YarnScheduler: Removed TaskSet 50.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,627 INFO scheduler.DAGScheduler: ResultStage 50 (treeReduce at KLLRunner.scala:107) finished in 0.087 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,627 INFO scheduler.DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,627 INFO cluster.YarnScheduler: Killing all running tasks in stage 50: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,628 INFO scheduler.DAGScheduler: Job 34 finished: treeReduce at KLLRunner.scala:107, took 0.097958 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,888 INFO scheduler.DAGScheduler: Registering RDD 209 (collect at AnalysisRunner.scala:326) as input to shuffle 16\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,888 INFO scheduler.DAGScheduler: Got map stage job 35 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,889 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 51 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,889 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,889 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,890 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 51 (MapPartitionsRDD[209] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,898 INFO memory.MemoryStore: Block broadcast_42 stored as values in memory (estimated size 90.7 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,900 INFO memory.MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,901 INFO storage.BlockManagerInfo: Added broadcast_42_piece0 in memory on 10.0.107.151:40635 (size: 27.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,901 INFO spark.SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,902 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 51 (MapPartitionsRDD[209] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,906 INFO cluster.YarnScheduler: Adding task set 51.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:57,909 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 51.0 (TID 40) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,006 INFO storage.BlockManagerInfo: Added broadcast_42_piece0 in memory on algo-1:40133 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,037 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 51.0 (TID 40) in 129 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,038 INFO cluster.YarnScheduler: Removed TaskSet 51.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,039 INFO scheduler.DAGScheduler: ShuffleMapStage 51 (collect at AnalysisRunner.scala:326) finished in 0.144 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,039 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,039 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,039 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,040 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,090 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,092 INFO scheduler.DAGScheduler: Got job 36 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,092 INFO scheduler.DAGScheduler: Final stage: ResultStage 53 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,092 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,092 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,093 INFO scheduler.DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[212] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,097 INFO memory.MemoryStore: Block broadcast_43 stored as values in memory (estimated size 66.2 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,099 INFO memory.MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,100 INFO storage.BlockManagerInfo: Added broadcast_43_piece0 in memory on 10.0.107.151:40635 (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,101 INFO spark.SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,101 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[212] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,102 INFO cluster.YarnScheduler: Adding task set 53.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,106 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 53.0 (TID 41) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,124 INFO storage.BlockManagerInfo: Added broadcast_43_piece0 in memory on algo-1:40133 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,128 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 16 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,140 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 53.0 (TID 41) in 34 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,140 INFO cluster.YarnScheduler: Removed TaskSet 53.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,141 INFO scheduler.DAGScheduler: ResultStage 53 (collect at AnalysisRunner.scala:326) finished in 0.047 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,142 INFO scheduler.DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,142 INFO cluster.YarnScheduler: Killing all running tasks in stage 53: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,142 INFO scheduler.DAGScheduler: Job 36 finished: collect at AnalysisRunner.scala:326, took 0.051415 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,227 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,229 INFO scheduler.DAGScheduler: Registering RDD 220 (countByKey at ColumnProfiler.scala:592) as input to shuffle 17\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,230 INFO scheduler.DAGScheduler: Got job 37 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,230 INFO scheduler.DAGScheduler: Final stage: ResultStage 55 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,230 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 54)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,230 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 54)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,234 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 54 (MapPartitionsRDD[220] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,245 INFO memory.MemoryStore: Block broadcast_44 stored as values in memory (estimated size 47.1 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,246 INFO memory.MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,247 INFO storage.BlockManagerInfo: Added broadcast_44_piece0 in memory on 10.0.107.151:40635 (size: 18.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,247 INFO spark.SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,248 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[220] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,248 INFO cluster.YarnScheduler: Adding task set 54.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,250 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 54.0 (TID 42) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,265 INFO storage.BlockManagerInfo: Added broadcast_44_piece0 in memory on algo-1:40133 (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,335 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 54.0 (TID 42) in 86 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,336 INFO cluster.YarnScheduler: Removed TaskSet 54.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,337 INFO scheduler.DAGScheduler: ShuffleMapStage 54 (countByKey at ColumnProfiler.scala:592) finished in 0.102 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,338 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,338 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,339 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 55)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,339 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,340 INFO scheduler.DAGScheduler: Submitting ResultStage 55 (ShuffledRDD[221] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,341 INFO memory.MemoryStore: Block broadcast_45 stored as values in memory (estimated size 5.1 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,344 INFO memory.MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,344 INFO storage.BlockManagerInfo: Added broadcast_45_piece0 in memory on 10.0.107.151:40635 (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,345 INFO spark.SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,346 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (ShuffledRDD[221] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,346 INFO cluster.YarnScheduler: Adding task set 55.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,348 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 55.0 (TID 43) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,365 INFO storage.BlockManagerInfo: Added broadcast_45_piece0 in memory on algo-1:40133 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,378 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 17 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,396 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 55.0 (TID 43) in 48 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,396 INFO cluster.YarnScheduler: Removed TaskSet 55.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,397 INFO scheduler.DAGScheduler: ResultStage 55 (countByKey at ColumnProfiler.scala:592) finished in 0.056 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,398 INFO scheduler.DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,399 INFO cluster.YarnScheduler: Killing all running tasks in stage 55: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,399 INFO scheduler.DAGScheduler: Job 37 finished: countByKey at ColumnProfiler.scala:592, took 0.171710 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,564 INFO scheduler.DAGScheduler: Registering RDD 226 (collect at AnalysisRunner.scala:326) as input to shuffle 18\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,565 INFO scheduler.DAGScheduler: Got map stage job 38 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,565 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 56 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,565 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,566 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,566 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 56 (MapPartitionsRDD[226] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,571 INFO memory.MemoryStore: Block broadcast_46 stored as values in memory (estimated size 100.0 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,573 INFO memory.MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,574 INFO storage.BlockManagerInfo: Added broadcast_46_piece0 in memory on 10.0.107.151:40635 (size: 32.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,574 INFO spark.SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,575 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 56 (MapPartitionsRDD[226] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,575 INFO cluster.YarnScheduler: Adding task set 56.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,576 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 56.0 (TID 44) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,594 INFO storage.BlockManagerInfo: Added broadcast_46_piece0 in memory on algo-1:40133 (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,749 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 56.0 (TID 44) in 173 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,749 INFO cluster.YarnScheduler: Removed TaskSet 56.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,750 INFO scheduler.DAGScheduler: ShuffleMapStage 56 (collect at AnalysisRunner.scala:326) finished in 0.182 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,751 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,751 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,752 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,752 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,807 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,808 INFO scheduler.DAGScheduler: Got job 39 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,808 INFO scheduler.DAGScheduler: Final stage: ResultStage 58 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,809 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 57)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,809 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,809 INFO scheduler.DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[229] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,816 INFO memory.MemoryStore: Block broadcast_47 stored as values in memory (estimated size 184.6 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,818 INFO memory.MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,819 INFO storage.BlockManagerInfo: Added broadcast_47_piece0 in memory on 10.0.107.151:40635 (size: 50.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,819 INFO spark.SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,820 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[229] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,820 INFO cluster.YarnScheduler: Adding task set 58.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,821 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 58.0 (TID 45) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,832 INFO storage.BlockManagerInfo: Added broadcast_47_piece0 in memory on algo-1:40133 (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,849 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 18 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,936 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 58.0 (TID 45) in 115 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,936 INFO cluster.YarnScheduler: Removed TaskSet 58.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,937 INFO scheduler.DAGScheduler: ResultStage 58 (collect at AnalysisRunner.scala:326) finished in 0.126 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,940 INFO scheduler.DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,941 INFO cluster.YarnScheduler: Killing all running tasks in stage 58: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:58,941 INFO scheduler.DAGScheduler: Job 39 finished: collect at AnalysisRunner.scala:326, took 0.133491 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,075 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,076 INFO scheduler.DAGScheduler: Got job 40 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,076 INFO scheduler.DAGScheduler: Final stage: ResultStage 59 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,076 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,077 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,077 INFO scheduler.DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[239] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,088 INFO memory.MemoryStore: Block broadcast_48 stored as values in memory (estimated size 54.8 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,090 INFO memory.MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,090 INFO storage.BlockManagerInfo: Added broadcast_48_piece0 in memory on 10.0.107.151:40635 (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,091 INFO spark.SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,091 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[239] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,091 INFO cluster.YarnScheduler: Adding task set 59.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,095 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 59.0 (TID 46) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,104 INFO storage.BlockManagerInfo: Added broadcast_48_piece0 in memory on algo-1:40133 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,144 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 59.0 (TID 46) in 50 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,144 INFO cluster.YarnScheduler: Removed TaskSet 59.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,145 INFO scheduler.DAGScheduler: ResultStage 59 (treeReduce at KLLRunner.scala:107) finished in 0.067 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,146 INFO scheduler.DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,146 INFO cluster.YarnScheduler: Killing all running tasks in stage 59: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,146 INFO scheduler.DAGScheduler: Job 40 finished: treeReduce at KLLRunner.scala:107, took 0.070490 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,297 INFO scheduler.DAGScheduler: Registering RDD 244 (collect at AnalysisRunner.scala:326) as input to shuffle 19\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,297 INFO scheduler.DAGScheduler: Got map stage job 41 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,298 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 60 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,298 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,298 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,299 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 60 (MapPartitionsRDD[244] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,303 INFO memory.MemoryStore: Block broadcast_49 stored as values in memory (estimated size 90.7 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,305 INFO memory.MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,305 INFO storage.BlockManagerInfo: Added broadcast_49_piece0 in memory on 10.0.107.151:40635 (size: 27.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,306 INFO spark.SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,307 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 60 (MapPartitionsRDD[244] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,307 INFO cluster.YarnScheduler: Adding task set 60.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,308 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 60.0 (TID 47) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,319 INFO storage.BlockManagerInfo: Added broadcast_49_piece0 in memory on algo-1:40133 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,344 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 60.0 (TID 47) in 36 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,345 INFO cluster.YarnScheduler: Removed TaskSet 60.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,345 INFO scheduler.DAGScheduler: ShuffleMapStage 60 (collect at AnalysisRunner.scala:326) finished in 0.045 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,346 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,347 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,347 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,347 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,440 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,447 INFO scheduler.DAGScheduler: Got job 42 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,448 INFO scheduler.DAGScheduler: Final stage: ResultStage 62 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,448 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 61)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,448 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,449 INFO scheduler.DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[247] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,453 INFO memory.MemoryStore: Block broadcast_50 stored as values in memory (estimated size 66.2 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,461 INFO memory.MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,462 INFO storage.BlockManagerInfo: Added broadcast_50_piece0 in memory on 10.0.107.151:40635 (size: 19.2 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,463 INFO spark.SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,463 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[247] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,463 INFO cluster.YarnScheduler: Adding task set 62.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,464 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 62.0 (TID 48) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,473 INFO storage.BlockManagerInfo: Added broadcast_50_piece0 in memory on algo-1:40133 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,480 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 19 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,491 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 62.0 (TID 48) in 27 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,491 INFO cluster.YarnScheduler: Removed TaskSet 62.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,492 INFO scheduler.DAGScheduler: ResultStage 62 (collect at AnalysisRunner.scala:326) finished in 0.040 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,492 INFO scheduler.DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,493 INFO cluster.YarnScheduler: Killing all running tasks in stage 62: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,493 INFO scheduler.DAGScheduler: Job 42 finished: collect at AnalysisRunner.scala:326, took 0.053549 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,697 INFO storage.BlockManagerInfo: Removed broadcast_49_piece0 on algo-1:40133 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,706 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,707 INFO scheduler.DAGScheduler: Registering RDD 255 (countByKey at ColumnProfiler.scala:592) as input to shuffle 20\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,707 INFO scheduler.DAGScheduler: Got job 43 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,707 INFO scheduler.DAGScheduler: Final stage: ResultStage 64 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,707 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 63)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,707 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 63)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,709 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 63 (MapPartitionsRDD[255] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,710 INFO storage.BlockManagerInfo: Removed broadcast_49_piece0 on 10.0.107.151:40635 in memory (size: 27.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,718 INFO memory.MemoryStore: Block broadcast_51 stored as values in memory (estimated size 47.1 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,719 INFO memory.MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,720 INFO storage.BlockManagerInfo: Added broadcast_51_piece0 in memory on 10.0.107.151:40635 (size: 18.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,721 INFO spark.SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,722 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 63 (MapPartitionsRDD[255] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,722 INFO cluster.YarnScheduler: Adding task set 63.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,724 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 63.0 (TID 49) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,725 INFO storage.BlockManagerInfo: Removed broadcast_48_piece0 on algo-1:40133 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,729 INFO storage.BlockManagerInfo: Removed broadcast_48_piece0 on 10.0.107.151:40635 in memory (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,734 INFO storage.BlockManagerInfo: Removed broadcast_41_piece0 on 10.0.107.151:40635 in memory (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,738 INFO storage.BlockManagerInfo: Removed broadcast_41_piece0 on algo-1:40133 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,739 INFO storage.BlockManagerInfo: Added broadcast_51_piece0 in memory on algo-1:40133 (size: 18.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,742 INFO storage.BlockManagerInfo: Removed broadcast_50_piece0 on 10.0.107.151:40635 in memory (size: 19.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,752 INFO storage.BlockManagerInfo: Removed broadcast_50_piece0 on algo-1:40133 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,755 INFO storage.BlockManagerInfo: Removed broadcast_44_piece0 on 10.0.107.151:40635 in memory (size: 18.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,756 INFO storage.BlockManagerInfo: Removed broadcast_44_piece0 on algo-1:40133 in memory (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,757 INFO storage.BlockManagerInfo: Removed broadcast_46_piece0 on 10.0.107.151:40635 in memory (size: 32.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,759 INFO storage.BlockManagerInfo: Removed broadcast_46_piece0 on algo-1:40133 in memory (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,762 INFO storage.BlockManagerInfo: Removed broadcast_47_piece0 on 10.0.107.151:40635 in memory (size: 50.3 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,762 INFO storage.BlockManagerInfo: Removed broadcast_47_piece0 on algo-1:40133 in memory (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,767 INFO storage.BlockManagerInfo: Removed broadcast_43_piece0 on 10.0.107.151:40635 in memory (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,768 INFO storage.BlockManagerInfo: Removed broadcast_43_piece0 on algo-1:40133 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,772 INFO storage.BlockManagerInfo: Removed broadcast_42_piece0 on algo-1:40133 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,774 INFO storage.BlockManagerInfo: Removed broadcast_42_piece0 on 10.0.107.151:40635 in memory (size: 27.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,778 INFO storage.BlockManagerInfo: Removed broadcast_45_piece0 on algo-1:40133 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,779 INFO storage.BlockManagerInfo: Removed broadcast_45_piece0 on 10.0.107.151:40635 in memory (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,828 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 63.0 (TID 49) in 105 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,828 INFO cluster.YarnScheduler: Removed TaskSet 63.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,829 INFO scheduler.DAGScheduler: ShuffleMapStage 63 (countByKey at ColumnProfiler.scala:592) finished in 0.119 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,829 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,829 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,830 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 64)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,830 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,830 INFO scheduler.DAGScheduler: Submitting ResultStage 64 (ShuffledRDD[256] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,832 INFO memory.MemoryStore: Block broadcast_52 stored as values in memory (estimated size 5.1 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,840 INFO memory.MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,841 INFO storage.BlockManagerInfo: Added broadcast_52_piece0 in memory on 10.0.107.151:40635 (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,841 INFO spark.SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,842 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (ShuffledRDD[256] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,842 INFO cluster.YarnScheduler: Adding task set 64.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,843 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 64.0 (TID 50) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,851 INFO storage.BlockManagerInfo: Added broadcast_52_piece0 in memory on algo-1:40133 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,854 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 20 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,876 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 64.0 (TID 50) in 33 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,876 INFO cluster.YarnScheduler: Removed TaskSet 64.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,877 INFO scheduler.DAGScheduler: ResultStage 64 (countByKey at ColumnProfiler.scala:592) finished in 0.046 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,877 INFO scheduler.DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,878 INFO cluster.YarnScheduler: Killing all running tasks in stage 64: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:17:59,878 INFO scheduler.DAGScheduler: Job 43 finished: countByKey at ColumnProfiler.scala:592, took 0.171981 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,112 INFO scheduler.DAGScheduler: Registering RDD 261 (collect at AnalysisRunner.scala:326) as input to shuffle 21\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,115 INFO scheduler.DAGScheduler: Got map stage job 44 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,115 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 65 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,115 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,116 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,116 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 65 (MapPartitionsRDD[261] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,122 INFO memory.MemoryStore: Block broadcast_53 stored as values in memory (estimated size 100.0 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,124 INFO memory.MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,124 INFO storage.BlockManagerInfo: Added broadcast_53_piece0 in memory on 10.0.107.151:40635 (size: 32.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,125 INFO spark.SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,125 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 65 (MapPartitionsRDD[261] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,125 INFO cluster.YarnScheduler: Adding task set 65.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,127 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 65.0 (TID 51) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,135 INFO storage.BlockManagerInfo: Added broadcast_53_piece0 in memory on algo-1:40133 (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,262 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 65.0 (TID 51) in 135 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,262 INFO cluster.YarnScheduler: Removed TaskSet 65.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,263 INFO scheduler.DAGScheduler: ShuffleMapStage 65 (collect at AnalysisRunner.scala:326) finished in 0.146 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,263 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,264 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,265 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,265 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,332 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,339 INFO scheduler.DAGScheduler: Got job 45 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,339 INFO scheduler.DAGScheduler: Final stage: ResultStage 67 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,340 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 66)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,340 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,340 INFO scheduler.DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[264] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,355 INFO memory.MemoryStore: Block broadcast_54 stored as values in memory (estimated size 184.6 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,358 INFO memory.MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 50.2 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,359 INFO storage.BlockManagerInfo: Added broadcast_54_piece0 in memory on 10.0.107.151:40635 (size: 50.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,362 INFO spark.SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,363 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[264] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,363 INFO cluster.YarnScheduler: Adding task set 67.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,366 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 67.0 (TID 52) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,374 INFO storage.BlockManagerInfo: Added broadcast_54_piece0 in memory on algo-1:40133 (size: 50.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,393 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 21 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,501 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 67.0 (TID 52) in 135 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,501 INFO cluster.YarnScheduler: Removed TaskSet 67.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,503 INFO scheduler.DAGScheduler: ResultStage 67 (collect at AnalysisRunner.scala:326) finished in 0.161 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,504 INFO scheduler.DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,505 INFO cluster.YarnScheduler: Killing all running tasks in stage 67: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,505 INFO scheduler.DAGScheduler: Job 45 finished: collect at AnalysisRunner.scala:326, took 0.166643 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,673 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,674 INFO scheduler.DAGScheduler: Got job 46 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,674 INFO scheduler.DAGScheduler: Final stage: ResultStage 68 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,675 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,675 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,676 INFO scheduler.DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[274] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,684 INFO memory.MemoryStore: Block broadcast_55 stored as values in memory (estimated size 54.8 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,688 INFO memory.MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,689 INFO storage.BlockManagerInfo: Added broadcast_55_piece0 in memory on 10.0.107.151:40635 (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,690 INFO spark.SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,690 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[274] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,691 INFO cluster.YarnScheduler: Adding task set 68.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,692 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 68.0 (TID 53) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,700 INFO storage.BlockManagerInfo: Added broadcast_55_piece0 in memory on algo-1:40133 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,726 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 68.0 (TID 53) in 34 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,727 INFO scheduler.DAGScheduler: ResultStage 68 (treeReduce at KLLRunner.scala:107) finished in 0.051 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,727 INFO scheduler.DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,727 INFO cluster.YarnScheduler: Removed TaskSet 68.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,727 INFO cluster.YarnScheduler: Killing all running tasks in stage 68: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,727 INFO scheduler.DAGScheduler: Job 46 finished: treeReduce at KLLRunner.scala:107, took 0.053833 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,853 INFO scheduler.DAGScheduler: Registering RDD 279 (collect at AnalysisRunner.scala:326) as input to shuffle 22\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,854 INFO scheduler.DAGScheduler: Got map stage job 47 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,854 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 69 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,854 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,854 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,855 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 69 (MapPartitionsRDD[279] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,861 INFO memory.MemoryStore: Block broadcast_56 stored as values in memory (estimated size 90.7 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,862 INFO memory.MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,863 INFO storage.BlockManagerInfo: Added broadcast_56_piece0 in memory on 10.0.107.151:40635 (size: 27.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,863 INFO spark.SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,864 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 69 (MapPartitionsRDD[279] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,864 INFO cluster.YarnScheduler: Adding task set 69.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,865 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 69.0 (TID 54) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,875 INFO storage.BlockManagerInfo: Added broadcast_56_piece0 in memory on algo-1:40133 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,897 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 69.0 (TID 54) in 32 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,897 INFO cluster.YarnScheduler: Removed TaskSet 69.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,898 INFO scheduler.DAGScheduler: ShuffleMapStage 69 (collect at AnalysisRunner.scala:326) finished in 0.043 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,898 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,898 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,898 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,898 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,971 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,972 INFO scheduler.DAGScheduler: Got job 48 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,972 INFO scheduler.DAGScheduler: Final stage: ResultStage 71 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,972 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 70)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,972 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,973 INFO scheduler.DAGScheduler: Submitting ResultStage 71 (MapPartitionsRDD[282] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,974 INFO memory.MemoryStore: Block broadcast_57 stored as values in memory (estimated size 66.2 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,977 INFO memory.MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,977 INFO storage.BlockManagerInfo: Added broadcast_57_piece0 in memory on 10.0.107.151:40635 (size: 19.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,977 INFO spark.SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,978 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 71 (MapPartitionsRDD[282] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,978 INFO cluster.YarnScheduler: Adding task set 71.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,979 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 71.0 (TID 55) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,986 INFO storage.BlockManagerInfo: Added broadcast_57_piece0 in memory on algo-1:40133 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,991 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 22 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,997 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 71.0 (TID 55) in 18 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,997 INFO scheduler.DAGScheduler: ResultStage 71 (collect at AnalysisRunner.scala:326) finished in 0.024 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,998 INFO scheduler.DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,998 INFO cluster.YarnScheduler: Removed TaskSet 71.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,998 INFO cluster.YarnScheduler: Killing all running tasks in stage 71: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:00,998 INFO scheduler.DAGScheduler: Job 48 finished: collect at AnalysisRunner.scala:326, took 0.027205 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,084 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,085 INFO scheduler.DAGScheduler: Registering RDD 290 (countByKey at ColumnProfiler.scala:592) as input to shuffle 23\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,085 INFO scheduler.DAGScheduler: Got job 49 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,085 INFO scheduler.DAGScheduler: Final stage: ResultStage 73 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,085 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 72)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,085 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 72)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,086 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 72 (MapPartitionsRDD[290] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,101 INFO memory.MemoryStore: Block broadcast_58 stored as values in memory (estimated size 47.1 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,102 INFO memory.MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,105 INFO storage.BlockManagerInfo: Added broadcast_58_piece0 in memory on 10.0.107.151:40635 (size: 18.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,105 INFO spark.SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,106 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 72 (MapPartitionsRDD[290] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,106 INFO cluster.YarnScheduler: Adding task set 72.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,107 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 72.0 (TID 56) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,114 INFO storage.BlockManagerInfo: Added broadcast_58_piece0 in memory on algo-1:40133 (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,155 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 72.0 (TID 56) in 48 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,155 INFO cluster.YarnScheduler: Removed TaskSet 72.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,156 INFO scheduler.DAGScheduler: ShuffleMapStage 72 (countByKey at ColumnProfiler.scala:592) finished in 0.069 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,156 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,156 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,156 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 73)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,156 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,156 INFO scheduler.DAGScheduler: Submitting ResultStage 73 (ShuffledRDD[291] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,158 INFO memory.MemoryStore: Block broadcast_59 stored as values in memory (estimated size 5.1 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,159 INFO memory.MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,159 INFO storage.BlockManagerInfo: Added broadcast_59_piece0 in memory on 10.0.107.151:40635 (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,160 INFO spark.SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,160 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 73 (ShuffledRDD[291] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,160 INFO cluster.YarnScheduler: Adding task set 73.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,161 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 73.0 (TID 57) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,170 INFO storage.BlockManagerInfo: Added broadcast_59_piece0 in memory on algo-1:40133 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,173 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 23 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,193 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 73.0 (TID 57) in 31 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,193 INFO cluster.YarnScheduler: Removed TaskSet 73.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,193 INFO scheduler.DAGScheduler: ResultStage 73 (countByKey at ColumnProfiler.scala:592) finished in 0.036 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,194 INFO scheduler.DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,194 INFO cluster.YarnScheduler: Killing all running tasks in stage 73: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,195 INFO scheduler.DAGScheduler: Job 49 finished: countByKey at ColumnProfiler.scala:592, took 0.110439 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,312 INFO scheduler.DAGScheduler: Registering RDD 296 (collect at AnalysisRunner.scala:326) as input to shuffle 24\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,313 INFO scheduler.DAGScheduler: Got map stage job 50 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,313 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 74 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,313 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,314 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,314 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 74 (MapPartitionsRDD[296] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,319 INFO memory.MemoryStore: Block broadcast_60 stored as values in memory (estimated size 100.0 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,321 INFO memory.MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,321 INFO storage.BlockManagerInfo: Added broadcast_60_piece0 in memory on 10.0.107.151:40635 (size: 32.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,322 INFO spark.SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,323 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 74 (MapPartitionsRDD[296] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,323 INFO cluster.YarnScheduler: Adding task set 74.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,329 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 74.0 (TID 58) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,342 INFO storage.BlockManagerInfo: Added broadcast_60_piece0 in memory on algo-1:40133 (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,448 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 74.0 (TID 58) in 119 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,449 INFO cluster.YarnScheduler: Removed TaskSet 74.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,450 INFO scheduler.DAGScheduler: ShuffleMapStage 74 (collect at AnalysisRunner.scala:326) finished in 0.134 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,458 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,458 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,459 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,459 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,510 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,511 INFO scheduler.DAGScheduler: Got job 51 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,512 INFO scheduler.DAGScheduler: Final stage: ResultStage 76 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,512 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 75)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,513 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,513 INFO scheduler.DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[299] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,522 INFO memory.MemoryStore: Block broadcast_61 stored as values in memory (estimated size 184.6 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,525 INFO memory.MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 50.2 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,525 INFO storage.BlockManagerInfo: Added broadcast_61_piece0 in memory on 10.0.107.151:40635 (size: 50.2 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,526 INFO spark.SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,527 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[299] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,527 INFO cluster.YarnScheduler: Adding task set 76.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,528 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 76.0 (TID 59) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,541 INFO storage.BlockManagerInfo: Added broadcast_61_piece0 in memory on algo-1:40133 (size: 50.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,557 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 24 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,663 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 76.0 (TID 59) in 135 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,663 INFO cluster.YarnScheduler: Removed TaskSet 76.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,663 INFO scheduler.DAGScheduler: ResultStage 76 (collect at AnalysisRunner.scala:326) finished in 0.147 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,664 INFO scheduler.DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,664 INFO cluster.YarnScheduler: Killing all running tasks in stage 76: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,664 INFO scheduler.DAGScheduler: Job 51 finished: collect at AnalysisRunner.scala:326, took 0.153764 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,779 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,780 INFO scheduler.DAGScheduler: Got job 52 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,781 INFO scheduler.DAGScheduler: Final stage: ResultStage 77 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,781 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,781 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,782 INFO scheduler.DAGScheduler: Submitting ResultStage 77 (MapPartitionsRDD[309] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,787 INFO memory.MemoryStore: Block broadcast_62 stored as values in memory (estimated size 54.8 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,789 INFO memory.MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,789 INFO storage.BlockManagerInfo: Added broadcast_62_piece0 in memory on 10.0.107.151:40635 (size: 20.7 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,790 INFO spark.SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,790 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 77 (MapPartitionsRDD[309] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,790 INFO cluster.YarnScheduler: Adding task set 77.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,792 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 77.0 (TID 60) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,799 INFO storage.BlockManagerInfo: Added broadcast_62_piece0 in memory on algo-1:40133 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,827 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 77.0 (TID 60) in 36 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,827 INFO cluster.YarnScheduler: Removed TaskSet 77.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,828 INFO scheduler.DAGScheduler: ResultStage 77 (treeReduce at KLLRunner.scala:107) finished in 0.046 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,828 INFO scheduler.DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,828 INFO cluster.YarnScheduler: Killing all running tasks in stage 77: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:01,829 INFO scheduler.DAGScheduler: Job 52 finished: treeReduce at KLLRunner.scala:107, took 0.049067 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,008 INFO storage.BlockManagerInfo: Removed broadcast_53_piece0 on 10.0.107.151:40635 in memory (size: 32.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,008 INFO storage.BlockManagerInfo: Removed broadcast_53_piece0 on algo-1:40133 in memory (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,018 INFO storage.BlockManagerInfo: Removed broadcast_62_piece0 on 10.0.107.151:40635 in memory (size: 20.7 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,019 INFO storage.BlockManagerInfo: Removed broadcast_62_piece0 on algo-1:40133 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,025 INFO storage.BlockManagerInfo: Removed broadcast_57_piece0 on 10.0.107.151:40635 in memory (size: 19.2 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,026 INFO storage.BlockManagerInfo: Removed broadcast_57_piece0 on algo-1:40133 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,034 INFO storage.BlockManagerInfo: Removed broadcast_60_piece0 on 10.0.107.151:40635 in memory (size: 32.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,035 INFO storage.BlockManagerInfo: Removed broadcast_60_piece0 on algo-1:40133 in memory (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,036 INFO scheduler.DAGScheduler: Registering RDD 314 (collect at AnalysisRunner.scala:326) as input to shuffle 25\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,037 INFO scheduler.DAGScheduler: Got map stage job 53 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,037 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 78 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,037 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,038 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,038 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 78 (MapPartitionsRDD[314] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,041 INFO memory.MemoryStore: Block broadcast_63 stored as values in memory (estimated size 90.7 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,043 INFO memory.MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,046 INFO storage.BlockManagerInfo: Removed broadcast_59_piece0 on 10.0.107.151:40635 in memory (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,048 INFO storage.BlockManagerInfo: Removed broadcast_59_piece0 on algo-1:40133 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,048 INFO storage.BlockManagerInfo: Added broadcast_63_piece0 in memory on 10.0.107.151:40635 (size: 27.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,051 INFO spark.SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,051 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 78 (MapPartitionsRDD[314] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,052 INFO cluster.YarnScheduler: Adding task set 78.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,056 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 78.0 (TID 61) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,064 INFO storage.BlockManagerInfo: Removed broadcast_58_piece0 on 10.0.107.151:40635 in memory (size: 18.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,078 INFO storage.BlockManagerInfo: Removed broadcast_58_piece0 on algo-1:40133 in memory (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,081 INFO storage.BlockManagerInfo: Added broadcast_63_piece0 in memory on algo-1:40133 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,091 INFO storage.BlockManagerInfo: Removed broadcast_61_piece0 on 10.0.107.151:40635 in memory (size: 50.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,092 INFO storage.BlockManagerInfo: Removed broadcast_61_piece0 on algo-1:40133 in memory (size: 50.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,094 INFO storage.BlockManagerInfo: Removed broadcast_55_piece0 on 10.0.107.151:40635 in memory (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,096 INFO storage.BlockManagerInfo: Removed broadcast_55_piece0 on algo-1:40133 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,099 INFO storage.BlockManagerInfo: Removed broadcast_54_piece0 on 10.0.107.151:40635 in memory (size: 50.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,100 INFO storage.BlockManagerInfo: Removed broadcast_54_piece0 on algo-1:40133 in memory (size: 50.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,103 INFO storage.BlockManagerInfo: Removed broadcast_52_piece0 on 10.0.107.151:40635 in memory (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,104 INFO storage.BlockManagerInfo: Removed broadcast_52_piece0 on algo-1:40133 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,106 INFO storage.BlockManagerInfo: Removed broadcast_56_piece0 on 10.0.107.151:40635 in memory (size: 27.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,107 INFO storage.BlockManagerInfo: Removed broadcast_56_piece0 on algo-1:40133 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,111 INFO storage.BlockManagerInfo: Removed broadcast_51_piece0 on 10.0.107.151:40635 in memory (size: 18.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,112 INFO storage.BlockManagerInfo: Removed broadcast_51_piece0 on algo-1:40133 in memory (size: 18.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,126 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 78.0 (TID 61) in 70 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,131 INFO cluster.YarnScheduler: Removed TaskSet 78.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,132 INFO scheduler.DAGScheduler: ShuffleMapStage 78 (collect at AnalysisRunner.scala:326) finished in 0.093 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,132 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,133 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,133 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,133 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,186 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,187 INFO scheduler.DAGScheduler: Got job 54 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,187 INFO scheduler.DAGScheduler: Final stage: ResultStage 80 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,187 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 79)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,187 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,187 INFO scheduler.DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[317] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,189 INFO memory.MemoryStore: Block broadcast_64 stored as values in memory (estimated size 66.2 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,192 INFO memory.MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,192 INFO storage.BlockManagerInfo: Added broadcast_64_piece0 in memory on 10.0.107.151:40635 (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,193 INFO spark.SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,193 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 80 (MapPartitionsRDD[317] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,193 INFO cluster.YarnScheduler: Adding task set 80.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,194 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 80.0 (TID 62) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,207 INFO storage.BlockManagerInfo: Added broadcast_64_piece0 in memory on algo-1:40133 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,212 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 25 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,223 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 80.0 (TID 62) in 29 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,223 INFO cluster.YarnScheduler: Removed TaskSet 80.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,224 INFO scheduler.DAGScheduler: ResultStage 80 (collect at AnalysisRunner.scala:326) finished in 0.036 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,224 INFO scheduler.DAGScheduler: Job 54 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,224 INFO cluster.YarnScheduler: Killing all running tasks in stage 80: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,225 INFO scheduler.DAGScheduler: Job 54 finished: collect at AnalysisRunner.scala:326, took 0.038897 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,283 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,284 INFO scheduler.DAGScheduler: Registering RDD 325 (countByKey at ColumnProfiler.scala:592) as input to shuffle 26\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,284 INFO scheduler.DAGScheduler: Got job 55 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,285 INFO scheduler.DAGScheduler: Final stage: ResultStage 82 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,285 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 81)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,285 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 81)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,285 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 81 (MapPartitionsRDD[325] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,289 INFO memory.MemoryStore: Block broadcast_65 stored as values in memory (estimated size 47.1 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,293 INFO memory.MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,295 INFO storage.BlockManagerInfo: Added broadcast_65_piece0 in memory on 10.0.107.151:40635 (size: 18.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,297 INFO spark.SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,297 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 81 (MapPartitionsRDD[325] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,297 INFO cluster.YarnScheduler: Adding task set 81.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,299 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 81.0 (TID 63) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,309 INFO storage.BlockManagerInfo: Added broadcast_65_piece0 in memory on algo-1:40133 (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,357 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 81.0 (TID 63) in 58 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,358 INFO cluster.YarnScheduler: Removed TaskSet 81.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,358 INFO scheduler.DAGScheduler: ShuffleMapStage 81 (countByKey at ColumnProfiler.scala:592) finished in 0.072 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,359 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,359 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,360 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 82)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,360 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,360 INFO scheduler.DAGScheduler: Submitting ResultStage 82 (ShuffledRDD[326] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,362 INFO memory.MemoryStore: Block broadcast_66 stored as values in memory (estimated size 5.1 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,363 INFO memory.MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,363 INFO storage.BlockManagerInfo: Added broadcast_66_piece0 in memory on 10.0.107.151:40635 (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,364 INFO spark.SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,364 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 82 (ShuffledRDD[326] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,364 INFO cluster.YarnScheduler: Adding task set 82.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,365 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 82.0 (TID 64) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,379 INFO storage.BlockManagerInfo: Added broadcast_66_piece0 in memory on algo-1:40133 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,383 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 26 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,396 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 82.0 (TID 64) in 31 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,396 INFO cluster.YarnScheduler: Removed TaskSet 82.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,399 INFO scheduler.DAGScheduler: ResultStage 82 (countByKey at ColumnProfiler.scala:592) finished in 0.038 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,399 INFO scheduler.DAGScheduler: Job 55 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,399 INFO cluster.YarnScheduler: Killing all running tasks in stage 82: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,399 INFO scheduler.DAGScheduler: Job 55 finished: countByKey at ColumnProfiler.scala:592, took 0.116403 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,582 INFO scheduler.DAGScheduler: Registering RDD 331 (collect at AnalysisRunner.scala:326) as input to shuffle 27\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,582 INFO scheduler.DAGScheduler: Got map stage job 56 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,582 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 83 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,582 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,582 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,583 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 83 (MapPartitionsRDD[331] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,586 INFO memory.MemoryStore: Block broadcast_67 stored as values in memory (estimated size 100.0 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,588 INFO memory.MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,588 INFO storage.BlockManagerInfo: Added broadcast_67_piece0 in memory on 10.0.107.151:40635 (size: 32.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,591 INFO spark.SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,592 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 83 (MapPartitionsRDD[331] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,592 INFO cluster.YarnScheduler: Adding task set 83.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,593 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 83.0 (TID 65) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,604 INFO storage.BlockManagerInfo: Added broadcast_67_piece0 in memory on algo-1:40133 (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,782 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 83.0 (TID 65) in 189 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,782 INFO cluster.YarnScheduler: Removed TaskSet 83.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,783 INFO scheduler.DAGScheduler: ShuffleMapStage 83 (collect at AnalysisRunner.scala:326) finished in 0.199 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,784 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,785 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,785 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,785 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,849 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,851 INFO scheduler.DAGScheduler: Got job 57 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,851 INFO scheduler.DAGScheduler: Final stage: ResultStage 85 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,851 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 84)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,851 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,851 INFO scheduler.DAGScheduler: Submitting ResultStage 85 (MapPartitionsRDD[334] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,864 INFO memory.MemoryStore: Block broadcast_68 stored as values in memory (estimated size 184.6 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,866 INFO memory.MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 50.2 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,868 INFO storage.BlockManagerInfo: Added broadcast_68_piece0 in memory on 10.0.107.151:40635 (size: 50.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,871 INFO spark.SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,871 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 85 (MapPartitionsRDD[334] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,871 INFO cluster.YarnScheduler: Adding task set 85.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,872 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 85.0 (TID 66) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,880 INFO storage.BlockManagerInfo: Added broadcast_68_piece0 in memory on algo-1:40133 (size: 50.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:02,899 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 27 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,160 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 85.0 (TID 66) in 288 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,161 INFO scheduler.DAGScheduler: ResultStage 85 (collect at AnalysisRunner.scala:326) finished in 0.308 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,162 INFO cluster.YarnScheduler: Removed TaskSet 85.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,162 INFO scheduler.DAGScheduler: Job 57 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,162 INFO cluster.YarnScheduler: Killing all running tasks in stage 85: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,163 INFO scheduler.DAGScheduler: Job 57 finished: collect at AnalysisRunner.scala:326, took 0.313003 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,277 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,278 INFO scheduler.DAGScheduler: Got job 58 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,278 INFO scheduler.DAGScheduler: Final stage: ResultStage 86 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,278 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,278 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,278 INFO scheduler.DAGScheduler: Submitting ResultStage 86 (MapPartitionsRDD[344] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,293 INFO memory.MemoryStore: Block broadcast_69 stored as values in memory (estimated size 54.8 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,295 INFO memory.MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,296 INFO storage.BlockManagerInfo: Added broadcast_69_piece0 in memory on 10.0.107.151:40635 (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,296 INFO spark.SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,299 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 86 (MapPartitionsRDD[344] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,299 INFO cluster.YarnScheduler: Adding task set 86.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,301 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 86.0 (TID 67) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,308 INFO storage.BlockManagerInfo: Added broadcast_69_piece0 in memory on algo-1:40133 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,336 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 86.0 (TID 67) in 36 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,336 INFO cluster.YarnScheduler: Removed TaskSet 86.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,337 INFO scheduler.DAGScheduler: ResultStage 86 (treeReduce at KLLRunner.scala:107) finished in 0.057 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,337 INFO scheduler.DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,337 INFO cluster.YarnScheduler: Killing all running tasks in stage 86: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,338 INFO scheduler.DAGScheduler: Job 58 finished: treeReduce at KLLRunner.scala:107, took 0.060754 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,540 INFO scheduler.DAGScheduler: Registering RDD 349 (collect at AnalysisRunner.scala:326) as input to shuffle 28\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,540 INFO scheduler.DAGScheduler: Got map stage job 59 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,540 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 87 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,540 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,541 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,542 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 87 (MapPartitionsRDD[349] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,545 INFO memory.MemoryStore: Block broadcast_70 stored as values in memory (estimated size 90.7 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,547 INFO memory.MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,547 INFO storage.BlockManagerInfo: Added broadcast_70_piece0 in memory on 10.0.107.151:40635 (size: 27.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,549 INFO spark.SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,549 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 87 (MapPartitionsRDD[349] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,549 INFO cluster.YarnScheduler: Adding task set 87.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,551 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 87.0 (TID 68) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,560 INFO storage.BlockManagerInfo: Added broadcast_70_piece0 in memory on algo-1:40133 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,581 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 87.0 (TID 68) in 31 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,582 INFO scheduler.DAGScheduler: ShuffleMapStage 87 (collect at AnalysisRunner.scala:326) finished in 0.038 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,582 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,583 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,583 INFO cluster.YarnScheduler: Removed TaskSet 87.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,583 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,583 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,658 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,663 INFO scheduler.DAGScheduler: Got job 60 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,663 INFO scheduler.DAGScheduler: Final stage: ResultStage 89 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,663 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 88)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,663 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,664 INFO scheduler.DAGScheduler: Submitting ResultStage 89 (MapPartitionsRDD[352] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,665 INFO memory.MemoryStore: Block broadcast_71 stored as values in memory (estimated size 66.2 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,667 INFO memory.MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,667 INFO storage.BlockManagerInfo: Added broadcast_71_piece0 in memory on 10.0.107.151:40635 (size: 19.2 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,668 INFO spark.SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,668 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 89 (MapPartitionsRDD[352] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,669 INFO cluster.YarnScheduler: Adding task set 89.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,670 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 89.0 (TID 69) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,677 INFO storage.BlockManagerInfo: Added broadcast_71_piece0 in memory on algo-1:40133 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,680 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 28 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,687 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 89.0 (TID 69) in 17 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,687 INFO cluster.YarnScheduler: Removed TaskSet 89.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,688 INFO scheduler.DAGScheduler: ResultStage 89 (collect at AnalysisRunner.scala:326) finished in 0.024 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,688 INFO scheduler.DAGScheduler: Job 60 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,688 INFO cluster.YarnScheduler: Killing all running tasks in stage 89: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,688 INFO scheduler.DAGScheduler: Job 60 finished: collect at AnalysisRunner.scala:326, took 0.026445 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,765 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,766 INFO scheduler.DAGScheduler: Registering RDD 360 (countByKey at ColumnProfiler.scala:592) as input to shuffle 29\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,767 INFO scheduler.DAGScheduler: Got job 61 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,767 INFO scheduler.DAGScheduler: Final stage: ResultStage 91 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,767 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 90)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,767 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 90)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,768 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 90 (MapPartitionsRDD[360] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,773 INFO memory.MemoryStore: Block broadcast_72 stored as values in memory (estimated size 47.1 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,774 INFO memory.MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,775 INFO storage.BlockManagerInfo: Added broadcast_72_piece0 in memory on 10.0.107.151:40635 (size: 18.8 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,775 INFO spark.SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,776 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 90 (MapPartitionsRDD[360] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,776 INFO cluster.YarnScheduler: Adding task set 90.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,777 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 90.0 (TID 70) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,786 INFO storage.BlockManagerInfo: Added broadcast_72_piece0 in memory on algo-1:40133 (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,812 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 90.0 (TID 70) in 35 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,812 INFO cluster.YarnScheduler: Removed TaskSet 90.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,813 INFO scheduler.DAGScheduler: ShuffleMapStage 90 (countByKey at ColumnProfiler.scala:592) finished in 0.044 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,814 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,814 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,814 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 91)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,815 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,815 INFO scheduler.DAGScheduler: Submitting ResultStage 91 (ShuffledRDD[361] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,819 INFO memory.MemoryStore: Block broadcast_73 stored as values in memory (estimated size 5.1 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,821 INFO memory.MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,822 INFO storage.BlockManagerInfo: Added broadcast_73_piece0 in memory on 10.0.107.151:40635 (size: 3.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,824 INFO spark.SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,824 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 91 (ShuffledRDD[361] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,824 INFO cluster.YarnScheduler: Adding task set 91.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,825 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 91.0 (TID 71) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,838 INFO storage.BlockManagerInfo: Added broadcast_73_piece0 in memory on algo-1:40133 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,845 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,870 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 91.0 (TID 71) in 45 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,870 INFO cluster.YarnScheduler: Removed TaskSet 91.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,871 INFO scheduler.DAGScheduler: ResultStage 91 (countByKey at ColumnProfiler.scala:592) finished in 0.054 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,872 INFO scheduler.DAGScheduler: Job 61 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,872 INFO cluster.YarnScheduler: Killing all running tasks in stage 91: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:03,873 INFO scheduler.DAGScheduler: Job 61 finished: countByKey at ColumnProfiler.scala:592, took 0.107097 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,006 INFO scheduler.DAGScheduler: Registering RDD 366 (collect at AnalysisRunner.scala:326) as input to shuffle 30\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,007 INFO scheduler.DAGScheduler: Got map stage job 62 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,007 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 92 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,007 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,008 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,008 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 92 (MapPartitionsRDD[366] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,013 INFO memory.MemoryStore: Block broadcast_74 stored as values in memory (estimated size 100.0 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,015 INFO memory.MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,016 INFO storage.BlockManagerInfo: Added broadcast_74_piece0 in memory on 10.0.107.151:40635 (size: 32.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,016 INFO spark.SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,017 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 92 (MapPartitionsRDD[366] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,018 INFO cluster.YarnScheduler: Adding task set 92.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,019 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 92.0 (TID 72) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,028 INFO storage.BlockManagerInfo: Added broadcast_74_piece0 in memory on algo-1:40133 (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,198 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 92.0 (TID 72) in 179 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,198 INFO cluster.YarnScheduler: Removed TaskSet 92.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,199 INFO scheduler.DAGScheduler: ShuffleMapStage 92 (collect at AnalysisRunner.scala:326) finished in 0.189 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,200 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,200 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,201 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,201 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,265 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,266 INFO scheduler.DAGScheduler: Got job 63 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,266 INFO scheduler.DAGScheduler: Final stage: ResultStage 94 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,266 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 93)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,266 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,266 INFO scheduler.DAGScheduler: Submitting ResultStage 94 (MapPartitionsRDD[369] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,277 INFO memory.MemoryStore: Block broadcast_75 stored as values in memory (estimated size 184.6 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,283 INFO memory.MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 50.2 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,283 INFO storage.BlockManagerInfo: Added broadcast_75_piece0 in memory on 10.0.107.151:40635 (size: 50.2 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,284 INFO spark.SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,284 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 94 (MapPartitionsRDD[369] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,284 INFO cluster.YarnScheduler: Adding task set 94.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,285 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 94.0 (TID 73) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,294 INFO storage.BlockManagerInfo: Added broadcast_75_piece0 in memory on algo-1:40133 (size: 50.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,305 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 30 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,420 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 94.0 (TID 73) in 135 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,421 INFO cluster.YarnScheduler: Removed TaskSet 94.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,421 INFO scheduler.DAGScheduler: ResultStage 94 (collect at AnalysisRunner.scala:326) finished in 0.154 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,422 INFO scheduler.DAGScheduler: Job 63 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,422 INFO cluster.YarnScheduler: Killing all running tasks in stage 94: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,422 INFO scheduler.DAGScheduler: Job 63 finished: collect at AnalysisRunner.scala:326, took 0.156907 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,525 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,526 INFO scheduler.DAGScheduler: Got job 64 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,526 INFO scheduler.DAGScheduler: Final stage: ResultStage 95 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,526 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,527 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,527 INFO scheduler.DAGScheduler: Submitting ResultStage 95 (MapPartitionsRDD[379] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,531 INFO memory.MemoryStore: Block broadcast_76 stored as values in memory (estimated size 54.8 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,533 INFO memory.MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1456.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,534 INFO storage.BlockManagerInfo: Added broadcast_76_piece0 in memory on 10.0.107.151:40635 (size: 20.7 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,534 INFO spark.SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,534 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 95 (MapPartitionsRDD[379] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,534 INFO cluster.YarnScheduler: Adding task set 95.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,535 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 95.0 (TID 74) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,542 INFO storage.BlockManagerInfo: Added broadcast_76_piece0 in memory on algo-1:40133 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,567 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 95.0 (TID 74) in 32 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,568 INFO cluster.YarnScheduler: Removed TaskSet 95.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,568 INFO scheduler.DAGScheduler: ResultStage 95 (treeReduce at KLLRunner.scala:107) finished in 0.040 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,569 INFO scheduler.DAGScheduler: Job 64 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,569 INFO cluster.YarnScheduler: Killing all running tasks in stage 95: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,569 INFO scheduler.DAGScheduler: Job 64 finished: treeReduce at KLLRunner.scala:107, took 0.044153 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,727 INFO storage.BlockManagerInfo: Removed broadcast_65_piece0 on 10.0.107.151:40635 in memory (size: 18.8 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,728 INFO storage.BlockManagerInfo: Removed broadcast_65_piece0 on algo-1:40133 in memory (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,731 INFO storage.BlockManagerInfo: Removed broadcast_71_piece0 on algo-1:40133 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,733 INFO storage.BlockManagerInfo: Removed broadcast_71_piece0 on 10.0.107.151:40635 in memory (size: 19.2 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,736 INFO storage.BlockManagerInfo: Removed broadcast_75_piece0 on 10.0.107.151:40635 in memory (size: 50.2 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,747 INFO storage.BlockManagerInfo: Removed broadcast_75_piece0 on algo-1:40133 in memory (size: 50.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,751 INFO storage.BlockManagerInfo: Removed broadcast_69_piece0 on 10.0.107.151:40635 in memory (size: 20.7 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,752 INFO storage.BlockManagerInfo: Removed broadcast_69_piece0 on algo-1:40133 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,755 INFO storage.BlockManagerInfo: Removed broadcast_74_piece0 on 10.0.107.151:40635 in memory (size: 32.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,755 INFO storage.BlockManagerInfo: Removed broadcast_74_piece0 on algo-1:40133 in memory (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,757 INFO storage.BlockManagerInfo: Removed broadcast_73_piece0 on 10.0.107.151:40635 in memory (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,758 INFO storage.BlockManagerInfo: Removed broadcast_73_piece0 on algo-1:40133 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,760 INFO storage.BlockManagerInfo: Removed broadcast_66_piece0 on 10.0.107.151:40635 in memory (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,765 INFO storage.BlockManagerInfo: Removed broadcast_66_piece0 on algo-1:40133 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,767 INFO storage.BlockManagerInfo: Removed broadcast_76_piece0 on 10.0.107.151:40635 in memory (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,768 INFO storage.BlockManagerInfo: Removed broadcast_76_piece0 on algo-1:40133 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,771 INFO storage.BlockManagerInfo: Removed broadcast_67_piece0 on 10.0.107.151:40635 in memory (size: 32.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,771 INFO storage.BlockManagerInfo: Removed broadcast_67_piece0 on algo-1:40133 in memory (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,774 INFO storage.BlockManagerInfo: Removed broadcast_72_piece0 on 10.0.107.151:40635 in memory (size: 18.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,774 INFO storage.BlockManagerInfo: Removed broadcast_72_piece0 on algo-1:40133 in memory (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,776 INFO storage.BlockManagerInfo: Removed broadcast_64_piece0 on 10.0.107.151:40635 in memory (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,777 INFO storage.BlockManagerInfo: Removed broadcast_64_piece0 on algo-1:40133 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,798 INFO storage.BlockManagerInfo: Removed broadcast_70_piece0 on 10.0.107.151:40635 in memory (size: 27.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,798 INFO storage.BlockManagerInfo: Removed broadcast_70_piece0 on algo-1:40133 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,804 INFO storage.BlockManagerInfo: Removed broadcast_63_piece0 on 10.0.107.151:40635 in memory (size: 27.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,805 INFO storage.BlockManagerInfo: Removed broadcast_63_piece0 on algo-1:40133 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,807 INFO storage.BlockManagerInfo: Removed broadcast_68_piece0 on 10.0.107.151:40635 in memory (size: 50.2 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,808 INFO storage.BlockManagerInfo: Removed broadcast_68_piece0 on algo-1:40133 in memory (size: 50.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,834 INFO scheduler.DAGScheduler: Registering RDD 384 (collect at AnalysisRunner.scala:326) as input to shuffle 31\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,835 INFO scheduler.DAGScheduler: Got map stage job 65 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,835 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 96 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,835 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,836 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,836 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 96 (MapPartitionsRDD[384] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,838 INFO memory.MemoryStore: Block broadcast_77 stored as values in memory (estimated size 90.7 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,840 INFO memory.MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,840 INFO storage.BlockManagerInfo: Added broadcast_77_piece0 in memory on 10.0.107.151:40635 (size: 27.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,841 INFO spark.SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,841 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 96 (MapPartitionsRDD[384] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,842 INFO cluster.YarnScheduler: Adding task set 96.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,843 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 96.0 (TID 75) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,854 INFO storage.BlockManagerInfo: Added broadcast_77_piece0 in memory on algo-1:40133 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,885 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 96.0 (TID 75) in 43 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,885 INFO cluster.YarnScheduler: Removed TaskSet 96.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,886 INFO scheduler.DAGScheduler: ShuffleMapStage 96 (collect at AnalysisRunner.scala:326) finished in 0.049 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,887 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,887 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,887 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,888 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,935 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,935 INFO scheduler.DAGScheduler: Got job 66 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,936 INFO scheduler.DAGScheduler: Final stage: ResultStage 98 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,936 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 97)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,936 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,936 INFO scheduler.DAGScheduler: Submitting ResultStage 98 (MapPartitionsRDD[387] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,939 INFO memory.MemoryStore: Block broadcast_78 stored as values in memory (estimated size 66.2 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,940 INFO memory.MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,941 INFO storage.BlockManagerInfo: Added broadcast_78_piece0 in memory on 10.0.107.151:40635 (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,941 INFO spark.SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,942 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 98 (MapPartitionsRDD[387] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,942 INFO cluster.YarnScheduler: Adding task set 98.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,943 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 98.0 (TID 76) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,951 INFO storage.BlockManagerInfo: Added broadcast_78_piece0 in memory on algo-1:40133 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,955 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,961 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 98.0 (TID 76) in 18 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,961 INFO cluster.YarnScheduler: Removed TaskSet 98.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,962 INFO scheduler.DAGScheduler: ResultStage 98 (collect at AnalysisRunner.scala:326) finished in 0.024 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,962 INFO scheduler.DAGScheduler: Job 66 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,963 INFO cluster.YarnScheduler: Killing all running tasks in stage 98: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:04,963 INFO scheduler.DAGScheduler: Job 66 finished: collect at AnalysisRunner.scala:326, took 0.028042 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,071 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,077 INFO scheduler.DAGScheduler: Registering RDD 395 (countByKey at ColumnProfiler.scala:592) as input to shuffle 32\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,077 INFO scheduler.DAGScheduler: Got job 67 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,077 INFO scheduler.DAGScheduler: Final stage: ResultStage 100 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,078 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 99)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,078 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 99)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,079 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 99 (MapPartitionsRDD[395] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,083 INFO memory.MemoryStore: Block broadcast_79 stored as values in memory (estimated size 47.1 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,085 INFO memory.MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,085 INFO storage.BlockManagerInfo: Added broadcast_79_piece0 in memory on 10.0.107.151:40635 (size: 18.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,086 INFO spark.SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,086 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 99 (MapPartitionsRDD[395] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,086 INFO cluster.YarnScheduler: Adding task set 99.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,087 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 99.0 (TID 77) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,094 INFO storage.BlockManagerInfo: Added broadcast_79_piece0 in memory on algo-1:40133 (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,141 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 99.0 (TID 77) in 54 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,141 INFO cluster.YarnScheduler: Removed TaskSet 99.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,142 INFO scheduler.DAGScheduler: ShuffleMapStage 99 (countByKey at ColumnProfiler.scala:592) finished in 0.062 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,143 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,144 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,145 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 100)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,145 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,145 INFO scheduler.DAGScheduler: Submitting ResultStage 100 (ShuffledRDD[396] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,147 INFO memory.MemoryStore: Block broadcast_80 stored as values in memory (estimated size 5.1 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,148 INFO memory.MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,149 INFO storage.BlockManagerInfo: Added broadcast_80_piece0 in memory on 10.0.107.151:40635 (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,149 INFO spark.SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,150 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 100 (ShuffledRDD[396] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,150 INFO cluster.YarnScheduler: Adding task set 100.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,151 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 100.0 (TID 78) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,161 INFO storage.BlockManagerInfo: Added broadcast_80_piece0 in memory on algo-1:40133 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,165 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,182 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 100.0 (TID 78) in 31 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,183 INFO cluster.YarnScheduler: Removed TaskSet 100.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,183 INFO scheduler.DAGScheduler: ResultStage 100 (countByKey at ColumnProfiler.scala:592) finished in 0.037 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,185 INFO scheduler.DAGScheduler: Job 67 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,185 INFO cluster.YarnScheduler: Killing all running tasks in stage 100: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,185 INFO scheduler.DAGScheduler: Job 67 finished: countByKey at ColumnProfiler.scala:592, took 0.109440 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,422 INFO scheduler.DAGScheduler: Registering RDD 401 (collect at AnalysisRunner.scala:326) as input to shuffle 33\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,422 INFO scheduler.DAGScheduler: Got map stage job 68 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,422 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 101 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,422 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,423 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,423 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 101 (MapPartitionsRDD[401] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,427 INFO memory.MemoryStore: Block broadcast_81 stored as values in memory (estimated size 100.0 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,429 INFO memory.MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 33.0 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,430 INFO storage.BlockManagerInfo: Added broadcast_81_piece0 in memory on 10.0.107.151:40635 (size: 33.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,432 INFO spark.SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,433 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 101 (MapPartitionsRDD[401] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,433 INFO cluster.YarnScheduler: Adding task set 101.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,434 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 101.0 (TID 79) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,445 INFO storage.BlockManagerInfo: Added broadcast_81_piece0 in memory on algo-1:40133 (size: 33.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,602 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 101.0 (TID 79) in 168 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,602 INFO cluster.YarnScheduler: Removed TaskSet 101.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,603 INFO scheduler.DAGScheduler: ShuffleMapStage 101 (collect at AnalysisRunner.scala:326) finished in 0.178 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,603 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,604 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,604 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,604 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,638 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,639 INFO scheduler.DAGScheduler: Got job 69 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,640 INFO scheduler.DAGScheduler: Final stage: ResultStage 103 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,640 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 102)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,640 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,640 INFO scheduler.DAGScheduler: Submitting ResultStage 103 (MapPartitionsRDD[404] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,648 INFO memory.MemoryStore: Block broadcast_82 stored as values in memory (estimated size 184.6 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,650 INFO memory.MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,651 INFO storage.BlockManagerInfo: Added broadcast_82_piece0 in memory on 10.0.107.151:40635 (size: 50.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,651 INFO spark.SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,652 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 103 (MapPartitionsRDD[404] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,652 INFO cluster.YarnScheduler: Adding task set 103.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,653 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 103.0 (TID 80) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,663 INFO storage.BlockManagerInfo: Added broadcast_82_piece0 in memory on algo-1:40133 (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,675 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,849 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 103.0 (TID 80) in 196 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,849 INFO cluster.YarnScheduler: Removed TaskSet 103.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,850 INFO scheduler.DAGScheduler: ResultStage 103 (collect at AnalysisRunner.scala:326) finished in 0.208 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,852 INFO scheduler.DAGScheduler: Job 69 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,852 INFO cluster.YarnScheduler: Killing all running tasks in stage 103: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:05,853 INFO scheduler.DAGScheduler: Job 69 finished: collect at AnalysisRunner.scala:326, took 0.214072 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,048 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,048 INFO scheduler.DAGScheduler: Got job 70 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,049 INFO scheduler.DAGScheduler: Final stage: ResultStage 104 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,049 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,049 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,050 INFO scheduler.DAGScheduler: Submitting ResultStage 104 (MapPartitionsRDD[414] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,054 INFO memory.MemoryStore: Block broadcast_83 stored as values in memory (estimated size 54.8 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,056 INFO memory.MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,056 INFO storage.BlockManagerInfo: Added broadcast_83_piece0 in memory on 10.0.107.151:40635 (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,057 INFO spark.SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,057 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 104 (MapPartitionsRDD[414] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,057 INFO cluster.YarnScheduler: Adding task set 104.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,058 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 104.0 (TID 81) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,068 INFO storage.BlockManagerInfo: Added broadcast_83_piece0 in memory on algo-1:40133 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,097 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 104.0 (TID 81) in 39 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,099 INFO cluster.YarnScheduler: Removed TaskSet 104.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,100 INFO scheduler.DAGScheduler: ResultStage 104 (treeReduce at KLLRunner.scala:107) finished in 0.049 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,100 INFO scheduler.DAGScheduler: Job 70 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,100 INFO cluster.YarnScheduler: Killing all running tasks in stage 104: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,101 INFO scheduler.DAGScheduler: Job 70 finished: treeReduce at KLLRunner.scala:107, took 0.053007 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,229 INFO scheduler.DAGScheduler: Registering RDD 419 (collect at AnalysisRunner.scala:326) as input to shuffle 34\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,230 INFO scheduler.DAGScheduler: Got map stage job 71 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,230 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 105 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,230 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,231 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,231 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 105 (MapPartitionsRDD[419] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,234 INFO memory.MemoryStore: Block broadcast_84 stored as values in memory (estimated size 90.7 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,236 INFO memory.MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,236 INFO storage.BlockManagerInfo: Added broadcast_84_piece0 in memory on 10.0.107.151:40635 (size: 27.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,237 INFO spark.SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,237 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 105 (MapPartitionsRDD[419] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,238 INFO cluster.YarnScheduler: Adding task set 105.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,239 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 105.0 (TID 82) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,246 INFO storage.BlockManagerInfo: Added broadcast_84_piece0 in memory on algo-1:40133 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,261 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 105.0 (TID 82) in 23 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,261 INFO cluster.YarnScheduler: Removed TaskSet 105.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,262 INFO scheduler.DAGScheduler: ShuffleMapStage 105 (collect at AnalysisRunner.scala:326) finished in 0.030 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,262 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,262 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,262 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,262 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,300 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,300 INFO scheduler.DAGScheduler: Got job 72 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,301 INFO scheduler.DAGScheduler: Final stage: ResultStage 107 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,301 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 106)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,301 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,302 INFO scheduler.DAGScheduler: Submitting ResultStage 107 (MapPartitionsRDD[422] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,303 INFO memory.MemoryStore: Block broadcast_85 stored as values in memory (estimated size 66.2 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,305 INFO memory.MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,305 INFO storage.BlockManagerInfo: Added broadcast_85_piece0 in memory on 10.0.107.151:40635 (size: 19.2 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,306 INFO spark.SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,306 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 107 (MapPartitionsRDD[422] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,306 INFO cluster.YarnScheduler: Adding task set 107.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,307 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 107.0 (TID 83) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,316 INFO storage.BlockManagerInfo: Added broadcast_85_piece0 in memory on algo-1:40133 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,320 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,326 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 107.0 (TID 83) in 19 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,326 INFO cluster.YarnScheduler: Removed TaskSet 107.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,327 INFO scheduler.DAGScheduler: ResultStage 107 (collect at AnalysisRunner.scala:326) finished in 0.025 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,327 INFO scheduler.DAGScheduler: Job 72 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,327 INFO cluster.YarnScheduler: Killing all running tasks in stage 107: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,328 INFO scheduler.DAGScheduler: Job 72 finished: collect at AnalysisRunner.scala:326, took 0.027626 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,398 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,399 INFO scheduler.DAGScheduler: Registering RDD 430 (countByKey at ColumnProfiler.scala:592) as input to shuffle 35\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,400 INFO scheduler.DAGScheduler: Got job 73 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,400 INFO scheduler.DAGScheduler: Final stage: ResultStage 109 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,400 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 108)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,400 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 108)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,402 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 108 (MapPartitionsRDD[430] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,406 INFO memory.MemoryStore: Block broadcast_86 stored as values in memory (estimated size 47.1 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,407 INFO memory.MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,407 INFO storage.BlockManagerInfo: Added broadcast_86_piece0 in memory on 10.0.107.151:40635 (size: 18.8 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,407 INFO spark.SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,408 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 108 (MapPartitionsRDD[430] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,408 INFO cluster.YarnScheduler: Adding task set 108.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,409 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 108.0 (TID 84) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,417 INFO storage.BlockManagerInfo: Added broadcast_86_piece0 in memory on algo-1:40133 (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,467 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 108.0 (TID 84) in 59 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,467 INFO cluster.YarnScheduler: Removed TaskSet 108.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,468 INFO scheduler.DAGScheduler: ShuffleMapStage 108 (countByKey at ColumnProfiler.scala:592) finished in 0.065 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,469 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,469 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,470 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 109)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,470 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,470 INFO scheduler.DAGScheduler: Submitting ResultStage 109 (ShuffledRDD[431] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,471 INFO memory.MemoryStore: Block broadcast_87 stored as values in memory (estimated size 5.1 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,473 INFO memory.MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,473 INFO storage.BlockManagerInfo: Added broadcast_87_piece0 in memory on 10.0.107.151:40635 (size: 3.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,474 INFO spark.SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,474 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 109 (ShuffledRDD[431] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,475 INFO cluster.YarnScheduler: Adding task set 109.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,476 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 109.0 (TID 85) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,484 INFO storage.BlockManagerInfo: Added broadcast_87_piece0 in memory on algo-1:40133 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,486 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,494 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 109.0 (TID 85) in 19 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,494 INFO cluster.YarnScheduler: Removed TaskSet 109.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,495 INFO scheduler.DAGScheduler: ResultStage 109 (countByKey at ColumnProfiler.scala:592) finished in 0.024 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,496 INFO scheduler.DAGScheduler: Job 73 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,496 INFO cluster.YarnScheduler: Killing all running tasks in stage 109: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,497 INFO scheduler.DAGScheduler: Job 73 finished: countByKey at ColumnProfiler.scala:592, took 0.098878 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,580 INFO scheduler.DAGScheduler: Registering RDD 436 (collect at AnalysisRunner.scala:326) as input to shuffle 36\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,580 INFO scheduler.DAGScheduler: Got map stage job 74 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,580 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 110 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,580 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,581 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,581 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 110 (MapPartitionsRDD[436] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,585 INFO memory.MemoryStore: Block broadcast_88 stored as values in memory (estimated size 100.0 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,587 INFO memory.MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,587 INFO storage.BlockManagerInfo: Added broadcast_88_piece0 in memory on 10.0.107.151:40635 (size: 32.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,590 INFO spark.SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,591 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 110 (MapPartitionsRDD[436] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,591 INFO cluster.YarnScheduler: Adding task set 110.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,592 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 110.0 (TID 86) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:06,599 INFO storage.BlockManagerInfo: Added broadcast_88_piece0 in memory on algo-1:40133 (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,025 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 110.0 (TID 86) in 433 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,026 INFO cluster.YarnScheduler: Removed TaskSet 110.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,027 INFO scheduler.DAGScheduler: ShuffleMapStage 110 (collect at AnalysisRunner.scala:326) finished in 0.445 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,027 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,027 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,027 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,027 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,071 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,072 INFO scheduler.DAGScheduler: Got job 75 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,072 INFO scheduler.DAGScheduler: Final stage: ResultStage 112 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,072 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 111)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,072 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,072 INFO scheduler.DAGScheduler: Submitting ResultStage 112 (MapPartitionsRDD[439] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,079 INFO memory.MemoryStore: Block broadcast_89 stored as values in memory (estimated size 184.6 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,081 INFO memory.MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,081 INFO storage.BlockManagerInfo: Added broadcast_89_piece0 in memory on 10.0.107.151:40635 (size: 50.3 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,082 INFO spark.SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,082 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 112 (MapPartitionsRDD[439] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,082 INFO cluster.YarnScheduler: Adding task set 112.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,083 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 112.0 (TID 87) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,095 INFO storage.BlockManagerInfo: Added broadcast_89_piece0 in memory on algo-1:40133 (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,134 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,322 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 112.0 (TID 87) in 239 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,322 INFO cluster.YarnScheduler: Removed TaskSet 112.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,322 INFO scheduler.DAGScheduler: ResultStage 112 (collect at AnalysisRunner.scala:326) finished in 0.249 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,323 INFO scheduler.DAGScheduler: Job 75 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,323 INFO cluster.YarnScheduler: Killing all running tasks in stage 112: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,324 INFO scheduler.DAGScheduler: Job 75 finished: collect at AnalysisRunner.scala:326, took 0.252481 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,435 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,436 INFO scheduler.DAGScheduler: Got job 76 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,436 INFO scheduler.DAGScheduler: Final stage: ResultStage 113 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,436 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,436 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,437 INFO scheduler.DAGScheduler: Submitting ResultStage 113 (MapPartitionsRDD[449] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,442 INFO memory.MemoryStore: Block broadcast_90 stored as values in memory (estimated size 54.8 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,444 INFO memory.MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 20.8 KiB, free 1456.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,444 INFO storage.BlockManagerInfo: Added broadcast_90_piece0 in memory on 10.0.107.151:40635 (size: 20.8 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,445 INFO spark.SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,445 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 113 (MapPartitionsRDD[449] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,445 INFO cluster.YarnScheduler: Adding task set 113.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,446 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 113.0 (TID 88) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,456 INFO storage.BlockManagerInfo: Added broadcast_90_piece0 in memory on algo-1:40133 (size: 20.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,499 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 113.0 (TID 88) in 53 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,499 INFO cluster.YarnScheduler: Removed TaskSet 113.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,499 INFO scheduler.DAGScheduler: ResultStage 113 (treeReduce at KLLRunner.scala:107) finished in 0.061 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,500 INFO scheduler.DAGScheduler: Job 76 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,500 INFO cluster.YarnScheduler: Killing all running tasks in stage 113: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,501 INFO scheduler.DAGScheduler: Job 76 finished: treeReduce at KLLRunner.scala:107, took 0.065132 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,624 INFO storage.BlockManagerInfo: Removed broadcast_87_piece0 on 10.0.107.151:40635 in memory (size: 3.0 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,625 INFO storage.BlockManagerInfo: Removed broadcast_87_piece0 on algo-1:40133 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,630 INFO storage.BlockManagerInfo: Removed broadcast_85_piece0 on 10.0.107.151:40635 in memory (size: 19.2 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,630 INFO storage.BlockManagerInfo: Removed broadcast_85_piece0 on algo-1:40133 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,637 INFO storage.BlockManagerInfo: Removed broadcast_83_piece0 on 10.0.107.151:40635 in memory (size: 20.7 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,638 INFO storage.BlockManagerInfo: Removed broadcast_83_piece0 on algo-1:40133 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,645 INFO storage.BlockManagerInfo: Removed broadcast_88_piece0 on 10.0.107.151:40635 in memory (size: 32.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,646 INFO storage.BlockManagerInfo: Removed broadcast_88_piece0 on algo-1:40133 in memory (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,648 INFO storage.BlockManagerInfo: Removed broadcast_89_piece0 on 10.0.107.151:40635 in memory (size: 50.3 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,649 INFO storage.BlockManagerInfo: Removed broadcast_89_piece0 on algo-1:40133 in memory (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,653 INFO storage.BlockManagerInfo: Removed broadcast_81_piece0 on algo-1:40133 in memory (size: 33.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,653 INFO storage.BlockManagerInfo: Removed broadcast_81_piece0 on 10.0.107.151:40635 in memory (size: 33.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,657 INFO storage.BlockManagerInfo: Removed broadcast_78_piece0 on algo-1:40133 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,658 INFO storage.BlockManagerInfo: Removed broadcast_78_piece0 on 10.0.107.151:40635 in memory (size: 19.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,661 INFO storage.BlockManagerInfo: Removed broadcast_86_piece0 on 10.0.107.151:40635 in memory (size: 18.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,661 INFO storage.BlockManagerInfo: Removed broadcast_86_piece0 on algo-1:40133 in memory (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,666 INFO storage.BlockManagerInfo: Removed broadcast_79_piece0 on algo-1:40133 in memory (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,667 INFO storage.BlockManagerInfo: Removed broadcast_79_piece0 on 10.0.107.151:40635 in memory (size: 18.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,673 INFO storage.BlockManagerInfo: Removed broadcast_90_piece0 on algo-1:40133 in memory (size: 20.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,674 INFO storage.BlockManagerInfo: Removed broadcast_90_piece0 on 10.0.107.151:40635 in memory (size: 20.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,686 INFO storage.BlockManagerInfo: Removed broadcast_84_piece0 on algo-1:40133 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,686 INFO storage.BlockManagerInfo: Removed broadcast_84_piece0 on 10.0.107.151:40635 in memory (size: 27.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,689 INFO storage.BlockManagerInfo: Removed broadcast_82_piece0 on 10.0.107.151:40635 in memory (size: 50.3 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,689 INFO storage.BlockManagerInfo: Removed broadcast_82_piece0 on algo-1:40133 in memory (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,691 INFO storage.BlockManagerInfo: Removed broadcast_77_piece0 on 10.0.107.151:40635 in memory (size: 27.9 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,692 INFO storage.BlockManagerInfo: Removed broadcast_77_piece0 on algo-1:40133 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,694 INFO storage.BlockManagerInfo: Removed broadcast_80_piece0 on 10.0.107.151:40635 in memory (size: 3.0 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,695 INFO storage.BlockManagerInfo: Removed broadcast_80_piece0 on algo-1:40133 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,759 INFO scheduler.DAGScheduler: Registering RDD 454 (collect at AnalysisRunner.scala:326) as input to shuffle 37\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,759 INFO scheduler.DAGScheduler: Got map stage job 77 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,759 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 114 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,759 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,760 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,761 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 114 (MapPartitionsRDD[454] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,764 INFO memory.MemoryStore: Block broadcast_91 stored as values in memory (estimated size 90.7 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,766 INFO memory.MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,766 INFO storage.BlockManagerInfo: Added broadcast_91_piece0 in memory on 10.0.107.151:40635 (size: 27.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,766 INFO spark.SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,767 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 114 (MapPartitionsRDD[454] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,767 INFO cluster.YarnScheduler: Adding task set 114.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,768 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 114.0 (TID 89) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,776 INFO storage.BlockManagerInfo: Added broadcast_91_piece0 in memory on algo-1:40133 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,790 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 114.0 (TID 89) in 22 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,790 INFO cluster.YarnScheduler: Removed TaskSet 114.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,792 INFO scheduler.DAGScheduler: ShuffleMapStage 114 (collect at AnalysisRunner.scala:326) finished in 0.030 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,793 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,793 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,793 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,793 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,832 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,833 INFO scheduler.DAGScheduler: Got job 78 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,833 INFO scheduler.DAGScheduler: Final stage: ResultStage 116 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,833 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 115)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,833 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,834 INFO scheduler.DAGScheduler: Submitting ResultStage 116 (MapPartitionsRDD[457] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,835 INFO memory.MemoryStore: Block broadcast_92 stored as values in memory (estimated size 66.2 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,837 INFO memory.MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,838 INFO storage.BlockManagerInfo: Added broadcast_92_piece0 in memory on 10.0.107.151:40635 (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,838 INFO spark.SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,838 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 116 (MapPartitionsRDD[457] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,839 INFO cluster.YarnScheduler: Adding task set 116.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,839 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 116.0 (TID 90) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,847 INFO storage.BlockManagerInfo: Added broadcast_92_piece0 in memory on algo-1:40133 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,851 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,863 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 116.0 (TID 90) in 24 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,863 INFO cluster.YarnScheduler: Removed TaskSet 116.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,864 INFO scheduler.DAGScheduler: ResultStage 116 (collect at AnalysisRunner.scala:326) finished in 0.029 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,864 INFO scheduler.DAGScheduler: Job 78 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,864 INFO cluster.YarnScheduler: Killing all running tasks in stage 116: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,864 INFO scheduler.DAGScheduler: Job 78 finished: collect at AnalysisRunner.scala:326, took 0.031661 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,907 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,908 INFO scheduler.DAGScheduler: Registering RDD 465 (countByKey at ColumnProfiler.scala:592) as input to shuffle 38\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,908 INFO scheduler.DAGScheduler: Got job 79 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,908 INFO scheduler.DAGScheduler: Final stage: ResultStage 118 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,909 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 117)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,909 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 117)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,910 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 117 (MapPartitionsRDD[465] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,914 INFO memory.MemoryStore: Block broadcast_93 stored as values in memory (estimated size 47.1 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,915 INFO memory.MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,916 INFO storage.BlockManagerInfo: Added broadcast_93_piece0 in memory on 10.0.107.151:40635 (size: 18.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,916 INFO spark.SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,917 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 117 (MapPartitionsRDD[465] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,917 INFO cluster.YarnScheduler: Adding task set 117.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,918 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 117.0 (TID 91) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,924 INFO storage.BlockManagerInfo: Added broadcast_93_piece0 in memory on algo-1:40133 (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,965 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 117.0 (TID 91) in 47 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,966 INFO cluster.YarnScheduler: Removed TaskSet 117.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,966 INFO scheduler.DAGScheduler: ShuffleMapStage 117 (countByKey at ColumnProfiler.scala:592) finished in 0.055 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,966 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,967 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,967 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 118)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,967 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,967 INFO scheduler.DAGScheduler: Submitting ResultStage 118 (ShuffledRDD[466] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,968 INFO memory.MemoryStore: Block broadcast_94 stored as values in memory (estimated size 5.1 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,970 INFO memory.MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,970 INFO storage.BlockManagerInfo: Added broadcast_94_piece0 in memory on 10.0.107.151:40635 (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,971 INFO spark.SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,971 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 118 (ShuffledRDD[466] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,971 INFO cluster.YarnScheduler: Adding task set 118.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,972 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 118.0 (TID 92) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,978 INFO storage.BlockManagerInfo: Added broadcast_94_piece0 in memory on algo-1:40133 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,981 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,996 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 118.0 (TID 92) in 24 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,997 INFO scheduler.DAGScheduler: ResultStage 118 (countByKey at ColumnProfiler.scala:592) finished in 0.029 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,997 INFO scheduler.DAGScheduler: Job 79 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,997 INFO cluster.YarnScheduler: Removed TaskSet 118.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,998 INFO cluster.YarnScheduler: Killing all running tasks in stage 118: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:07,999 INFO scheduler.DAGScheduler: Job 79 finished: countByKey at ColumnProfiler.scala:592, took 0.091439 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,159 INFO scheduler.DAGScheduler: Registering RDD 471 (collect at AnalysisRunner.scala:326) as input to shuffle 39\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,160 INFO scheduler.DAGScheduler: Got map stage job 80 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,160 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 119 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,160 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,161 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,161 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 119 (MapPartitionsRDD[471] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,165 INFO memory.MemoryStore: Block broadcast_95 stored as values in memory (estimated size 100.0 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,167 INFO memory.MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 32.8 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,167 INFO storage.BlockManagerInfo: Added broadcast_95_piece0 in memory on 10.0.107.151:40635 (size: 32.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,168 INFO spark.SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,169 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 119 (MapPartitionsRDD[471] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,169 INFO cluster.YarnScheduler: Adding task set 119.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,171 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 119.0 (TID 93) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,182 INFO storage.BlockManagerInfo: Added broadcast_95_piece0 in memory on algo-1:40133 (size: 32.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,276 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 119.0 (TID 93) in 105 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,276 INFO cluster.YarnScheduler: Removed TaskSet 119.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,277 INFO scheduler.DAGScheduler: ShuffleMapStage 119 (collect at AnalysisRunner.scala:326) finished in 0.115 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,278 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,278 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,278 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,278 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,324 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,325 INFO scheduler.DAGScheduler: Got job 81 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,329 INFO scheduler.DAGScheduler: Final stage: ResultStage 121 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,329 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 120)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,329 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,330 INFO scheduler.DAGScheduler: Submitting ResultStage 121 (MapPartitionsRDD[474] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,341 INFO memory.MemoryStore: Block broadcast_96 stored as values in memory (estimated size 184.6 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,346 INFO memory.MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,346 INFO storage.BlockManagerInfo: Added broadcast_96_piece0 in memory on 10.0.107.151:40635 (size: 50.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,347 INFO spark.SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,347 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 121 (MapPartitionsRDD[474] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,348 INFO cluster.YarnScheduler: Adding task set 121.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,355 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 121.0 (TID 94) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,363 INFO storage.BlockManagerInfo: Added broadcast_96_piece0 in memory on algo-1:40133 (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,382 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,449 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 121.0 (TID 94) in 94 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,451 INFO cluster.YarnScheduler: Removed TaskSet 121.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,451 INFO scheduler.DAGScheduler: ResultStage 121 (collect at AnalysisRunner.scala:326) finished in 0.121 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,452 INFO scheduler.DAGScheduler: Job 81 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,452 INFO cluster.YarnScheduler: Killing all running tasks in stage 121: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,453 INFO scheduler.DAGScheduler: Job 81 finished: collect at AnalysisRunner.scala:326, took 0.128273 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,539 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,540 INFO scheduler.DAGScheduler: Got job 82 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,540 INFO scheduler.DAGScheduler: Final stage: ResultStage 122 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,541 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,541 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,542 INFO scheduler.DAGScheduler: Submitting ResultStage 122 (MapPartitionsRDD[484] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,546 INFO memory.MemoryStore: Block broadcast_97 stored as values in memory (estimated size 54.8 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,548 INFO memory.MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,548 INFO storage.BlockManagerInfo: Added broadcast_97_piece0 in memory on 10.0.107.151:40635 (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,549 INFO spark.SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,549 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 122 (MapPartitionsRDD[484] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,550 INFO cluster.YarnScheduler: Adding task set 122.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,551 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 122.0 (TID 95) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,557 INFO storage.BlockManagerInfo: Added broadcast_97_piece0 in memory on algo-1:40133 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,576 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 122.0 (TID 95) in 25 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,576 INFO cluster.YarnScheduler: Removed TaskSet 122.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,577 INFO scheduler.DAGScheduler: ResultStage 122 (treeReduce at KLLRunner.scala:107) finished in 0.035 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,577 INFO scheduler.DAGScheduler: Job 82 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,578 INFO cluster.YarnScheduler: Killing all running tasks in stage 122: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,578 INFO scheduler.DAGScheduler: Job 82 finished: treeReduce at KLLRunner.scala:107, took 0.038584 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,664 INFO scheduler.DAGScheduler: Registering RDD 489 (collect at AnalysisRunner.scala:326) as input to shuffle 40\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,664 INFO scheduler.DAGScheduler: Got map stage job 83 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,664 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 123 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,665 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,665 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,666 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 123 (MapPartitionsRDD[489] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,669 INFO memory.MemoryStore: Block broadcast_98 stored as values in memory (estimated size 90.7 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,670 INFO memory.MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,670 INFO storage.BlockManagerInfo: Added broadcast_98_piece0 in memory on 10.0.107.151:40635 (size: 27.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,671 INFO spark.SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,671 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 123 (MapPartitionsRDD[489] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,672 INFO cluster.YarnScheduler: Adding task set 123.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,673 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 123.0 (TID 96) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,682 INFO storage.BlockManagerInfo: Added broadcast_98_piece0 in memory on algo-1:40133 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,705 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 123.0 (TID 96) in 33 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,705 INFO cluster.YarnScheduler: Removed TaskSet 123.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,706 INFO scheduler.DAGScheduler: ShuffleMapStage 123 (collect at AnalysisRunner.scala:326) finished in 0.038 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,707 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,707 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,707 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,707 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,751 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,752 INFO scheduler.DAGScheduler: Got job 84 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,752 INFO scheduler.DAGScheduler: Final stage: ResultStage 125 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,752 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 124)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,752 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,753 INFO scheduler.DAGScheduler: Submitting ResultStage 125 (MapPartitionsRDD[492] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,754 INFO memory.MemoryStore: Block broadcast_99 stored as values in memory (estimated size 66.2 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,756 INFO memory.MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,756 INFO storage.BlockManagerInfo: Added broadcast_99_piece0 in memory on 10.0.107.151:40635 (size: 19.2 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,756 INFO spark.SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,757 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 125 (MapPartitionsRDD[492] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,757 INFO cluster.YarnScheduler: Adding task set 125.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,758 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 125.0 (TID 97) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,767 INFO storage.BlockManagerInfo: Added broadcast_99_piece0 in memory on algo-1:40133 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,773 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 40 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,778 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 125.0 (TID 97) in 20 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,778 INFO cluster.YarnScheduler: Removed TaskSet 125.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,778 INFO scheduler.DAGScheduler: ResultStage 125 (collect at AnalysisRunner.scala:326) finished in 0.024 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,778 INFO scheduler.DAGScheduler: Job 84 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,778 INFO cluster.YarnScheduler: Killing all running tasks in stage 125: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,780 INFO scheduler.DAGScheduler: Job 84 finished: collect at AnalysisRunner.scala:326, took 0.027828 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,835 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,836 INFO scheduler.DAGScheduler: Registering RDD 500 (countByKey at ColumnProfiler.scala:592) as input to shuffle 41\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,837 INFO scheduler.DAGScheduler: Got job 85 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,837 INFO scheduler.DAGScheduler: Final stage: ResultStage 127 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,837 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 126)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,837 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 126)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,838 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 126 (MapPartitionsRDD[500] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,841 INFO memory.MemoryStore: Block broadcast_100 stored as values in memory (estimated size 47.1 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,842 INFO memory.MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,843 INFO storage.BlockManagerInfo: Added broadcast_100_piece0 in memory on 10.0.107.151:40635 (size: 18.8 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,843 INFO spark.SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,843 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 126 (MapPartitionsRDD[500] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,843 INFO cluster.YarnScheduler: Adding task set 126.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,844 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 126.0 (TID 98) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,854 INFO storage.BlockManagerInfo: Added broadcast_100_piece0 in memory on algo-1:40133 (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,898 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 126.0 (TID 98) in 54 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,898 INFO cluster.YarnScheduler: Removed TaskSet 126.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,899 INFO scheduler.DAGScheduler: ShuffleMapStage 126 (countByKey at ColumnProfiler.scala:592) finished in 0.061 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,899 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,899 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,899 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 127)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,900 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,900 INFO scheduler.DAGScheduler: Submitting ResultStage 127 (ShuffledRDD[501] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,901 INFO memory.MemoryStore: Block broadcast_101 stored as values in memory (estimated size 5.1 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,904 INFO memory.MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,905 INFO storage.BlockManagerInfo: Added broadcast_101_piece0 in memory on 10.0.107.151:40635 (size: 3.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,908 INFO spark.SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,909 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 127 (ShuffledRDD[501] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,909 INFO cluster.YarnScheduler: Adding task set 127.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,910 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 127.0 (TID 99) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,919 INFO storage.BlockManagerInfo: Added broadcast_101_piece0 in memory on algo-1:40133 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,922 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,929 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 127.0 (TID 99) in 19 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,930 INFO cluster.YarnScheduler: Removed TaskSet 127.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,930 INFO scheduler.DAGScheduler: ResultStage 127 (countByKey at ColumnProfiler.scala:592) finished in 0.029 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,931 INFO scheduler.DAGScheduler: Job 85 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,931 INFO cluster.YarnScheduler: Killing all running tasks in stage 127: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:08,931 INFO scheduler.DAGScheduler: Job 85 finished: countByKey at ColumnProfiler.scala:592, took 0.095868 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,014 INFO scheduler.DAGScheduler: Registering RDD 506 (collect at AnalysisRunner.scala:326) as input to shuffle 42\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,014 INFO scheduler.DAGScheduler: Got map stage job 86 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,015 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 128 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,015 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,015 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,016 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 128 (MapPartitionsRDD[506] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,023 INFO memory.MemoryStore: Block broadcast_102 stored as values in memory (estimated size 100.0 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,027 INFO memory.MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,027 INFO storage.BlockManagerInfo: Added broadcast_102_piece0 in memory on 10.0.107.151:40635 (size: 32.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,028 INFO spark.SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,028 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 128 (MapPartitionsRDD[506] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,029 INFO cluster.YarnScheduler: Adding task set 128.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,031 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 128.0 (TID 100) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,038 INFO storage.BlockManagerInfo: Added broadcast_102_piece0 in memory on algo-1:40133 (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,149 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 128.0 (TID 100) in 118 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,149 INFO cluster.YarnScheduler: Removed TaskSet 128.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,150 INFO scheduler.DAGScheduler: ShuffleMapStage 128 (collect at AnalysisRunner.scala:326) finished in 0.131 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,150 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,150 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,151 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,151 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,178 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,179 INFO scheduler.DAGScheduler: Got job 87 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,179 INFO scheduler.DAGScheduler: Final stage: ResultStage 130 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,179 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 129)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,179 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,179 INFO scheduler.DAGScheduler: Submitting ResultStage 130 (MapPartitionsRDD[509] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,184 INFO memory.MemoryStore: Block broadcast_103 stored as values in memory (estimated size 184.6 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,186 INFO memory.MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,186 INFO storage.BlockManagerInfo: Added broadcast_103_piece0 in memory on 10.0.107.151:40635 (size: 50.3 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,187 INFO spark.SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,187 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 130 (MapPartitionsRDD[509] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,187 INFO cluster.YarnScheduler: Adding task set 130.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,188 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 130.0 (TID 101) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,196 INFO storage.BlockManagerInfo: Added broadcast_103_piece0 in memory on algo-1:40133 (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,207 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 42 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,264 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 130.0 (TID 101) in 76 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,265 INFO cluster.YarnScheduler: Removed TaskSet 130.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,265 INFO scheduler.DAGScheduler: ResultStage 130 (collect at AnalysisRunner.scala:326) finished in 0.085 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,265 INFO scheduler.DAGScheduler: Job 87 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,265 INFO cluster.YarnScheduler: Killing all running tasks in stage 130: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,266 INFO scheduler.DAGScheduler: Job 87 finished: collect at AnalysisRunner.scala:326, took 0.087213 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,370 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,371 INFO scheduler.DAGScheduler: Got job 88 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,372 INFO scheduler.DAGScheduler: Final stage: ResultStage 131 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,372 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,374 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,374 INFO scheduler.DAGScheduler: Submitting ResultStage 131 (MapPartitionsRDD[519] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,387 INFO memory.MemoryStore: Block broadcast_104 stored as values in memory (estimated size 54.8 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,388 INFO memory.MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1456.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,388 INFO storage.BlockManagerInfo: Added broadcast_104_piece0 in memory on 10.0.107.151:40635 (size: 20.7 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,389 INFO spark.SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,389 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 131 (MapPartitionsRDD[519] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,389 INFO cluster.YarnScheduler: Adding task set 131.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,390 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 131.0 (TID 102) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,401 INFO storage.BlockManagerInfo: Added broadcast_104_piece0 in memory on algo-1:40133 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,418 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 131.0 (TID 102) in 28 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,419 INFO cluster.YarnScheduler: Removed TaskSet 131.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,419 INFO scheduler.DAGScheduler: ResultStage 131 (treeReduce at KLLRunner.scala:107) finished in 0.044 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,419 INFO scheduler.DAGScheduler: Job 88 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,419 INFO cluster.YarnScheduler: Killing all running tasks in stage 131: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,420 INFO scheduler.DAGScheduler: Job 88 finished: treeReduce at KLLRunner.scala:107, took 0.048657 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,564 INFO scheduler.DAGScheduler: Registering RDD 524 (collect at AnalysisRunner.scala:326) as input to shuffle 43\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,564 INFO scheduler.DAGScheduler: Got map stage job 89 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,565 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 132 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,565 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,565 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,566 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 132 (MapPartitionsRDD[524] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,568 INFO memory.MemoryStore: Block broadcast_105 stored as values in memory (estimated size 90.7 KiB, free 1456.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,570 INFO memory.MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1456.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,570 INFO storage.BlockManagerInfo: Added broadcast_105_piece0 in memory on 10.0.107.151:40635 (size: 27.9 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,570 INFO spark.SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,571 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 132 (MapPartitionsRDD[524] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,571 INFO cluster.YarnScheduler: Adding task set 132.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,571 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 132.0 (TID 103) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,583 INFO storage.BlockManagerInfo: Added broadcast_105_piece0 in memory on algo-1:40133 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,593 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 132.0 (TID 103) in 22 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,594 INFO cluster.YarnScheduler: Removed TaskSet 132.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,594 INFO scheduler.DAGScheduler: ShuffleMapStage 132 (collect at AnalysisRunner.scala:326) finished in 0.028 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,594 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,594 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,594 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,594 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,677 INFO storage.BlockManagerInfo: Removed broadcast_96_piece0 on 10.0.107.151:40635 in memory (size: 50.3 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,678 INFO storage.BlockManagerInfo: Removed broadcast_96_piece0 on algo-1:40133 in memory (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,682 INFO storage.BlockManagerInfo: Removed broadcast_95_piece0 on 10.0.107.151:40635 in memory (size: 32.8 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,684 INFO storage.BlockManagerInfo: Removed broadcast_95_piece0 on algo-1:40133 in memory (size: 32.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,687 INFO storage.BlockManagerInfo: Removed broadcast_92_piece0 on 10.0.107.151:40635 in memory (size: 19.2 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,689 INFO storage.BlockManagerInfo: Removed broadcast_92_piece0 on algo-1:40133 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,692 INFO storage.BlockManagerInfo: Removed broadcast_93_piece0 on 10.0.107.151:40635 in memory (size: 18.8 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,693 INFO storage.BlockManagerInfo: Removed broadcast_93_piece0 on algo-1:40133 in memory (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,695 INFO storage.BlockManagerInfo: Removed broadcast_94_piece0 on 10.0.107.151:40635 in memory (size: 3.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,696 INFO storage.BlockManagerInfo: Removed broadcast_94_piece0 on algo-1:40133 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,697 INFO storage.BlockManagerInfo: Removed broadcast_91_piece0 on 10.0.107.151:40635 in memory (size: 27.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,702 INFO storage.BlockManagerInfo: Removed broadcast_91_piece0 on algo-1:40133 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,705 INFO storage.BlockManagerInfo: Removed broadcast_101_piece0 on 10.0.107.151:40635 in memory (size: 3.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,706 INFO storage.BlockManagerInfo: Removed broadcast_101_piece0 on algo-1:40133 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,707 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,707 INFO scheduler.DAGScheduler: Got job 90 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,708 INFO scheduler.DAGScheduler: Final stage: ResultStage 134 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,709 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 133)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,709 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,710 INFO scheduler.DAGScheduler: Submitting ResultStage 134 (MapPartitionsRDD[527] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,712 INFO memory.MemoryStore: Block broadcast_106 stored as values in memory (estimated size 66.2 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,714 INFO memory.MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,709 INFO storage.BlockManagerInfo: Removed broadcast_102_piece0 on 10.0.107.151:40635 in memory (size: 32.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,715 INFO storage.BlockManagerInfo: Removed broadcast_102_piece0 on algo-1:40133 in memory (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,715 INFO storage.BlockManagerInfo: Added broadcast_106_piece0 in memory on 10.0.107.151:40635 (size: 19.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,716 INFO spark.SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,716 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 134 (MapPartitionsRDD[527] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,717 INFO cluster.YarnScheduler: Adding task set 134.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,718 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 134.0 (TID 104) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,720 INFO storage.BlockManagerInfo: Removed broadcast_103_piece0 on 10.0.107.151:40635 in memory (size: 50.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,720 INFO storage.BlockManagerInfo: Removed broadcast_103_piece0 on algo-1:40133 in memory (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,732 INFO storage.BlockManagerInfo: Removed broadcast_104_piece0 on algo-1:40133 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,733 INFO storage.BlockManagerInfo: Added broadcast_106_piece0 in memory on algo-1:40133 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,736 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,736 INFO storage.BlockManagerInfo: Removed broadcast_104_piece0 on 10.0.107.151:40635 in memory (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,740 INFO storage.BlockManagerInfo: Removed broadcast_100_piece0 on algo-1:40133 in memory (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,741 INFO storage.BlockManagerInfo: Removed broadcast_100_piece0 on 10.0.107.151:40635 in memory (size: 18.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,743 INFO storage.BlockManagerInfo: Removed broadcast_97_piece0 on algo-1:40133 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,744 INFO storage.BlockManagerInfo: Removed broadcast_97_piece0 on 10.0.107.151:40635 in memory (size: 20.7 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,746 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 134.0 (TID 104) in 28 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,746 INFO cluster.YarnScheduler: Removed TaskSet 134.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,746 INFO scheduler.DAGScheduler: ResultStage 134 (collect at AnalysisRunner.scala:326) finished in 0.035 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,747 INFO storage.BlockManagerInfo: Removed broadcast_98_piece0 on 10.0.107.151:40635 in memory (size: 27.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,747 INFO scheduler.DAGScheduler: Job 90 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,748 INFO cluster.YarnScheduler: Killing all running tasks in stage 134: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,748 INFO scheduler.DAGScheduler: Job 90 finished: collect at AnalysisRunner.scala:326, took 0.041535 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,749 INFO storage.BlockManagerInfo: Removed broadcast_98_piece0 on algo-1:40133 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,755 INFO storage.BlockManagerInfo: Removed broadcast_99_piece0 on 10.0.107.151:40635 in memory (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,756 INFO storage.BlockManagerInfo: Removed broadcast_99_piece0 on algo-1:40133 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,758 INFO storage.BlockManagerInfo: Removed broadcast_105_piece0 on 10.0.107.151:40635 in memory (size: 27.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,759 INFO storage.BlockManagerInfo: Removed broadcast_105_piece0 on algo-1:40133 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,831 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,832 INFO scheduler.DAGScheduler: Registering RDD 535 (countByKey at ColumnProfiler.scala:592) as input to shuffle 44\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,833 INFO scheduler.DAGScheduler: Got job 91 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,833 INFO scheduler.DAGScheduler: Final stage: ResultStage 136 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,833 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 135)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,833 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 135)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,834 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 135 (MapPartitionsRDD[535] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,839 INFO memory.MemoryStore: Block broadcast_107 stored as values in memory (estimated size 47.1 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,841 INFO memory.MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,841 INFO storage.BlockManagerInfo: Added broadcast_107_piece0 in memory on 10.0.107.151:40635 (size: 18.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,841 INFO spark.SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,842 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 135 (MapPartitionsRDD[535] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,842 INFO cluster.YarnScheduler: Adding task set 135.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,843 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 135.0 (TID 105) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,854 INFO storage.BlockManagerInfo: Added broadcast_107_piece0 in memory on algo-1:40133 (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,883 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 135.0 (TID 105) in 40 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,884 INFO cluster.YarnScheduler: Removed TaskSet 135.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,885 INFO scheduler.DAGScheduler: ShuffleMapStage 135 (countByKey at ColumnProfiler.scala:592) finished in 0.049 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,885 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,885 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,885 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 136)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,886 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,886 INFO scheduler.DAGScheduler: Submitting ResultStage 136 (ShuffledRDD[536] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,887 INFO memory.MemoryStore: Block broadcast_108 stored as values in memory (estimated size 5.1 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,888 INFO memory.MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,889 INFO storage.BlockManagerInfo: Added broadcast_108_piece0 in memory on 10.0.107.151:40635 (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,889 INFO spark.SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,890 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 136 (ShuffledRDD[536] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,890 INFO cluster.YarnScheduler: Adding task set 136.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,891 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 136.0 (TID 106) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,906 INFO storage.BlockManagerInfo: Added broadcast_108_piece0 in memory on algo-1:40133 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,910 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 44 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,919 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 136.0 (TID 106) in 28 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,920 INFO cluster.YarnScheduler: Removed TaskSet 136.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,920 INFO scheduler.DAGScheduler: ResultStage 136 (countByKey at ColumnProfiler.scala:592) finished in 0.033 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,921 INFO scheduler.DAGScheduler: Job 91 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,921 INFO cluster.YarnScheduler: Killing all running tasks in stage 136: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:09,921 INFO scheduler.DAGScheduler: Job 91 finished: countByKey at ColumnProfiler.scala:592, took 0.089262 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,145 INFO scheduler.DAGScheduler: Registering RDD 541 (collect at AnalysisRunner.scala:326) as input to shuffle 45\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,146 INFO scheduler.DAGScheduler: Got map stage job 92 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,146 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 137 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,146 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,147 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,147 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 137 (MapPartitionsRDD[541] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,151 INFO memory.MemoryStore: Block broadcast_109 stored as values in memory (estimated size 100.0 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,155 INFO memory.MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 32.8 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,155 INFO storage.BlockManagerInfo: Added broadcast_109_piece0 in memory on 10.0.107.151:40635 (size: 32.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,156 INFO spark.SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,156 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 137 (MapPartitionsRDD[541] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,157 INFO cluster.YarnScheduler: Adding task set 137.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,157 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 137.0 (TID 107) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,168 INFO storage.BlockManagerInfo: Added broadcast_109_piece0 in memory on algo-1:40133 (size: 32.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,260 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 137.0 (TID 107) in 103 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,260 INFO cluster.YarnScheduler: Removed TaskSet 137.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,261 INFO scheduler.DAGScheduler: ShuffleMapStage 137 (collect at AnalysisRunner.scala:326) finished in 0.113 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,262 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,262 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,262 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,263 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,307 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,308 INFO scheduler.DAGScheduler: Got job 93 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,308 INFO scheduler.DAGScheduler: Final stage: ResultStage 139 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,309 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 138)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,309 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,309 INFO scheduler.DAGScheduler: Submitting ResultStage 139 (MapPartitionsRDD[544] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,322 INFO memory.MemoryStore: Block broadcast_110 stored as values in memory (estimated size 184.6 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,326 INFO memory.MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,328 INFO storage.BlockManagerInfo: Added broadcast_110_piece0 in memory on 10.0.107.151:40635 (size: 50.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,329 INFO spark.SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,329 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 139 (MapPartitionsRDD[544] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,330 INFO cluster.YarnScheduler: Adding task set 139.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,332 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 139.0 (TID 108) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,338 INFO storage.BlockManagerInfo: Added broadcast_110_piece0 in memory on algo-1:40133 (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,358 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 45 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,462 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 139.0 (TID 108) in 130 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,463 INFO cluster.YarnScheduler: Removed TaskSet 139.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,463 INFO scheduler.DAGScheduler: ResultStage 139 (collect at AnalysisRunner.scala:326) finished in 0.153 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,463 INFO scheduler.DAGScheduler: Job 93 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,464 INFO cluster.YarnScheduler: Killing all running tasks in stage 139: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,464 INFO scheduler.DAGScheduler: Job 93 finished: collect at AnalysisRunner.scala:326, took 0.156431 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,549 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,551 INFO scheduler.DAGScheduler: Got job 94 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,552 INFO scheduler.DAGScheduler: Final stage: ResultStage 140 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,552 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,552 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,553 INFO scheduler.DAGScheduler: Submitting ResultStage 140 (MapPartitionsRDD[554] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,559 INFO memory.MemoryStore: Block broadcast_111 stored as values in memory (estimated size 54.8 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,560 INFO memory.MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,561 INFO storage.BlockManagerInfo: Added broadcast_111_piece0 in memory on 10.0.107.151:40635 (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,561 INFO spark.SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,561 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 140 (MapPartitionsRDD[554] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,562 INFO cluster.YarnScheduler: Adding task set 140.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,564 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 140.0 (TID 109) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,579 INFO storage.BlockManagerInfo: Added broadcast_111_piece0 in memory on algo-1:40133 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,611 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 140.0 (TID 109) in 46 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,611 INFO cluster.YarnScheduler: Removed TaskSet 140.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,611 INFO scheduler.DAGScheduler: ResultStage 140 (treeReduce at KLLRunner.scala:107) finished in 0.058 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,611 INFO scheduler.DAGScheduler: Job 94 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,611 INFO cluster.YarnScheduler: Killing all running tasks in stage 140: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,612 INFO scheduler.DAGScheduler: Job 94 finished: treeReduce at KLLRunner.scala:107, took 0.060718 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,701 INFO scheduler.DAGScheduler: Registering RDD 559 (collect at AnalysisRunner.scala:326) as input to shuffle 46\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,701 INFO scheduler.DAGScheduler: Got map stage job 95 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,701 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 141 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,702 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,702 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,702 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 141 (MapPartitionsRDD[559] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,705 INFO memory.MemoryStore: Block broadcast_112 stored as values in memory (estimated size 90.7 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,706 INFO memory.MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,707 INFO storage.BlockManagerInfo: Added broadcast_112_piece0 in memory on 10.0.107.151:40635 (size: 27.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,707 INFO spark.SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,707 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 141 (MapPartitionsRDD[559] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,708 INFO cluster.YarnScheduler: Adding task set 141.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,709 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 141.0 (TID 110) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,717 INFO storage.BlockManagerInfo: Added broadcast_112_piece0 in memory on algo-1:40133 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,736 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 141.0 (TID 110) in 28 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,736 INFO cluster.YarnScheduler: Removed TaskSet 141.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,737 INFO scheduler.DAGScheduler: ShuffleMapStage 141 (collect at AnalysisRunner.scala:326) finished in 0.034 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,738 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,738 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,738 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,738 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,778 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,779 INFO scheduler.DAGScheduler: Got job 96 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,779 INFO scheduler.DAGScheduler: Final stage: ResultStage 143 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,779 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 142)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,780 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,780 INFO scheduler.DAGScheduler: Submitting ResultStage 143 (MapPartitionsRDD[562] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,782 INFO memory.MemoryStore: Block broadcast_113 stored as values in memory (estimated size 66.2 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,783 INFO memory.MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,784 INFO storage.BlockManagerInfo: Added broadcast_113_piece0 in memory on 10.0.107.151:40635 (size: 19.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,784 INFO spark.SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,785 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 143 (MapPartitionsRDD[562] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,785 INFO cluster.YarnScheduler: Adding task set 143.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,786 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 143.0 (TID 111) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,798 INFO storage.BlockManagerInfo: Added broadcast_113_piece0 in memory on algo-1:40133 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,802 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 46 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,809 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 143.0 (TID 111) in 23 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,809 INFO cluster.YarnScheduler: Removed TaskSet 143.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,810 INFO scheduler.DAGScheduler: ResultStage 143 (collect at AnalysisRunner.scala:326) finished in 0.029 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,811 INFO scheduler.DAGScheduler: Job 96 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,811 INFO cluster.YarnScheduler: Killing all running tasks in stage 143: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,811 INFO scheduler.DAGScheduler: Job 96 finished: collect at AnalysisRunner.scala:326, took 0.032645 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,903 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,904 INFO scheduler.DAGScheduler: Registering RDD 570 (countByKey at ColumnProfiler.scala:592) as input to shuffle 47\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,904 INFO scheduler.DAGScheduler: Got job 97 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,904 INFO scheduler.DAGScheduler: Final stage: ResultStage 145 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,905 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 144)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,905 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 144)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,906 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 144 (MapPartitionsRDD[570] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,911 INFO memory.MemoryStore: Block broadcast_114 stored as values in memory (estimated size 47.1 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,912 INFO memory.MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,913 INFO storage.BlockManagerInfo: Added broadcast_114_piece0 in memory on 10.0.107.151:40635 (size: 18.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,913 INFO spark.SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,913 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 144 (MapPartitionsRDD[570] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,913 INFO cluster.YarnScheduler: Adding task set 144.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,916 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 144.0 (TID 112) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,925 INFO storage.BlockManagerInfo: Added broadcast_114_piece0 in memory on algo-1:40133 (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,943 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 144.0 (TID 112) in 27 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,943 INFO cluster.YarnScheduler: Removed TaskSet 144.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,944 INFO scheduler.DAGScheduler: ShuffleMapStage 144 (countByKey at ColumnProfiler.scala:592) finished in 0.036 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,944 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,945 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,945 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 145)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,945 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,945 INFO scheduler.DAGScheduler: Submitting ResultStage 145 (ShuffledRDD[571] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,947 INFO memory.MemoryStore: Block broadcast_115 stored as values in memory (estimated size 5.1 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,949 INFO memory.MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,950 INFO storage.BlockManagerInfo: Added broadcast_115_piece0 in memory on 10.0.107.151:40635 (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,950 INFO spark.SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,950 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 145 (ShuffledRDD[571] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,951 INFO cluster.YarnScheduler: Adding task set 145.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,952 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 145.0 (TID 113) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,965 INFO storage.BlockManagerInfo: Added broadcast_115_piece0 in memory on algo-1:40133 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,968 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 47 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,976 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 145.0 (TID 113) in 25 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,976 INFO cluster.YarnScheduler: Removed TaskSet 145.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,977 INFO scheduler.DAGScheduler: ResultStage 145 (countByKey at ColumnProfiler.scala:592) finished in 0.031 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,977 INFO scheduler.DAGScheduler: Job 97 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,978 INFO cluster.YarnScheduler: Killing all running tasks in stage 145: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:10,979 INFO scheduler.DAGScheduler: Job 97 finished: countByKey at ColumnProfiler.scala:592, took 0.075701 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,058 INFO scheduler.DAGScheduler: Registering RDD 576 (collect at AnalysisRunner.scala:326) as input to shuffle 48\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,059 INFO scheduler.DAGScheduler: Got map stage job 98 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,059 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 146 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,059 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,060 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,060 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 146 (MapPartitionsRDD[576] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,064 INFO memory.MemoryStore: Block broadcast_116 stored as values in memory (estimated size 100.0 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,066 INFO memory.MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 32.8 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,066 INFO storage.BlockManagerInfo: Added broadcast_116_piece0 in memory on 10.0.107.151:40635 (size: 32.8 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,067 INFO spark.SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,067 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 146 (MapPartitionsRDD[576] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,067 INFO cluster.YarnScheduler: Adding task set 146.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,068 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 146.0 (TID 114) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,077 INFO storage.BlockManagerInfo: Added broadcast_116_piece0 in memory on algo-1:40133 (size: 32.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,174 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 146.0 (TID 114) in 106 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,175 INFO scheduler.DAGScheduler: ShuffleMapStage 146 (collect at AnalysisRunner.scala:326) finished in 0.114 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,175 INFO cluster.YarnScheduler: Removed TaskSet 146.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,175 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,175 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,175 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,175 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,203 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,204 INFO scheduler.DAGScheduler: Got job 99 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,204 INFO scheduler.DAGScheduler: Final stage: ResultStage 148 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,204 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 147)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,205 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,205 INFO scheduler.DAGScheduler: Submitting ResultStage 148 (MapPartitionsRDD[579] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,210 INFO memory.MemoryStore: Block broadcast_117 stored as values in memory (estimated size 184.6 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,211 INFO memory.MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,211 INFO storage.BlockManagerInfo: Added broadcast_117_piece0 in memory on 10.0.107.151:40635 (size: 50.3 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,212 INFO spark.SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,212 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 148 (MapPartitionsRDD[579] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,212 INFO cluster.YarnScheduler: Adding task set 148.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,213 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 148.0 (TID 115) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,220 INFO storage.BlockManagerInfo: Added broadcast_117_piece0 in memory on algo-1:40133 (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,227 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 48 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,275 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 148.0 (TID 115) in 62 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,275 INFO cluster.YarnScheduler: Removed TaskSet 148.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,276 INFO scheduler.DAGScheduler: ResultStage 148 (collect at AnalysisRunner.scala:326) finished in 0.070 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,276 INFO scheduler.DAGScheduler: Job 99 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,276 INFO cluster.YarnScheduler: Killing all running tasks in stage 148: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,277 INFO scheduler.DAGScheduler: Job 99 finished: collect at AnalysisRunner.scala:326, took 0.073522 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,357 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,358 INFO scheduler.DAGScheduler: Got job 100 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,358 INFO scheduler.DAGScheduler: Final stage: ResultStage 149 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,358 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,359 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,359 INFO scheduler.DAGScheduler: Submitting ResultStage 149 (MapPartitionsRDD[589] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,363 INFO memory.MemoryStore: Block broadcast_118 stored as values in memory (estimated size 54.8 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,365 INFO memory.MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,365 INFO storage.BlockManagerInfo: Added broadcast_118_piece0 in memory on 10.0.107.151:40635 (size: 20.7 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,365 INFO spark.SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,366 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 149 (MapPartitionsRDD[589] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,366 INFO cluster.YarnScheduler: Adding task set 149.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,367 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 149.0 (TID 116) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,373 INFO storage.BlockManagerInfo: Added broadcast_118_piece0 in memory on algo-1:40133 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,392 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 149.0 (TID 116) in 25 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,392 INFO cluster.YarnScheduler: Removed TaskSet 149.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,393 INFO scheduler.DAGScheduler: ResultStage 149 (treeReduce at KLLRunner.scala:107) finished in 0.034 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,393 INFO scheduler.DAGScheduler: Job 100 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,393 INFO cluster.YarnScheduler: Killing all running tasks in stage 149: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,394 INFO scheduler.DAGScheduler: Job 100 finished: treeReduce at KLLRunner.scala:107, took 0.036274 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,473 INFO scheduler.DAGScheduler: Registering RDD 594 (collect at AnalysisRunner.scala:326) as input to shuffle 49\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,473 INFO scheduler.DAGScheduler: Got map stage job 101 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,474 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 150 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,474 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,474 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,475 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 150 (MapPartitionsRDD[594] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,476 INFO memory.MemoryStore: Block broadcast_119 stored as values in memory (estimated size 90.7 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,478 INFO memory.MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1456.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,478 INFO storage.BlockManagerInfo: Added broadcast_119_piece0 in memory on 10.0.107.151:40635 (size: 27.9 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,478 INFO spark.SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,478 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 150 (MapPartitionsRDD[594] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,478 INFO cluster.YarnScheduler: Adding task set 150.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,479 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 150.0 (TID 117) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,485 INFO storage.BlockManagerInfo: Added broadcast_119_piece0 in memory on algo-1:40133 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,495 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 150.0 (TID 117) in 16 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,495 INFO cluster.YarnScheduler: Removed TaskSet 150.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,496 INFO scheduler.DAGScheduler: ShuffleMapStage 150 (collect at AnalysisRunner.scala:326) finished in 0.020 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,496 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,496 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,496 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,496 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,532 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,533 INFO scheduler.DAGScheduler: Got job 102 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,533 INFO scheduler.DAGScheduler: Final stage: ResultStage 152 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,533 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 151)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,533 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,534 INFO scheduler.DAGScheduler: Submitting ResultStage 152 (MapPartitionsRDD[597] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,535 INFO memory.MemoryStore: Block broadcast_120 stored as values in memory (estimated size 66.2 KiB, free 1456.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,536 INFO memory.MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1456.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,536 INFO storage.BlockManagerInfo: Added broadcast_120_piece0 in memory on 10.0.107.151:40635 (size: 19.2 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,537 INFO spark.SparkContext: Created broadcast 120 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,537 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 152 (MapPartitionsRDD[597] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,537 INFO cluster.YarnScheduler: Adding task set 152.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,538 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 152.0 (TID 118) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,544 INFO storage.BlockManagerInfo: Added broadcast_120_piece0 in memory on algo-1:40133 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,546 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 49 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,551 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 152.0 (TID 118) in 13 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,551 INFO cluster.YarnScheduler: Removed TaskSet 152.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,552 INFO scheduler.DAGScheduler: ResultStage 152 (collect at AnalysisRunner.scala:326) finished in 0.018 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,552 INFO scheduler.DAGScheduler: Job 102 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,552 INFO cluster.YarnScheduler: Killing all running tasks in stage 152: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,553 INFO scheduler.DAGScheduler: Job 102 finished: collect at AnalysisRunner.scala:326, took 0.020722 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,598 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,599 INFO scheduler.DAGScheduler: Registering RDD 605 (countByKey at ColumnProfiler.scala:592) as input to shuffle 50\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,599 INFO scheduler.DAGScheduler: Got job 103 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,599 INFO scheduler.DAGScheduler: Final stage: ResultStage 154 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,599 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 153)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,599 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 153)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,600 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 153 (MapPartitionsRDD[605] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,605 INFO memory.MemoryStore: Block broadcast_121 stored as values in memory (estimated size 47.1 KiB, free 1456.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,607 INFO memory.MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1456.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,610 INFO storage.BlockManagerInfo: Added broadcast_121_piece0 in memory on 10.0.107.151:40635 (size: 18.8 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,610 INFO spark.SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,610 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 153 (MapPartitionsRDD[605] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,610 INFO cluster.YarnScheduler: Adding task set 153.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,611 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 153.0 (TID 119) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,622 INFO storage.BlockManagerInfo: Added broadcast_121_piece0 in memory on algo-1:40133 (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,639 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 153.0 (TID 119) in 28 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,640 INFO cluster.YarnScheduler: Removed TaskSet 153.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,640 INFO scheduler.DAGScheduler: ShuffleMapStage 153 (countByKey at ColumnProfiler.scala:592) finished in 0.040 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,641 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,641 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,641 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 154)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,641 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,642 INFO scheduler.DAGScheduler: Submitting ResultStage 154 (ShuffledRDD[606] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,643 INFO memory.MemoryStore: Block broadcast_122 stored as values in memory (estimated size 5.1 KiB, free 1456.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,645 INFO memory.MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1456.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,645 INFO storage.BlockManagerInfo: Added broadcast_122_piece0 in memory on 10.0.107.151:40635 (size: 3.0 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,646 INFO spark.SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,646 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 154 (ShuffledRDD[606] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,646 INFO cluster.YarnScheduler: Adding task set 154.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,647 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 154.0 (TID 120) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,654 INFO storage.BlockManagerInfo: Added broadcast_122_piece0 in memory on algo-1:40133 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,656 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 50 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,668 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 154.0 (TID 120) in 21 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,668 INFO cluster.YarnScheduler: Removed TaskSet 154.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,669 INFO scheduler.DAGScheduler: ResultStage 154 (countByKey at ColumnProfiler.scala:592) finished in 0.026 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,670 INFO scheduler.DAGScheduler: Job 103 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,670 INFO cluster.YarnScheduler: Killing all running tasks in stage 154: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,670 INFO scheduler.DAGScheduler: Job 103 finished: countByKey at ColumnProfiler.scala:592, took 0.072373 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,754 INFO storage.BlockManagerInfo: Removed broadcast_110_piece0 on 10.0.107.151:40635 in memory (size: 50.3 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,756 INFO storage.BlockManagerInfo: Removed broadcast_110_piece0 on algo-1:40133 in memory (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,759 INFO storage.BlockManagerInfo: Removed broadcast_119_piece0 on 10.0.107.151:40635 in memory (size: 27.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,761 INFO storage.BlockManagerInfo: Removed broadcast_119_piece0 on algo-1:40133 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,767 INFO storage.BlockManagerInfo: Removed broadcast_122_piece0 on 10.0.107.151:40635 in memory (size: 3.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,768 INFO storage.BlockManagerInfo: Removed broadcast_122_piece0 on algo-1:40133 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,770 INFO storage.BlockManagerInfo: Removed broadcast_120_piece0 on 10.0.107.151:40635 in memory (size: 19.2 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,773 INFO storage.BlockManagerInfo: Removed broadcast_120_piece0 on algo-1:40133 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,774 INFO storage.BlockManagerInfo: Removed broadcast_111_piece0 on 10.0.107.151:40635 in memory (size: 20.7 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,779 INFO storage.BlockManagerInfo: Removed broadcast_111_piece0 on algo-1:40133 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,781 INFO storage.BlockManagerInfo: Removed broadcast_108_piece0 on 10.0.107.151:40635 in memory (size: 3.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,782 INFO storage.BlockManagerInfo: Removed broadcast_108_piece0 on algo-1:40133 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,783 INFO storage.BlockManagerInfo: Removed broadcast_115_piece0 on 10.0.107.151:40635 in memory (size: 3.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,786 INFO storage.BlockManagerInfo: Removed broadcast_115_piece0 on algo-1:40133 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,788 INFO storage.BlockManagerInfo: Removed broadcast_106_piece0 on 10.0.107.151:40635 in memory (size: 19.2 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,788 INFO storage.BlockManagerInfo: Removed broadcast_106_piece0 on algo-1:40133 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,792 INFO storage.BlockManagerInfo: Removed broadcast_117_piece0 on 10.0.107.151:40635 in memory (size: 50.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,793 INFO storage.BlockManagerInfo: Removed broadcast_117_piece0 on algo-1:40133 in memory (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,795 INFO storage.BlockManagerInfo: Removed broadcast_114_piece0 on 10.0.107.151:40635 in memory (size: 18.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,796 INFO storage.BlockManagerInfo: Removed broadcast_114_piece0 on algo-1:40133 in memory (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,797 INFO storage.BlockManagerInfo: Removed broadcast_118_piece0 on 10.0.107.151:40635 in memory (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,799 INFO storage.BlockManagerInfo: Removed broadcast_118_piece0 on algo-1:40133 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,801 INFO storage.BlockManagerInfo: Removed broadcast_116_piece0 on 10.0.107.151:40635 in memory (size: 32.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,803 INFO storage.BlockManagerInfo: Removed broadcast_116_piece0 on algo-1:40133 in memory (size: 32.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,804 INFO storage.BlockManagerInfo: Removed broadcast_113_piece0 on 10.0.107.151:40635 in memory (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,805 INFO storage.BlockManagerInfo: Removed broadcast_113_piece0 on algo-1:40133 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,819 INFO storage.BlockManagerInfo: Removed broadcast_112_piece0 on 10.0.107.151:40635 in memory (size: 27.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,819 INFO storage.BlockManagerInfo: Removed broadcast_112_piece0 on algo-1:40133 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,825 INFO storage.BlockManagerInfo: Removed broadcast_109_piece0 on 10.0.107.151:40635 in memory (size: 32.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,825 INFO storage.BlockManagerInfo: Removed broadcast_109_piece0 on algo-1:40133 in memory (size: 32.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,830 INFO storage.BlockManagerInfo: Removed broadcast_121_piece0 on 10.0.107.151:40635 in memory (size: 18.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,837 INFO storage.BlockManagerInfo: Removed broadcast_121_piece0 on algo-1:40133 in memory (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,838 INFO storage.BlockManagerInfo: Removed broadcast_107_piece0 on 10.0.107.151:40635 in memory (size: 18.8 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,840 INFO storage.BlockManagerInfo: Removed broadcast_107_piece0 on algo-1:40133 in memory (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,852 INFO scheduler.DAGScheduler: Registering RDD 611 (collect at AnalysisRunner.scala:326) as input to shuffle 51\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,852 INFO scheduler.DAGScheduler: Got map stage job 104 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,852 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 155 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,852 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,853 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,854 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 155 (MapPartitionsRDD[611] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,858 INFO memory.MemoryStore: Block broadcast_123 stored as values in memory (estimated size 100.0 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,860 INFO memory.MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,860 INFO storage.BlockManagerInfo: Added broadcast_123_piece0 in memory on 10.0.107.151:40635 (size: 32.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,860 INFO spark.SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,861 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 155 (MapPartitionsRDD[611] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,861 INFO cluster.YarnScheduler: Adding task set 155.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,862 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 155.0 (TID 121) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,870 INFO storage.BlockManagerInfo: Added broadcast_123_piece0 in memory on algo-1:40133 (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,974 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 155.0 (TID 121) in 112 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,974 INFO cluster.YarnScheduler: Removed TaskSet 155.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,975 INFO scheduler.DAGScheduler: ShuffleMapStage 155 (collect at AnalysisRunner.scala:326) finished in 0.120 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,975 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,976 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,976 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:11,976 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,014 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,014 INFO scheduler.DAGScheduler: Got job 105 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,014 INFO scheduler.DAGScheduler: Final stage: ResultStage 157 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,015 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 156)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,015 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,015 INFO scheduler.DAGScheduler: Submitting ResultStage 157 (MapPartitionsRDD[614] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,022 INFO memory.MemoryStore: Block broadcast_124 stored as values in memory (estimated size 184.6 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,024 INFO memory.MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,024 INFO storage.BlockManagerInfo: Added broadcast_124_piece0 in memory on 10.0.107.151:40635 (size: 50.3 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,025 INFO spark.SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,025 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 157 (MapPartitionsRDD[614] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,025 INFO cluster.YarnScheduler: Adding task set 157.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,026 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 157.0 (TID 122) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,032 INFO storage.BlockManagerInfo: Added broadcast_124_piece0 in memory on algo-1:40133 (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,042 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 51 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,121 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 157.0 (TID 122) in 95 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,121 INFO cluster.YarnScheduler: Removed TaskSet 157.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,122 INFO scheduler.DAGScheduler: ResultStage 157 (collect at AnalysisRunner.scala:326) finished in 0.106 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,123 INFO scheduler.DAGScheduler: Job 105 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,123 INFO cluster.YarnScheduler: Killing all running tasks in stage 157: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,123 INFO scheduler.DAGScheduler: Job 105 finished: collect at AnalysisRunner.scala:326, took 0.109411 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,200 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,201 INFO scheduler.DAGScheduler: Got job 106 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,202 INFO scheduler.DAGScheduler: Final stage: ResultStage 158 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,202 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,202 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,202 INFO scheduler.DAGScheduler: Submitting ResultStage 158 (MapPartitionsRDD[624] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,213 INFO memory.MemoryStore: Block broadcast_125 stored as values in memory (estimated size 54.8 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,214 INFO memory.MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,215 INFO storage.BlockManagerInfo: Added broadcast_125_piece0 in memory on 10.0.107.151:40635 (size: 20.7 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,215 INFO spark.SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,216 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 158 (MapPartitionsRDD[624] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,216 INFO cluster.YarnScheduler: Adding task set 158.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,217 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 158.0 (TID 123) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,223 INFO storage.BlockManagerInfo: Added broadcast_125_piece0 in memory on algo-1:40133 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,271 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 158.0 (TID 123) in 54 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,274 INFO cluster.YarnScheduler: Removed TaskSet 158.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,275 INFO scheduler.DAGScheduler: ResultStage 158 (treeReduce at KLLRunner.scala:107) finished in 0.071 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,276 INFO scheduler.DAGScheduler: Job 106 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,276 INFO cluster.YarnScheduler: Killing all running tasks in stage 158: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,284 INFO scheduler.DAGScheduler: Job 106 finished: treeReduce at KLLRunner.scala:107, took 0.083893 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,375 INFO scheduler.DAGScheduler: Registering RDD 629 (collect at AnalysisRunner.scala:326) as input to shuffle 52\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,376 INFO scheduler.DAGScheduler: Got map stage job 107 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,376 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 159 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,376 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,376 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,377 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 159 (MapPartitionsRDD[629] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,379 INFO memory.MemoryStore: Block broadcast_126 stored as values in memory (estimated size 90.7 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,381 INFO memory.MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,382 INFO storage.BlockManagerInfo: Added broadcast_126_piece0 in memory on 10.0.107.151:40635 (size: 27.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,382 INFO spark.SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,382 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 159 (MapPartitionsRDD[629] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,383 INFO cluster.YarnScheduler: Adding task set 159.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,383 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 159.0 (TID 124) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,394 INFO storage.BlockManagerInfo: Added broadcast_126_piece0 in memory on algo-1:40133 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,404 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 159.0 (TID 124) in 21 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,405 INFO cluster.YarnScheduler: Removed TaskSet 159.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,405 INFO scheduler.DAGScheduler: ShuffleMapStage 159 (collect at AnalysisRunner.scala:326) finished in 0.028 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,405 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,406 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,407 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,407 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,446 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,447 INFO scheduler.DAGScheduler: Got job 108 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,447 INFO scheduler.DAGScheduler: Final stage: ResultStage 161 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,447 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 160)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,447 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,448 INFO scheduler.DAGScheduler: Submitting ResultStage 161 (MapPartitionsRDD[632] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,450 INFO memory.MemoryStore: Block broadcast_127 stored as values in memory (estimated size 66.2 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,452 INFO memory.MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,452 INFO storage.BlockManagerInfo: Added broadcast_127_piece0 in memory on 10.0.107.151:40635 (size: 19.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,453 INFO spark.SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,453 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 161 (MapPartitionsRDD[632] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,453 INFO cluster.YarnScheduler: Adding task set 161.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,454 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 161.0 (TID 125) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,465 INFO storage.BlockManagerInfo: Added broadcast_127_piece0 in memory on algo-1:40133 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,467 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 52 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,472 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 161.0 (TID 125) in 18 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,472 INFO cluster.YarnScheduler: Removed TaskSet 161.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,472 INFO scheduler.DAGScheduler: ResultStage 161 (collect at AnalysisRunner.scala:326) finished in 0.023 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,473 INFO scheduler.DAGScheduler: Job 108 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,473 INFO cluster.YarnScheduler: Killing all running tasks in stage 161: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,474 INFO scheduler.DAGScheduler: Job 108 finished: collect at AnalysisRunner.scala:326, took 0.027376 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,518 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,518 INFO scheduler.DAGScheduler: Registering RDD 640 (countByKey at ColumnProfiler.scala:592) as input to shuffle 53\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,519 INFO scheduler.DAGScheduler: Got job 109 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,519 INFO scheduler.DAGScheduler: Final stage: ResultStage 163 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,519 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 162)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,519 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 162)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,520 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 162 (MapPartitionsRDD[640] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,524 INFO memory.MemoryStore: Block broadcast_128 stored as values in memory (estimated size 47.1 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,527 INFO memory.MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,529 INFO storage.BlockManagerInfo: Added broadcast_128_piece0 in memory on 10.0.107.151:40635 (size: 18.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,530 INFO spark.SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,530 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 162 (MapPartitionsRDD[640] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,533 INFO cluster.YarnScheduler: Adding task set 162.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,534 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 162.0 (TID 126) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,544 INFO storage.BlockManagerInfo: Added broadcast_128_piece0 in memory on algo-1:40133 (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,559 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 162.0 (TID 126) in 26 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,559 INFO cluster.YarnScheduler: Removed TaskSet 162.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,560 INFO scheduler.DAGScheduler: ShuffleMapStage 162 (countByKey at ColumnProfiler.scala:592) finished in 0.039 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,560 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,561 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,561 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 163)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,561 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,561 INFO scheduler.DAGScheduler: Submitting ResultStage 163 (ShuffledRDD[641] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,563 INFO memory.MemoryStore: Block broadcast_129 stored as values in memory (estimated size 5.1 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,564 INFO memory.MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,564 INFO storage.BlockManagerInfo: Added broadcast_129_piece0 in memory on 10.0.107.151:40635 (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,565 INFO spark.SparkContext: Created broadcast 129 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,565 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 163 (ShuffledRDD[641] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,566 INFO cluster.YarnScheduler: Adding task set 163.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,567 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 163.0 (TID 127) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,576 INFO storage.BlockManagerInfo: Added broadcast_129_piece0 in memory on algo-1:40133 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,578 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 53 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,593 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 163.0 (TID 127) in 27 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,593 INFO cluster.YarnScheduler: Removed TaskSet 163.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,594 INFO scheduler.DAGScheduler: ResultStage 163 (countByKey at ColumnProfiler.scala:592) finished in 0.032 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,595 INFO scheduler.DAGScheduler: Job 109 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,595 INFO cluster.YarnScheduler: Killing all running tasks in stage 163: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,595 INFO scheduler.DAGScheduler: Job 109 finished: countByKey at ColumnProfiler.scala:592, took 0.077549 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,728 INFO scheduler.DAGScheduler: Registering RDD 646 (collect at AnalysisRunner.scala:326) as input to shuffle 54\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,729 INFO scheduler.DAGScheduler: Got map stage job 110 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,729 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 164 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,729 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,730 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,730 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 164 (MapPartitionsRDD[646] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,734 INFO memory.MemoryStore: Block broadcast_130 stored as values in memory (estimated size 100.0 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,735 INFO memory.MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,736 INFO storage.BlockManagerInfo: Added broadcast_130_piece0 in memory on 10.0.107.151:40635 (size: 32.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,736 INFO spark.SparkContext: Created broadcast 130 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,737 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 164 (MapPartitionsRDD[646] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,737 INFO cluster.YarnScheduler: Adding task set 164.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,738 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 164.0 (TID 128) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,753 INFO storage.BlockManagerInfo: Added broadcast_130_piece0 in memory on algo-1:40133 (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,855 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 164.0 (TID 128) in 117 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,855 INFO cluster.YarnScheduler: Removed TaskSet 164.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,856 INFO scheduler.DAGScheduler: ShuffleMapStage 164 (collect at AnalysisRunner.scala:326) finished in 0.125 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,856 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,856 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,856 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,857 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,888 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,889 INFO scheduler.DAGScheduler: Got job 111 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,889 INFO scheduler.DAGScheduler: Final stage: ResultStage 166 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,890 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 165)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,890 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,890 INFO scheduler.DAGScheduler: Submitting ResultStage 166 (MapPartitionsRDD[649] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,897 INFO memory.MemoryStore: Block broadcast_131 stored as values in memory (estimated size 184.6 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,899 INFO memory.MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,899 INFO storage.BlockManagerInfo: Added broadcast_131_piece0 in memory on 10.0.107.151:40635 (size: 50.3 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,900 INFO spark.SparkContext: Created broadcast 131 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,900 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 166 (MapPartitionsRDD[649] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,900 INFO cluster.YarnScheduler: Adding task set 166.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,902 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 166.0 (TID 129) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,912 INFO storage.BlockManagerInfo: Added broadcast_131_piece0 in memory on algo-1:40133 (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,921 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 54 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,996 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 166.0 (TID 129) in 94 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,996 INFO cluster.YarnScheduler: Removed TaskSet 166.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,997 INFO scheduler.DAGScheduler: ResultStage 166 (collect at AnalysisRunner.scala:326) finished in 0.106 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,997 INFO scheduler.DAGScheduler: Job 111 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,997 INFO cluster.YarnScheduler: Killing all running tasks in stage 166: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:12,997 INFO scheduler.DAGScheduler: Job 111 finished: collect at AnalysisRunner.scala:326, took 0.108655 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,074 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,074 INFO scheduler.DAGScheduler: Got job 112 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,075 INFO scheduler.DAGScheduler: Final stage: ResultStage 167 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,075 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,075 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,076 INFO scheduler.DAGScheduler: Submitting ResultStage 167 (MapPartitionsRDD[659] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,085 INFO memory.MemoryStore: Block broadcast_132 stored as values in memory (estimated size 54.8 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,086 INFO memory.MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,086 INFO storage.BlockManagerInfo: Added broadcast_132_piece0 in memory on 10.0.107.151:40635 (size: 20.7 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,086 INFO spark.SparkContext: Created broadcast 132 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,087 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 167 (MapPartitionsRDD[659] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,087 INFO cluster.YarnScheduler: Adding task set 167.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,087 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 167.0 (TID 130) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,099 INFO storage.BlockManagerInfo: Added broadcast_132_piece0 in memory on algo-1:40133 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,117 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 167.0 (TID 130) in 30 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,118 INFO cluster.YarnScheduler: Removed TaskSet 167.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,118 INFO scheduler.DAGScheduler: ResultStage 167 (treeReduce at KLLRunner.scala:107) finished in 0.042 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,118 INFO scheduler.DAGScheduler: Job 112 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,118 INFO cluster.YarnScheduler: Killing all running tasks in stage 167: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,119 INFO scheduler.DAGScheduler: Job 112 finished: treeReduce at KLLRunner.scala:107, took 0.044750 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,204 INFO scheduler.DAGScheduler: Registering RDD 664 (collect at AnalysisRunner.scala:326) as input to shuffle 55\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,204 INFO scheduler.DAGScheduler: Got map stage job 113 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,204 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 168 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,205 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,205 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,205 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 168 (MapPartitionsRDD[664] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,208 INFO memory.MemoryStore: Block broadcast_133 stored as values in memory (estimated size 90.7 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,210 INFO memory.MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,212 INFO storage.BlockManagerInfo: Added broadcast_133_piece0 in memory on 10.0.107.151:40635 (size: 27.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,212 INFO spark.SparkContext: Created broadcast 133 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,213 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 168 (MapPartitionsRDD[664] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,213 INFO cluster.YarnScheduler: Adding task set 168.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,214 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 168.0 (TID 131) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,220 INFO storage.BlockManagerInfo: Added broadcast_133_piece0 in memory on algo-1:40133 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,231 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 168.0 (TID 131) in 17 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,231 INFO cluster.YarnScheduler: Removed TaskSet 168.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,232 INFO scheduler.DAGScheduler: ShuffleMapStage 168 (collect at AnalysisRunner.scala:326) finished in 0.026 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,232 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,232 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,233 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,233 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,270 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,271 INFO scheduler.DAGScheduler: Got job 114 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,271 INFO scheduler.DAGScheduler: Final stage: ResultStage 170 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,271 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 169)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,272 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,272 INFO scheduler.DAGScheduler: Submitting ResultStage 170 (MapPartitionsRDD[667] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,274 INFO memory.MemoryStore: Block broadcast_134 stored as values in memory (estimated size 66.2 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,275 INFO memory.MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,276 INFO storage.BlockManagerInfo: Added broadcast_134_piece0 in memory on 10.0.107.151:40635 (size: 19.2 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,276 INFO spark.SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,277 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 170 (MapPartitionsRDD[667] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,277 INFO cluster.YarnScheduler: Adding task set 170.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,278 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 170.0 (TID 132) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,284 INFO storage.BlockManagerInfo: Added broadcast_134_piece0 in memory on algo-1:40133 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,287 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 55 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,292 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 170.0 (TID 132) in 14 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,292 INFO cluster.YarnScheduler: Removed TaskSet 170.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,293 INFO scheduler.DAGScheduler: ResultStage 170 (collect at AnalysisRunner.scala:326) finished in 0.020 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,293 INFO scheduler.DAGScheduler: Job 114 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,293 INFO cluster.YarnScheduler: Killing all running tasks in stage 170: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,293 INFO scheduler.DAGScheduler: Job 114 finished: collect at AnalysisRunner.scala:326, took 0.023003 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,344 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,345 INFO scheduler.DAGScheduler: Registering RDD 675 (countByKey at ColumnProfiler.scala:592) as input to shuffle 56\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,346 INFO scheduler.DAGScheduler: Got job 115 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,346 INFO scheduler.DAGScheduler: Final stage: ResultStage 172 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,346 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 171)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,347 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 171)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,348 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 171 (MapPartitionsRDD[675] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,351 INFO memory.MemoryStore: Block broadcast_135 stored as values in memory (estimated size 47.1 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,353 INFO memory.MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,353 INFO storage.BlockManagerInfo: Added broadcast_135_piece0 in memory on 10.0.107.151:40635 (size: 18.8 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,354 INFO spark.SparkContext: Created broadcast 135 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,354 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 171 (MapPartitionsRDD[675] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,355 INFO cluster.YarnScheduler: Adding task set 171.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,355 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 171.0 (TID 133) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,365 INFO storage.BlockManagerInfo: Added broadcast_135_piece0 in memory on algo-1:40133 (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,406 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 171.0 (TID 133) in 51 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,406 INFO cluster.YarnScheduler: Removed TaskSet 171.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,407 INFO scheduler.DAGScheduler: ShuffleMapStage 171 (countByKey at ColumnProfiler.scala:592) finished in 0.058 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,407 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,407 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,408 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 172)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,408 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,408 INFO scheduler.DAGScheduler: Submitting ResultStage 172 (ShuffledRDD[676] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,409 INFO memory.MemoryStore: Block broadcast_136 stored as values in memory (estimated size 5.1 KiB, free 1456.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,411 INFO memory.MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1456.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,411 INFO storage.BlockManagerInfo: Added broadcast_136_piece0 in memory on 10.0.107.151:40635 (size: 3.0 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,412 INFO spark.SparkContext: Created broadcast 136 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,412 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 172 (ShuffledRDD[676] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,412 INFO cluster.YarnScheduler: Adding task set 172.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,413 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 172.0 (TID 134) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,420 INFO storage.BlockManagerInfo: Added broadcast_136_piece0 in memory on algo-1:40133 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,422 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 56 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,431 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 172.0 (TID 134) in 18 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,431 INFO cluster.YarnScheduler: Removed TaskSet 172.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,431 INFO scheduler.DAGScheduler: ResultStage 172 (countByKey at ColumnProfiler.scala:592) finished in 0.022 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,432 INFO scheduler.DAGScheduler: Job 115 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,432 INFO cluster.YarnScheduler: Killing all running tasks in stage 172: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,433 INFO scheduler.DAGScheduler: Job 115 finished: countByKey at ColumnProfiler.scala:592, took 0.087597 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,555 INFO scheduler.DAGScheduler: Registering RDD 681 (collect at AnalysisRunner.scala:326) as input to shuffle 57\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,556 INFO scheduler.DAGScheduler: Got map stage job 116 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,556 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 173 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,556 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,557 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,557 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 173 (MapPartitionsRDD[681] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,561 INFO memory.MemoryStore: Block broadcast_137 stored as values in memory (estimated size 100.0 KiB, free 1456.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,563 INFO memory.MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1456.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,568 INFO storage.BlockManagerInfo: Added broadcast_137_piece0 in memory on 10.0.107.151:40635 (size: 32.9 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,569 INFO spark.SparkContext: Created broadcast 137 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,569 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 173 (MapPartitionsRDD[681] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,569 INFO cluster.YarnScheduler: Adding task set 173.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,570 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 173.0 (TID 135) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,576 INFO storage.BlockManagerInfo: Added broadcast_137_piece0 in memory on algo-1:40133 (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,726 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 173.0 (TID 135) in 156 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,726 INFO cluster.YarnScheduler: Removed TaskSet 173.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,727 INFO scheduler.DAGScheduler: ShuffleMapStage 173 (collect at AnalysisRunner.scala:326) finished in 0.169 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,727 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,728 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,728 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,728 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,766 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,766 INFO scheduler.DAGScheduler: Got job 117 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,767 INFO scheduler.DAGScheduler: Final stage: ResultStage 175 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,767 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 174)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,767 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,768 INFO scheduler.DAGScheduler: Submitting ResultStage 175 (MapPartitionsRDD[684] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,776 INFO memory.MemoryStore: Block broadcast_138 stored as values in memory (estimated size 184.6 KiB, free 1456.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,778 INFO memory.MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 50.2 KiB, free 1456.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,779 INFO storage.BlockManagerInfo: Added broadcast_138_piece0 in memory on 10.0.107.151:40635 (size: 50.2 KiB, free: 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,779 INFO spark.SparkContext: Created broadcast 138 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,780 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 175 (MapPartitionsRDD[684] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,780 INFO cluster.YarnScheduler: Adding task set 175.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,785 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 175.0 (TID 136) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,791 INFO storage.BlockManagerInfo: Added broadcast_138_piece0 in memory on algo-1:40133 (size: 50.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,802 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 57 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,895 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 175.0 (TID 136) in 111 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,896 INFO scheduler.DAGScheduler: ResultStage 175 (collect at AnalysisRunner.scala:326) finished in 0.126 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,899 INFO scheduler.DAGScheduler: Job 117 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,899 INFO cluster.YarnScheduler: Removed TaskSet 175.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,900 INFO cluster.YarnScheduler: Killing all running tasks in stage 175: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:13,901 INFO scheduler.DAGScheduler: Job 117 finished: collect at AnalysisRunner.scala:326, took 0.134774 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,009 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,010 INFO scheduler.DAGScheduler: Got job 118 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,010 INFO scheduler.DAGScheduler: Final stage: ResultStage 176 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,010 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,011 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,011 INFO scheduler.DAGScheduler: Submitting ResultStage 176 (MapPartitionsRDD[694] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,026 INFO memory.MemoryStore: Block broadcast_139 stored as values in memory (estimated size 54.8 KiB, free 1456.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,027 INFO memory.MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1456.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,029 INFO storage.BlockManagerInfo: Added broadcast_139_piece0 in memory on 10.0.107.151:40635 (size: 20.7 KiB, free: 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,030 INFO spark.SparkContext: Created broadcast 139 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,030 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 176 (MapPartitionsRDD[694] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,030 INFO cluster.YarnScheduler: Adding task set 176.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,032 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 176.0 (TID 137) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,037 INFO storage.BlockManagerInfo: Added broadcast_139_piece0 in memory on algo-1:40133 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,056 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 176.0 (TID 137) in 25 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,057 INFO scheduler.DAGScheduler: ResultStage 176 (treeReduce at KLLRunner.scala:107) finished in 0.045 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,058 INFO scheduler.DAGScheduler: Job 118 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,058 INFO cluster.YarnScheduler: Removed TaskSet 176.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,059 INFO cluster.YarnScheduler: Killing all running tasks in stage 176: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,059 INFO scheduler.DAGScheduler: Job 118 finished: treeReduce at KLLRunner.scala:107, took 0.049885 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,236 INFO scheduler.DAGScheduler: Registering RDD 699 (collect at AnalysisRunner.scala:326) as input to shuffle 58\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,237 INFO scheduler.DAGScheduler: Got map stage job 119 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,237 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 177 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,237 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,238 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,238 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 177 (MapPartitionsRDD[699] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,241 INFO memory.MemoryStore: Block broadcast_140 stored as values in memory (estimated size 90.7 KiB, free 1456.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,244 INFO memory.MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1456.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,244 INFO storage.BlockManagerInfo: Added broadcast_140_piece0 in memory on 10.0.107.151:40635 (size: 27.9 KiB, free: 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,245 INFO spark.SparkContext: Created broadcast 140 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,245 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 177 (MapPartitionsRDD[699] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,246 INFO cluster.YarnScheduler: Adding task set 177.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,246 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 177.0 (TID 138) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,256 INFO storage.BlockManagerInfo: Added broadcast_140_piece0 in memory on algo-1:40133 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,268 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 177.0 (TID 138) in 22 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,268 INFO cluster.YarnScheduler: Removed TaskSet 177.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,269 INFO scheduler.DAGScheduler: ShuffleMapStage 177 (collect at AnalysisRunner.scala:326) finished in 0.030 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,270 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,270 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,270 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,270 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,355 INFO storage.BlockManagerInfo: Removed broadcast_126_piece0 on 10.0.107.151:40635 in memory (size: 27.9 KiB, free: 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,355 INFO storage.BlockManagerInfo: Removed broadcast_126_piece0 on algo-1:40133 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,358 INFO storage.BlockManagerInfo: Removed broadcast_128_piece0 on 10.0.107.151:40635 in memory (size: 18.8 KiB, free: 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,359 INFO storage.BlockManagerInfo: Removed broadcast_128_piece0 on algo-1:40133 in memory (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,364 INFO storage.BlockManagerInfo: Removed broadcast_127_piece0 on 10.0.107.151:40635 in memory (size: 19.2 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,364 INFO storage.BlockManagerInfo: Removed broadcast_127_piece0 on algo-1:40133 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,365 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,370 INFO scheduler.DAGScheduler: Got job 120 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,371 INFO scheduler.DAGScheduler: Final stage: ResultStage 179 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,371 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 178)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,371 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,372 INFO scheduler.DAGScheduler: Submitting ResultStage 179 (MapPartitionsRDD[702] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,373 INFO memory.MemoryStore: Block broadcast_141 stored as values in memory (estimated size 66.2 KiB, free 1456.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,374 INFO memory.MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1456.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,375 INFO storage.BlockManagerInfo: Removed broadcast_135_piece0 on 10.0.107.151:40635 in memory (size: 18.8 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,375 INFO storage.BlockManagerInfo: Added broadcast_141_piece0 in memory on 10.0.107.151:40635 (size: 19.2 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,375 INFO storage.BlockManagerInfo: Removed broadcast_135_piece0 on algo-1:40133 in memory (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,376 INFO spark.SparkContext: Created broadcast 141 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,376 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 179 (MapPartitionsRDD[702] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,376 INFO cluster.YarnScheduler: Adding task set 179.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,377 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 179.0 (TID 139) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,380 INFO storage.BlockManagerInfo: Removed broadcast_130_piece0 on 10.0.107.151:40635 in memory (size: 32.9 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,388 INFO storage.BlockManagerInfo: Removed broadcast_130_piece0 on algo-1:40133 in memory (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,389 INFO storage.BlockManagerInfo: Added broadcast_141_piece0 in memory on algo-1:40133 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,392 INFO storage.BlockManagerInfo: Removed broadcast_138_piece0 on 10.0.107.151:40635 in memory (size: 50.2 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,393 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 58 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,398 INFO storage.BlockManagerInfo: Removed broadcast_138_piece0 on algo-1:40133 in memory (size: 50.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,399 INFO storage.BlockManagerInfo: Removed broadcast_140_piece0 on 10.0.107.151:40635 in memory (size: 27.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,401 INFO storage.BlockManagerInfo: Removed broadcast_140_piece0 on algo-1:40133 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,402 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 179.0 (TID 139) in 25 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,402 INFO cluster.YarnScheduler: Removed TaskSet 179.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,402 INFO scheduler.DAGScheduler: ResultStage 179 (collect at AnalysisRunner.scala:326) finished in 0.029 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,402 INFO scheduler.DAGScheduler: Job 120 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,402 INFO cluster.YarnScheduler: Killing all running tasks in stage 179: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,403 INFO scheduler.DAGScheduler: Job 120 finished: collect at AnalysisRunner.scala:326, took 0.034269 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,409 INFO storage.BlockManagerInfo: Removed broadcast_137_piece0 on 10.0.107.151:40635 in memory (size: 32.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,411 INFO storage.BlockManagerInfo: Removed broadcast_137_piece0 on algo-1:40133 in memory (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,412 INFO storage.BlockManagerInfo: Removed broadcast_123_piece0 on 10.0.107.151:40635 in memory (size: 32.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,413 INFO storage.BlockManagerInfo: Removed broadcast_123_piece0 on algo-1:40133 in memory (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,414 INFO storage.BlockManagerInfo: Removed broadcast_131_piece0 on 10.0.107.151:40635 in memory (size: 50.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,415 INFO storage.BlockManagerInfo: Removed broadcast_131_piece0 on algo-1:40133 in memory (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,416 INFO storage.BlockManagerInfo: Removed broadcast_125_piece0 on 10.0.107.151:40635 in memory (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,417 INFO storage.BlockManagerInfo: Removed broadcast_125_piece0 on algo-1:40133 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,418 INFO storage.BlockManagerInfo: Removed broadcast_133_piece0 on 10.0.107.151:40635 in memory (size: 27.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,419 INFO storage.BlockManagerInfo: Removed broadcast_133_piece0 on algo-1:40133 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,421 INFO storage.BlockManagerInfo: Removed broadcast_129_piece0 on 10.0.107.151:40635 in memory (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,422 INFO storage.BlockManagerInfo: Removed broadcast_129_piece0 on algo-1:40133 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,423 INFO storage.BlockManagerInfo: Removed broadcast_124_piece0 on 10.0.107.151:40635 in memory (size: 50.3 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,424 INFO storage.BlockManagerInfo: Removed broadcast_124_piece0 on algo-1:40133 in memory (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,425 INFO storage.BlockManagerInfo: Removed broadcast_132_piece0 on 10.0.107.151:40635 in memory (size: 20.7 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,427 INFO storage.BlockManagerInfo: Removed broadcast_132_piece0 on algo-1:40133 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,428 INFO storage.BlockManagerInfo: Removed broadcast_134_piece0 on 10.0.107.151:40635 in memory (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,430 INFO storage.BlockManagerInfo: Removed broadcast_134_piece0 on algo-1:40133 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,432 INFO storage.BlockManagerInfo: Removed broadcast_139_piece0 on 10.0.107.151:40635 in memory (size: 20.7 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,434 INFO storage.BlockManagerInfo: Removed broadcast_139_piece0 on algo-1:40133 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,435 INFO storage.BlockManagerInfo: Removed broadcast_136_piece0 on 10.0.107.151:40635 in memory (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,436 INFO storage.BlockManagerInfo: Removed broadcast_136_piece0 on algo-1:40133 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,478 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,479 INFO scheduler.DAGScheduler: Registering RDD 710 (countByKey at ColumnProfiler.scala:592) as input to shuffle 59\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,479 INFO scheduler.DAGScheduler: Got job 121 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,480 INFO scheduler.DAGScheduler: Final stage: ResultStage 181 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,480 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 180)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,480 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 180)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,480 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 180 (MapPartitionsRDD[710] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,486 INFO memory.MemoryStore: Block broadcast_142 stored as values in memory (estimated size 47.1 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,487 INFO memory.MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,487 INFO storage.BlockManagerInfo: Added broadcast_142_piece0 in memory on 10.0.107.151:40635 (size: 18.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,488 INFO spark.SparkContext: Created broadcast 142 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,488 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 180 (MapPartitionsRDD[710] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,488 INFO cluster.YarnScheduler: Adding task set 180.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,489 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 180.0 (TID 140) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,494 INFO storage.BlockManagerInfo: Added broadcast_142_piece0 in memory on algo-1:40133 (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,527 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 180.0 (TID 140) in 38 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,527 INFO cluster.YarnScheduler: Removed TaskSet 180.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,528 INFO scheduler.DAGScheduler: ShuffleMapStage 180 (countByKey at ColumnProfiler.scala:592) finished in 0.047 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,529 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,529 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,530 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 181)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,530 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,530 INFO scheduler.DAGScheduler: Submitting ResultStage 181 (ShuffledRDD[711] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,531 INFO memory.MemoryStore: Block broadcast_143 stored as values in memory (estimated size 5.1 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,533 INFO memory.MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,533 INFO storage.BlockManagerInfo: Added broadcast_143_piece0 in memory on 10.0.107.151:40635 (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,533 INFO spark.SparkContext: Created broadcast 143 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,534 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 181 (ShuffledRDD[711] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,534 INFO cluster.YarnScheduler: Adding task set 181.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,535 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 181.0 (TID 141) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,540 INFO storage.BlockManagerInfo: Added broadcast_143_piece0 in memory on algo-1:40133 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,542 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 59 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,553 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 181.0 (TID 141) in 18 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,553 INFO cluster.YarnScheduler: Removed TaskSet 181.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,554 INFO scheduler.DAGScheduler: ResultStage 181 (countByKey at ColumnProfiler.scala:592) finished in 0.023 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,554 INFO scheduler.DAGScheduler: Job 121 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,555 INFO cluster.YarnScheduler: Killing all running tasks in stage 181: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,555 INFO scheduler.DAGScheduler: Job 121 finished: countByKey at ColumnProfiler.scala:592, took 0.076510 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,731 INFO FileUtil: Write to file constraints.json at path /opt/ml/processing/output.\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,766 INFO codegen.CodeGenerator: Code generated in 9.05864 ms\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,771 INFO scheduler.DAGScheduler: Registering RDD 716 (count at StatsGenerator.scala:66) as input to shuffle 60\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,771 INFO scheduler.DAGScheduler: Got map stage job 122 (count at StatsGenerator.scala:66) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,771 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 182 (count at StatsGenerator.scala:66)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,771 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,772 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,772 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 182 (MapPartitionsRDD[716] at count at StatsGenerator.scala:66), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,774 INFO memory.MemoryStore: Block broadcast_144 stored as values in memory (estimated size 39.6 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,776 INFO memory.MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 15.1 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,776 INFO storage.BlockManagerInfo: Added broadcast_144_piece0 in memory on 10.0.107.151:40635 (size: 15.1 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,777 INFO spark.SparkContext: Created broadcast 144 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,777 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 182 (MapPartitionsRDD[716] at count at StatsGenerator.scala:66) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,777 INFO cluster.YarnScheduler: Adding task set 182.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,778 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 182.0 (TID 142) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,786 INFO storage.BlockManagerInfo: Added broadcast_144_piece0 in memory on algo-1:40133 (size: 15.1 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,836 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 182.0 (TID 142) in 58 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,836 INFO cluster.YarnScheduler: Removed TaskSet 182.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,837 INFO scheduler.DAGScheduler: ShuffleMapStage 182 (count at StatsGenerator.scala:66) finished in 0.064 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,837 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,838 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,838 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,838 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,861 INFO codegen.CodeGenerator: Code generated in 17.658603 ms\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,870 INFO spark.SparkContext: Starting job: count at StatsGenerator.scala:66\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,871 INFO scheduler.DAGScheduler: Got job 123 (count at StatsGenerator.scala:66) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,871 INFO scheduler.DAGScheduler: Final stage: ResultStage 184 (count at StatsGenerator.scala:66)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,871 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 183)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,872 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,872 INFO scheduler.DAGScheduler: Submitting ResultStage 184 (MapPartitionsRDD[719] at count at StatsGenerator.scala:66), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,873 INFO memory.MemoryStore: Block broadcast_145 stored as values in memory (estimated size 11.1 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,875 INFO memory.MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,875 INFO storage.BlockManagerInfo: Added broadcast_145_piece0 in memory on 10.0.107.151:40635 (size: 5.5 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,876 INFO spark.SparkContext: Created broadcast 145 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,876 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 184 (MapPartitionsRDD[719] at count at StatsGenerator.scala:66) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,876 INFO cluster.YarnScheduler: Adding task set 184.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,877 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 184.0 (TID 143) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,883 INFO storage.BlockManagerInfo: Added broadcast_145_piece0 in memory on algo-1:40133 (size: 5.5 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,886 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 60 to 10.0.107.151:56546\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,907 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 184.0 (TID 143) in 30 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,907 INFO cluster.YarnScheduler: Removed TaskSet 184.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,908 INFO scheduler.DAGScheduler: ResultStage 184 (count at StatsGenerator.scala:66) finished in 0.035 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,908 INFO scheduler.DAGScheduler: Job 123 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,909 INFO cluster.YarnScheduler: Killing all running tasks in stage 184: Stage finished\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:14,909 INFO scheduler.DAGScheduler: Job 123 finished: count at StatsGenerator.scala:66, took 0.038500 s\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:15,670 INFO FileUtil: Write to file statistics.json at path /opt/ml/processing/output.\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:15,687 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:15,716 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:15,717 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:15,729 INFO cluster.YarnClientSchedulerBackend: YARN client scheduler backend Stopped\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:15,748 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:15,797 INFO memory.MemoryStore: MemoryStore cleared\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:15,804 INFO storage.BlockManager: BlockManager stopped\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:15,820 INFO storage.BlockManagerMaster: BlockManagerMaster stopped\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:15,833 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:15,883 INFO spark.SparkContext: Successfully stopped SparkContext\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:15,884 INFO Main: Completed: Job completed successfully with no violations.\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:15,884 INFO Main: Write to file /opt/ml/output/message.\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:15,903 INFO util.ShutdownHookManager: Shutdown hook called\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:15,905 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-e7963265-3aab-4833-8aee-ce1cbaddf1e4\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:15,932 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-5d276ba1-b346-400a-bdc9-b39c7125e9e9\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:16,065 - DefaultDataAnalyzer - INFO - Completed spark-submit with return code : 0\u001b[0m\n",
      "\u001b[34m2024-03-30 23:18:16,066 - DefaultDataAnalyzer - INFO - Spark job completed.\u001b[0m\n",
      "\n",
      "CPU times: user 1.03 s, sys: 35 ms, total: 1.07 s\n",
      "Wall time: 7min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "monitor_baseline = my_default_monitor.suggest_baseline(\n",
    "    baseline_dataset=baseline_data_uri,\n",
    "    dataset_format=DatasetFormat.csv(header=False),\n",
    "    output_s3_uri=baseline_results_uri,\n",
    "    job_name=f\"{prefix}-monitor-baseline-{datetime_stamp}\",\n",
    "    wait=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ddf619a-a4c7-4f09-a789-2e38f1d45a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "import boto3\n",
    "\n",
    "client = boto3.client(\"sagemaker\")\n",
    "\n",
    "\n",
    "def get_last_processing_job():\n",
    "    response = client.list_processing_jobs(\n",
    "        NameContains=f\"{prefix}-monitor-baseline-{datetime_stamp}\",\n",
    "        StatusEquals=\"Completed\",\n",
    "        SortBy=\"CreationTime\",\n",
    "        SortOrder=\"Descending\",\n",
    "        MaxResults=20,\n",
    "    )\n",
    "    pprint.pprint(response[\"ProcessingJobSummaries\"][0])\n",
    "    return response[\"ProcessingJobSummaries\"][0][\"ProcessingJobName\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bb1aa8a-aee0-48df-8698-a50f2039fd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CreationTime': datetime.datetime(2024, 3, 30, 23, 11, 34, 579000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2024, 3, 30, 23, 18, 25, 774000, tzinfo=tzlocal()),\n",
      " 'ProcessingEndTime': datetime.datetime(2024, 3, 30, 23, 18, 25, 171000, tzinfo=tzlocal()),\n",
      " 'ProcessingJobArn': 'arn:aws:sagemaker:us-west-2:846634201516:processing-job/customerchurn-monitor-baseline-2024-03-30-231131',\n",
      " 'ProcessingJobName': 'customerchurn-monitor-baseline-2024-03-30-231131',\n",
      " 'ProcessingJobStatus': 'Completed'}\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingJob\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.model_monitor.model_monitoring import ModelMonitor\n",
    "import pprint\n",
    "my_default_monitor_name = get_last_processing_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ffae739-0057-455d-a279-7ac1b4547bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AppSpecification': {'ImageUri': '159807026194.dkr.ecr.us-west-2.amazonaws.com/sagemaker-model-monitor-analyzer'},\n",
      " 'CreationTime': datetime.datetime(2024, 3, 30, 23, 11, 34, 579000, tzinfo=tzlocal()),\n",
      " 'Environment': {'dataset_format': '{\"csv\": {\"header\": false, '\n",
      "                                   '\"output_columns_position\": \"START\"}}',\n",
      "                 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input',\n",
      "                 'output_path': '/opt/ml/processing/output',\n",
      "                 'publish_cloudwatch_metrics': 'Disabled'},\n",
      " 'ExitMessage': 'Completed: Job completed successfully with no violations.',\n",
      " 'LastModifiedTime': datetime.datetime(2024, 3, 30, 23, 18, 25, 774000, tzinfo=tzlocal()),\n",
      " 'ProcessingEndTime': datetime.datetime(2024, 3, 30, 23, 18, 25, 171000, tzinfo=tzlocal()),\n",
      " 'ProcessingInputs': [{'AppManaged': False,\n",
      "                       'InputName': 'baseline_dataset_input',\n",
      "                       'S3Input': {'LocalPath': '/opt/ml/processing/input/baseline_dataset_input',\n",
      "                                   'S3CompressionType': 'None',\n",
      "                                   'S3DataDistributionType': 'FullyReplicated',\n",
      "                                   'S3DataType': 'S3Prefix',\n",
      "                                   'S3InputMode': 'File',\n",
      "                                   'S3Uri': 's3://sagemaker-us-west-2-846634201516/ml_deploy/validation'}}],\n",
      " 'ProcessingJobArn': 'arn:aws:sagemaker:us-west-2:846634201516:processing-job/customerchurn-monitor-baseline-2024-03-30-231131',\n",
      " 'ProcessingJobName': 'customerchurn-monitor-baseline-2024-03-30-231131',\n",
      " 'ProcessingJobStatus': 'Completed',\n",
      " 'ProcessingOutputConfig': {'Outputs': [{'AppManaged': False,\n",
      "                                         'OutputName': 'monitoring_output',\n",
      "                                         'S3Output': {'LocalPath': '/opt/ml/processing/output',\n",
      "                                                      'S3UploadMode': 'EndOfJob',\n",
      "                                                      'S3Uri': 's3://sagemaker-us-west-2-846634201516/monitoring/baseline/results'}}]},\n",
      " 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1,\n",
      "                                           'InstanceType': 'ml.m5.large',\n",
      "                                           'VolumeSizeInGB': 20}},\n",
      " 'ProcessingStartTime': datetime.datetime(2024, 3, 30, 23, 16, 8, 100000, tzinfo=tzlocal()),\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '1858',\n",
      "                                      'content-type': 'application/x-amz-json-1.1',\n",
      "                                      'date': 'Sat, 30 Mar 2024 23:23:26 GMT',\n",
      "                                      'x-amzn-requestid': '50a01413-6351-4e35-a769-9cb7e49e8034'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': '50a01413-6351-4e35-a769-9cb7e49e8034',\n",
      "                      'RetryAttempts': 0},\n",
      " 'RoleArn': 'arn:aws:iam::846634201516:role/service-role/AmazonSageMaker-ExecutionRole-20240122T185424',\n",
      " 'StoppingCondition': {'MaxRuntimeInSeconds': 1800}}\n"
     ]
    }
   ],
   "source": [
    "my_default_monitor_reload = ProcessingJob.from_processing_name(sess, my_default_monitor_name)\n",
    "\n",
    "response = client.describe_processing_job(ProcessingJobName=my_default_monitor_name)\n",
    "pprint.pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0386037b-1a0b-4398-a0f1-8528b4c8fe97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>inferred_type</th>\n",
       "      <th>numerical_statistics.common.num_present</th>\n",
       "      <th>numerical_statistics.common.num_missing</th>\n",
       "      <th>numerical_statistics.mean</th>\n",
       "      <th>numerical_statistics.sum</th>\n",
       "      <th>numerical_statistics.std_dev</th>\n",
       "      <th>numerical_statistics.min</th>\n",
       "      <th>numerical_statistics.max</th>\n",
       "      <th>numerical_statistics.distribution.kll.buckets</th>\n",
       "      <th>numerical_statistics.distribution.kll.sketch.parameters.c</th>\n",
       "      <th>numerical_statistics.distribution.kll.sketch.parameters.k</th>\n",
       "      <th>numerical_statistics.distribution.kll.sketch.data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_c0</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1038</td>\n",
       "      <td>0</td>\n",
       "      <td>0.503854</td>\n",
       "      <td>523.000000</td>\n",
       "      <td>0.499985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_c1</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1038</td>\n",
       "      <td>0</td>\n",
       "      <td>102.279383</td>\n",
       "      <td>106166.000000</td>\n",
       "      <td>57.590835</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>[{'lower_bound': 1.0, 'upper_bound': 20.9, 'co...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_c2</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1038</td>\n",
       "      <td>0</td>\n",
       "      <td>231.406551</td>\n",
       "      <td>240200.000000</td>\n",
       "      <td>272.249153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 130.0, 'c...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[0.0, 0.0, 500.0, 700.0, 0.0, 0.0, 0.0, 500.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_c3</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1038</td>\n",
       "      <td>0</td>\n",
       "      <td>5.578486</td>\n",
       "      <td>5790.468231</td>\n",
       "      <td>3.381909</td>\n",
       "      <td>0.014247</td>\n",
       "      <td>16.504147</td>\n",
       "      <td>[{'lower_bound': 0.014247142810832612, 'upper_...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[1.442509561551946, 4.93641897645424, 7.03572...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_c4</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1038</td>\n",
       "      <td>0</td>\n",
       "      <td>3.443160</td>\n",
       "      <td>3574.000000</td>\n",
       "      <td>1.710825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.8, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[3.0, 3.0, 5.0, 4.0, 3.0, 2.0, 5.0, 6.0, 3.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>_c5</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1038</td>\n",
       "      <td>0</td>\n",
       "      <td>5.102953</td>\n",
       "      <td>5296.865235</td>\n",
       "      <td>2.186658</td>\n",
       "      <td>0.014361</td>\n",
       "      <td>11.233955</td>\n",
       "      <td>[{'lower_bound': 0.014361348439859256, 'upper_...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[2.2467101421396123, 0.9736083883577038, 3.13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>_c6</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1038</td>\n",
       "      <td>0</td>\n",
       "      <td>3.103083</td>\n",
       "      <td>3221.000000</td>\n",
       "      <td>2.515074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 1.3, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[1.0, 2.0, 5.0, 0.0, 5.0, 1.0, 8.0, 2.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>_c7</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1038</td>\n",
       "      <td>0</td>\n",
       "      <td>4.014886</td>\n",
       "      <td>4167.451342</td>\n",
       "      <td>1.603892</td>\n",
       "      <td>0.077795</td>\n",
       "      <td>10.183378</td>\n",
       "      <td>[{'lower_bound': 0.07779530526817169, 'upper_b...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[5.052209883015463, 4.758515666071381, 5.1068...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>_c8</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1038</td>\n",
       "      <td>0</td>\n",
       "      <td>228.275530</td>\n",
       "      <td>236950.000000</td>\n",
       "      <td>95.956864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 50.0, 'co...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[150.0, 150.0, 200.0, 250.0, 400.0, 350.0, 45...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>_c9</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1038</td>\n",
       "      <td>0</td>\n",
       "      <td>5.027020</td>\n",
       "      <td>5218.047012</td>\n",
       "      <td>1.015671</td>\n",
       "      <td>2.223449</td>\n",
       "      <td>8.181336</td>\n",
       "      <td>[{'lower_bound': 2.22344893121115, 'upper_boun...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[4.227688847116808, 4.350906105573603, 5.5186...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name inferred_type  numerical_statistics.common.num_present  \\\n",
       "0  _c0    Fractional                                     1038   \n",
       "1  _c1    Fractional                                     1038   \n",
       "2  _c2    Fractional                                     1038   \n",
       "3  _c3    Fractional                                     1038   \n",
       "4  _c4    Fractional                                     1038   \n",
       "5  _c5    Fractional                                     1038   \n",
       "6  _c6    Fractional                                     1038   \n",
       "7  _c7    Fractional                                     1038   \n",
       "8  _c8    Fractional                                     1038   \n",
       "9  _c9    Fractional                                     1038   \n",
       "\n",
       "   numerical_statistics.common.num_missing  numerical_statistics.mean  \\\n",
       "0                                        0                   0.503854   \n",
       "1                                        0                 102.279383   \n",
       "2                                        0                 231.406551   \n",
       "3                                        0                   5.578486   \n",
       "4                                        0                   3.443160   \n",
       "5                                        0                   5.102953   \n",
       "6                                        0                   3.103083   \n",
       "7                                        0                   4.014886   \n",
       "8                                        0                 228.275530   \n",
       "9                                        0                   5.027020   \n",
       "\n",
       "   numerical_statistics.sum  numerical_statistics.std_dev  \\\n",
       "0                523.000000                      0.499985   \n",
       "1             106166.000000                     57.590835   \n",
       "2             240200.000000                    272.249153   \n",
       "3               5790.468231                      3.381909   \n",
       "4               3574.000000                      1.710825   \n",
       "5               5296.865235                      2.186658   \n",
       "6               3221.000000                      2.515074   \n",
       "7               4167.451342                      1.603892   \n",
       "8             236950.000000                     95.956864   \n",
       "9               5218.047012                      1.015671   \n",
       "\n",
       "   numerical_statistics.min  numerical_statistics.max  \\\n",
       "0                  0.000000                  1.000000   \n",
       "1                  1.000000                200.000000   \n",
       "2                  0.000000               1300.000000   \n",
       "3                  0.014247                 16.504147   \n",
       "4                  0.000000                  8.000000   \n",
       "5                  0.014361                 11.233955   \n",
       "6                  0.000000                 13.000000   \n",
       "7                  0.077795                 10.183378   \n",
       "8                  0.000000                500.000000   \n",
       "9                  2.223449                  8.181336   \n",
       "\n",
       "       numerical_statistics.distribution.kll.buckets  \\\n",
       "0  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "1  [{'lower_bound': 1.0, 'upper_bound': 20.9, 'co...   \n",
       "2  [{'lower_bound': 0.0, 'upper_bound': 130.0, 'c...   \n",
       "3  [{'lower_bound': 0.014247142810832612, 'upper_...   \n",
       "4  [{'lower_bound': 0.0, 'upper_bound': 0.8, 'cou...   \n",
       "5  [{'lower_bound': 0.014361348439859256, 'upper_...   \n",
       "6  [{'lower_bound': 0.0, 'upper_bound': 1.3, 'cou...   \n",
       "7  [{'lower_bound': 0.07779530526817169, 'upper_b...   \n",
       "8  [{'lower_bound': 0.0, 'upper_bound': 50.0, 'co...   \n",
       "9  [{'lower_bound': 2.22344893121115, 'upper_boun...   \n",
       "\n",
       "   numerical_statistics.distribution.kll.sketch.parameters.c  \\\n",
       "0                                               0.64           \n",
       "1                                               0.64           \n",
       "2                                               0.64           \n",
       "3                                               0.64           \n",
       "4                                               0.64           \n",
       "5                                               0.64           \n",
       "6                                               0.64           \n",
       "7                                               0.64           \n",
       "8                                               0.64           \n",
       "9                                               0.64           \n",
       "\n",
       "   numerical_statistics.distribution.kll.sketch.parameters.k  \\\n",
       "0                                             2048.0           \n",
       "1                                             2048.0           \n",
       "2                                             2048.0           \n",
       "3                                             2048.0           \n",
       "4                                             2048.0           \n",
       "5                                             2048.0           \n",
       "6                                             2048.0           \n",
       "7                                             2048.0           \n",
       "8                                             2048.0           \n",
       "9                                             2048.0           \n",
       "\n",
       "   numerical_statistics.distribution.kll.sketch.data  \n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "1  [[1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0,...  \n",
       "2  [[0.0, 0.0, 500.0, 700.0, 0.0, 0.0, 0.0, 500.0...  \n",
       "3  [[1.442509561551946, 4.93641897645424, 7.03572...  \n",
       "4  [[3.0, 3.0, 5.0, 4.0, 3.0, 2.0, 5.0, 6.0, 3.0,...  \n",
       "5  [[2.2467101421396123, 0.9736083883577038, 3.13...  \n",
       "6  [[1.0, 2.0, 5.0, 0.0, 5.0, 1.0, 8.0, 2.0, 1.0,...  \n",
       "7  [[5.052209883015463, 4.758515666071381, 5.1068...  \n",
       "8  [[150.0, 150.0, 200.0, 250.0, 400.0, 350.0, 45...  \n",
       "9  [[4.227688847116808, 4.350906105573603, 5.5186...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "baseline_job = my_default_monitor.latest_baselining_job\n",
    "schema_df = pd.json_normalize(baseline_job.baseline_statistics().body_dict[\"features\"])\n",
    "schema_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fada03d-1e20-4281-bc8e-ba5e49475c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>inferred_type</th>\n",
       "      <th>completeness</th>\n",
       "      <th>num_constraints.is_non_negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_c0</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_c1</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_c2</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_c3</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_c4</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>_c5</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>_c6</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>_c7</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>_c8</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>_c9</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name inferred_type  completeness  num_constraints.is_non_negative\n",
       "0  _c0    Fractional           1.0                             True\n",
       "1  _c1    Fractional           1.0                             True\n",
       "2  _c2    Fractional           1.0                             True\n",
       "3  _c3    Fractional           1.0                             True\n",
       "4  _c4    Fractional           1.0                             True\n",
       "5  _c5    Fractional           1.0                             True\n",
       "6  _c6    Fractional           1.0                             True\n",
       "7  _c7    Fractional           1.0                             True\n",
       "8  _c8    Fractional           1.0                             True\n",
       "9  _c9    Fractional           1.0                             True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constraints_df = pd.json_normalize(baseline_job.suggested_constraints().body_dict[\"features\"])\n",
    "constraints_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e57b2a2-d61e-4218-8d22-4dc462a62e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9136815667152405\n"
     ]
    }
   ],
   "source": [
    "sagemaker_runtime = boto3.client(\n",
    "    \"sagemaker-runtime\", region_name='us-west-2')\n",
    "\n",
    "response = sagemaker_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, \n",
    "    ContentType='text/csv',\n",
    "    Body = \"2.0,400.0,0.38571846040122537,2.0,4.177940384158745,0.0,3.745462710628048,250.0,3.699591756294294,1.0,11.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,0.0,1.0\"\n",
    ")\n",
    "print(response['Body'].read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bee9d3b9-0bdc-4c87-aa24-ea5980a22593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9136815667152405\n",
      "0.9136815667152405\n",
      "0.9136815667152405\n",
      "0.9136815667152405\n",
      "0.9136815667152405\n",
      "0.9136815667152405\n",
      "0.9136815667152405\n",
      "0.9136815667152405\n",
      "0.9136815667152405\n",
      "0.9136815667152405\n",
      "0.9136815667152405\n",
      "0.9136815667152405\n",
      "0.9136815667152405\n",
      "0.9136815667152405\n",
      "0.9136815667152405\n",
      "0.9136815667152405\n",
      "0.9136815667152405\n",
      "0.9136815667152405\n",
      "0.9136815667152405\n",
      "0.9136815667152405\n"
     ]
    }
   ],
   "source": [
    "for x in range(20):\n",
    "    response = sagemaker_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, \n",
    "    ContentType='text/csv',\n",
    "    Body = \"2.0,400.0,0.38571846040122537,2.0,4.177940384158745,0.0,3.745462710628048,250.0,3.699591756294294,1.0,11.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,0.0,1.0\"\n",
    ")\n",
    "    print(response['Body'].read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32b803a7-9de5-4116-9b6f-9aadcceff05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the data drift model monitoring processing job to start...\n",
      "Waiting for the data drift model monitoring processing job to start...\n",
      "Waiting for the data drift model monitoring processing job to start...\n",
      "Waiting for the data drift model monitoring processing job to start...\n",
      "Waiting for the data drift model monitoring processing job to start...\n",
      "Waiting for the data drift model monitoring processing job to start...\n",
      "Waiting for the data drift model monitoring processing job to start...\n",
      "Waiting for the data drift model monitoring processing job to start...\n",
      "Waiting for the data drift model monitoring processing job to start...\n",
      "Waiting for the data drift model monitoring processing job to start...\n",
      "Waiting for the data drift model monitoring processing job to start...\n",
      "Waiting for the data drift model monitoring processing job to start...\n",
      "Waiting for the data drift model monitoring processing job to start...\n",
      "Waiting for the data drift model monitoring processing job to start...\n",
      "Waiting for the data drift model monitoring processing job to start...\n",
      "Waiting for the data drift model monitoring processing job to start...\n",
      "Waiting for the data drift model monitoring processing job to start...\n",
      "Waiting for the data drift model monitoring processing job to start...\n",
      "Waiting for the data drift model monitoring processing job to start...\n",
      "Waiting for the data drift model monitoring processing job to start...\n",
      "Waiting for the data drift model monitoring processing job to start...\n",
      "Waiting for the data drift model monitoring processing job to start...\n",
      "Waiting for the data drift model monitoring processing job to start...\n",
      "Waiting for the data drift model monitoring processing job to start...\n",
      "Waiting for the data drift model monitoring processing job to start...\n",
      "Waiting for the data drift model monitoring processing job to start...\n",
      "Waiting for the data drift model monitoring processing job to start...\n",
      "Waiting for the data drift model monitoring processing job to start...\n",
      "Waiting for the data drift model monitoring processing job to start...\n",
      "Waiting for the data drift model monitoring processing job to start...\n",
      "The data drift model monitoring processing job has started.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "MODEL_MONITOR_SCHEDULE_NAME = \"mlops-data-quality-schedule\"\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "monitoring_executions = sm_client.list_monitoring_executions(\n",
    "    MonitoringScheduleName=MODEL_MONITOR_SCHEDULE_NAME\n",
    ")\n",
    "\n",
    "# Check if monitoring job has started\n",
    "while not (monitoring_executions.get(\"MonitoringExecutionSummaries\")):\n",
    "\n",
    "    # Progress update\n",
    "    print(\"Waiting for the data drift model monitoring processing job to start...\")\n",
    "\n",
    "    # Pause for 60 seconds\n",
    "    time.sleep(60)\n",
    "\n",
    "    # Get the first monitoring execution details\n",
    "    monitoring_executions = sm_client.list_monitoring_executions(\n",
    "        MonitoringScheduleName=MODEL_MONITOR_SCHEDULE_NAME\n",
    "    )\n",
    "\n",
    "print(\"The data drift model monitoring processing job has started.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "33900936-c850-417f-8246-fd9bd3a5fc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We created a hourly schedule above and it will kick off executions ON the hour (plus 0 - 20 min buffer.\n",
      "We will have to wait till we hit the hour...\n"
     ]
    }
   ],
   "source": [
    "mon_executions = my_default_monitor.list_executions()\n",
    "print(\"We created a hourly schedule above and it will kick off executions ON the hour (plus 0 - 20 min buffer.\\nWe will have to wait till we hit the hour...\")\n",
    "\n",
    "while len(mon_executions) == 0:\n",
    "    print(\"Waiting for the 1st execution to happen...\")\n",
    "    time.sleep(60)\n",
    "    mon_executions = my_default_monitor.list_executions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "232c1316-fa58-45c2-802e-12f0e56bdcb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest execution status: Completed\n",
      "Latest execution result: Completed: Job completed successfully with no violations.\n"
     ]
    }
   ],
   "source": [
    "latest_execution = mon_executions[-1] # latest execution's index is -1, previous is -2 and so on..\n",
    "\n",
    "\n",
    "print(\"Latest execution status: {}\".format(latest_execution.describe()['ProcessingJobStatus']))\n",
    "print(\"Latest execution result: {}\".format(latest_execution.describe()['ExitMessage']))\n",
    "\n",
    "latest_job = latest_execution.describe()\n",
    "if (latest_job['ProcessingJobStatus'] != 'Completed'):\n",
    "        print(\"====STOP==== \\n No completed executions to inspect further. Please wait till an execution completes or investigate previously reported failures.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "36937906-80c8-4fd0-bfa9-ab2a7df5b9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report Uri: s3://sagemaker-us-west-2-846634201516/reports//CustomerChurn/mlops-data-quality-schedule/2024/03/31/00\n"
     ]
    }
   ],
   "source": [
    "report_uri=latest_execution.output.destination\n",
    "print('Report Uri: {}'.format(report_uri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c24ad999-a7aa-40ac-98de-551af8f1a3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report bucket: sagemaker-us-west-2-846634201516\n",
      "Report key: reports//CustomerChurn/mlops-data-quality-schedule/2024/03/31/00\n",
      "Found Report Files:\n",
      "reports//CustomerChurn/mlops-data-quality-schedule/2024/03/31/00/constraint_violations.json\n",
      " reports//CustomerChurn/mlops-data-quality-schedule/2024/03/31/00/constraints.json\n",
      " reports//CustomerChurn/mlops-data-quality-schedule/2024/03/31/00/statistics.json\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "s3uri = urlparse(report_uri)\n",
    "report_bucket = s3uri.netloc\n",
    "report_key = s3uri.path.lstrip('/')\n",
    "print('Report bucket: {}'.format(report_bucket))\n",
    "print('Report key: {}'.format(report_key))\n",
    "\n",
    "s3_client = boto3.Session().client('s3')\n",
    "result = s3_client.list_objects(Bucket=report_bucket, Prefix=report_key)\n",
    "report_files = [report_file.get(\"Key\") for report_file in result.get('Contents')]\n",
    "print(\"Found Report Files:\")\n",
    "print(\"\\n \".join(report_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cd185d2-90c7-4563-9692-4a0ed296c292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "MODEL_MONITOR_SCHEDULE_NAME = \"mlops-data-quality-schedule\"\n",
    "\n",
    "response = sm_client.delete_monitoring_schedule(\n",
    "    MonitoringScheduleName=MODEL_MONITOR_SCHEDULE_NAME\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b1a2bf7-1776-4d58-8ec7-fa97fff4edfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'c9939153-4670-4f91-a482-bdafbe4886e1',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'c9939153-4670-4f91-a482-bdafbe4886e1',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Sun, 31 Mar 2024 03:29:38 GMT',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name = \"CustomerChurn\"\n",
    "sm_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e388ab7d-5332-4b91-aadc-2da9d83af515",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
