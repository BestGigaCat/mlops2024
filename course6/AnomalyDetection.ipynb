{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4faba512",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "\n",
    "# Please fill in the following for enabling data capture\n",
    "s3_capture_upload_path = f\"s3://sagemaker-us-west-2-846634201516/monitoring/\"  # example: s3://bucket-name/path/to/endpoint-data-capture/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f8601d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "# SageMaker session\n",
    "sess = sagemaker.Session()\n",
    "# get session bucket name\n",
    "bucket = sess.default_bucket()\n",
    "# bucket prefix or the subfolder for everything we produce\n",
    "prefix = \"music-recommendation\"\n",
    "# get sagemaker role\n",
    "sagemaker_role = sagemaker.get_execution_role()\n",
    "# s3 client\n",
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "\n",
    "sagemaker_client = boto_session.client(service_name=\"sagemaker\", region_name=region)\n",
    "sagemaker_session = sagemaker.session.Session(\n",
    "    boto_session=boto_session, sagemaker_client=sagemaker_client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e927b990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!!CPU times: user 79.8 ms, sys: 1.65 ms, total: 81.4 ms\n",
      "Wall time: 3min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'EndpointName': 'CustomerChurn',\n",
       " 'EndpointArn': 'arn:aws:sagemaker:us-west-2:846634201516:endpoint/customerchurn',\n",
       " 'EndpointConfigName': 'CustomerChurn-2024-01-25-04-39-15-884',\n",
       " 'ProductionVariants': [{'VariantName': 'AllTraffic',\n",
       "   'DeployedImages': [{'SpecifiedImage': '433757028032.dkr.ecr.us-west-2.amazonaws.com/xgboost:latest',\n",
       "     'ResolvedImage': '433757028032.dkr.ecr.us-west-2.amazonaws.com/xgboost@sha256:0c8f830ac408e6dee08445fb60392e9c3f05f790a4b3c07ec22327c08f75bcbf',\n",
       "     'ResolutionTime': datetime.datetime(2024, 1, 25, 4, 39, 18, 560000, tzinfo=tzlocal())}],\n",
       "   'CurrentWeight': 1.0,\n",
       "   'DesiredWeight': 1.0,\n",
       "   'CurrentInstanceCount': 1,\n",
       "   'DesiredInstanceCount': 1}],\n",
       " 'DataCaptureConfig': {'EnableCapture': True,\n",
       "  'CaptureStatus': 'Started',\n",
       "  'CurrentSamplingPercentage': 100,\n",
       "  'DestinationS3Uri': 's3://sagemaker-us-west-2-846634201516/monitoring/'},\n",
       " 'EndpointStatus': 'InService',\n",
       " 'CreationTime': datetime.datetime(2024, 1, 25, 4, 33, 19, 148000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2024, 1, 25, 4, 42, 3, 253000, tzinfo=tzlocal()),\n",
       " 'ResponseMetadata': {'RequestId': 'f65689ce-b6fd-45a9-b838-be1b5b7a2f41',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'f65689ce-b6fd-45a9-b838-be1b5b7a2f41',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '860',\n",
       "   'date': 'Thu, 25 Jan 2024 04:42:17 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "endpoint_name = \"CustomerChurn\"\n",
    "predictor = sagemaker.predictor.Predictor(\n",
    "    endpoint_name=endpoint_name, sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "# Change parameters as you would like - adjust sampling percentage,\n",
    "#  chose to capture request or response or both\n",
    "data_capture_config = DataCaptureConfig(\n",
    "    enable_capture=True,\n",
    "    sampling_percentage=100,\n",
    "    destination_s3_uri=s3_capture_upload_path,\n",
    "    kms_key_id=None,\n",
    "    capture_options=[\"REQUEST\", \"RESPONSE\"],\n",
    "    csv_content_types=[\"text/csv\"],\n",
    "    json_content_types=[\"application/json\"],\n",
    ")\n",
    "\n",
    "# Now it is time to apply the new configuration and wait for it to be applied\n",
    "predictor.update_data_capture_config(data_capture_config=data_capture_config)\n",
    "sess.wait_for_endpoint(endpoint=endpoint_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecd89a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline data uri: s3://sagemaker-us-west-2-846634201516/ml_deploy/validation\n",
      "Baseline results uri: s3://sagemaker-us-west-2-846634201516/monitoring/baseline/results\n"
     ]
    }
   ],
   "source": [
    "##'s3://bucketname/path/to/baseline/data' - Where your validation data is\n",
    "baseline_data_uri = f\"s3://sagemaker-us-west-2-846634201516/ml_deploy/validation\"\n",
    "##'s3://bucketname/path/to/baseline/data' - Where the results are to be stored in\n",
    "baseline_results_uri = f\"s3://sagemaker-us-west-2-846634201516/monitoring/baseline/results\"\n",
    "\n",
    "print(\"Baseline data uri: {}\".format(baseline_data_uri))\n",
    "print(\"Baseline results uri: {}\".format(baseline_results_uri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "938bc550",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "from sagemaker import get_execution_role\n",
    "import datetime\n",
    "\n",
    "role = get_execution_role(sagemaker_session=sess)\n",
    "prefix = \"customerchurn\"\n",
    "\n",
    "datetime_stamp = datetime.datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")\n",
    "\n",
    "my_default_monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=1800,\n",
    "    base_job_name=f\"{prefix}-monitor-{datetime_stamp}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bcd9537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  customerchurn-monitor-baseline-2024-01-25-044606\n",
      "Inputs:  [{'InputName': 'baseline_dataset_input', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-west-2-846634201516/ml_deploy/validation', 'LocalPath': '/opt/ml/processing/input/baseline_dataset_input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'monitoring_output', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-west-2-846634201516/monitoring/baseline/results', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      "...............................\u001b[34m2024-01-25 04:51:04.522789: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:04.522829: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:07.360038: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:07.360072: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:07.360098: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-0-83-226.us-west-2.compute.internal): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:07.360670: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:09,347 - __main__ - INFO - All params:{'ProcessingJobArn': 'arn:aws:sagemaker:us-west-2:846634201516:processing-job/customerchurn-monitor-baseline-2024-01-25-044606', 'ProcessingJobName': 'customerchurn-monitor-baseline-2024-01-25-044606', 'Environment': {'dataset_format': '{\"csv\": {\"header\": false, \"output_columns_position\": \"START\"}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}, 'AppSpecification': {'ImageUri': '159807026194.dkr.ecr.us-west-2.amazonaws.com/sagemaker-model-monitor-analyzer', 'ContainerEntrypoint': None, 'ContainerArguments': None}, 'ProcessingInputs': [{'InputName': 'baseline_dataset_input', 'AppManaged': False, 'S3Input': {'LocalPath': '/opt/ml/processing/input/baseline_dataset_input', 'S3Uri': 's3://sagemaker-us-west-2-846634201516/ml_deploy/validation', 'S3DataDistributionType': 'FullyReplicated', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3CompressionType': 'None', 'S3DownloadMode': 'StartOfJob'}, 'DatasetDefinition': None}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'monitoring_output', 'AppManaged': False, 'S3Output': {'LocalPath': '/opt/ml/processing/output', 'S3Uri': 's3://sagemaker-us-west-2-846634201516/monitoring/baseline/results', 'S3UploadMode': 'EndOfJob'}, 'FeatureStoreOutput': None}], 'KmsKeyId': None}, 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1, 'InstanceType': 'ml.m5.large', 'VolumeSizeInGB': 20, 'VolumeKmsKeyId': None}}, 'RoleArn': 'arn:aws:iam::846634201516:role/AmazonMWAA-SageMaker-Role', 'StoppingCondition': {'MaxRuntimeInSeconds': 1800}}\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:09,347 - __main__ - INFO - Current Environment:{'dataset_format': '{\"csv\": {\"header\": false, \"output_columns_position\": \"START\"}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:09,347 - __main__ - INFO - categorical_drift_method:None\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:09,347 - DefaultDataAnalyzer - INFO - Performing analysis with input: {\"dataset_source\": \"/opt/ml/processing/input/baseline_dataset_input\", \"dataset_format\": {\"csv\": {\"header\": false, \"output_columns_position\": \"START\"}}, \"output_path\": \"/opt/ml/processing/output\", \"monitoring_input_type\": null, \"analysis_type\": null, \"problem_type\": null, \"inference_attribute\": null, \"probability_attribute\": null, \"ground_truth_attribute\": null, \"probability_threshold_attribute\": null, \"positive_label\": null, \"exclude_features_attribute\": null, \"record_preprocessor_script\": null, \"post_analytics_processor_script\": null, \"baseline_constraints\": null, \"baseline_statistics\": null, \"data_quality_monitoring_config\": {\"evaluate_constraints\": \"Enabled\", \"emit_metrics\": \"Enabled\", \"datatype_check_threshold\": 1.0, \"domain_content_threshold\": 1.0, \"distribution_constraints\": {\"perform_comparison\": \"Enabled\", \"comparison_threshold\": 0.1, \"comparison_method\": \"Robust\", \"categorical_comparison_threshold\": 0.1, \"categorical_drift_method\": \"LInfinity\"}}, \"start_time\": null, \"end_time\": null, \"metric_time\": null, \"cloudwatch_metrics_directory\": \"/opt/ml/output/metrics/cloudwatch\", \"publish_cloudwatch_metrics\": \"Disabled\", \"sagemaker_endpoint_name\": null, \"sagemaker_monitoring_schedule_name\": null, \"output_message_file\": \"/opt/ml/output/message\", \"detect_outliers\": null, \"detect_drift\": null, \"image_data\": null, \"report_enabled\": false, \"auto_ml_job_detail\": null}\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:09,348 - DefaultDataAnalyzer - INFO - Bootstrapping yarn\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:09,348 - bootstrap - INFO - Copy aws jars\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:09,697 - bootstrap - INFO - Copy cluster config\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:09,698 - bootstrap - INFO - Write runtime cluster config\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:09,699 - bootstrap - INFO - Resource Config is: {'current_host': 'algo-1', 'hosts': ['algo-1']}\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:09,711 - bootstrap - INFO - Finished Yarn configuration files setup.\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:09,711 - bootstrap - INFO - Starting spark process for master node algo-1\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:09,712 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs namenode -format -force\u001b[0m\n",
      "\u001b[34mWARNING: /usr/hadoop-3.0.0/logs does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:11,312 INFO namenode.NameNode: STARTUP_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG: Starting NameNode\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   host = algo-1/10.0.83.226\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   args = [-format, -force]\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   version = 3.0.0\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   classpath = /usr/hadoop-3.0.0/etc/hadoop:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/junit-4.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-aws-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/aws-java-sdk-bundle-1.11.199.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-kms-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okio-1.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-2.2.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-prefix-tree-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-common-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-api-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/fst-2.50.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-csv-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-procedure-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-protocol-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jamon-runtime-2.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/servlet-api-2.5-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/joni-2.1.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-client-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-client-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-math-2.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-el-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-annotations-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-server-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-compiler-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/htrace-core-3.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jcodings-1.0.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/disruptor-3.3.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop2-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/findbugs-annotations-1.3.9-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-runtime-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-api-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn\u001b[0m\n",
      "\u001b[34m/hadoop-yarn-server-nodemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-router-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-registry-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-client-3.0.0.jar\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r c25427ceca461ee979d30edd7a4b0f50718e6533; compiled by 'andrew' on 2017-12-08T19:16Z\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   java = 1.8.0_392\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:11,353 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:11,359 INFO namenode.NameNode: createNameNode [-format, -force]\u001b[0m\n",
      "\u001b[34mFormatting using clusterid: CID-19854d38-2e27-4b6c-8f22-6e2b3bc99fdd\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,357 INFO namenode.FSEditLog: Edit logging is async:true\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,380 INFO namenode.FSNamesystem: KeyProvider: null\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,381 INFO namenode.FSNamesystem: fsLock is fair: true\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,385 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,401 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,401 INFO namenode.FSNamesystem: supergroup          = supergroup\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,401 INFO namenode.FSNamesystem: isPermissionEnabled = true\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,402 INFO namenode.FSNamesystem: HA Enabled: false\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,462 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,484 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,485 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,489 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,494 INFO blockmanagement.BlockManager: The block deletion will start around 2024 Jan 25 04:51:12\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,496 INFO util.GSet: Computing capacity for map BlocksMap\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,496 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,500 INFO util.GSet: 2.0% max memory 1.4 GB = 27.7 MB\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,500 INFO util.GSet: capacity      = 2^22 = 4194304 entries\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,557 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,561 INFO Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,561 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,561 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,561 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,562 INFO blockmanagement.BlockManager: defaultReplication         = 3\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,562 INFO blockmanagement.BlockManager: maxReplication             = 512\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,562 INFO blockmanagement.BlockManager: minReplication             = 1\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,562 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,562 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,562 INFO blockmanagement.BlockManager: encryptDataTransfer        = false\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,562 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,602 INFO util.GSet: Computing capacity for map INodeMap\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,602 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,602 INFO util.GSet: 1.0% max memory 1.4 GB = 13.8 MB\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,602 INFO util.GSet: capacity      = 2^21 = 2097152 entries\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,603 INFO namenode.FSDirectory: ACLs enabled? false\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,603 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,603 INFO namenode.FSDirectory: XAttrs enabled? true\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,604 INFO namenode.NameNode: Caching file names occurring more than 10 times\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,609 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,614 INFO util.GSet: Computing capacity for map cachedBlocks\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,614 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,614 INFO util.GSet: 0.25% max memory 1.4 GB = 3.5 MB\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,614 INFO util.GSet: capacity      = 2^19 = 524288 entries\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,623 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,624 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,624 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,628 INFO namenode.FSNamesystem: Retry cache on namenode is enabled\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,628 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,632 INFO util.GSet: Computing capacity for map NameNodeRetryCache\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,632 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,632 INFO util.GSet: 0.029999999329447746% max memory 1.4 GB = 425.0 KB\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,632 INFO util.GSet: capacity      = 2^16 = 65536 entries\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,666 INFO namenode.FSImage: Allocated new BlockPoolId: BP-610785931-10.0.83.226-1706158272657\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,684 INFO common.Storage: Storage directory /opt/amazon/hadoop/hdfs/namenode has been successfully formatted.\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,698 INFO namenode.FSImageFormatProtobuf: Saving image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 using no compression\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,812 INFO namenode.FSImageFormatProtobuf: Image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 of size 389 bytes saved in 0 seconds.\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,834 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,841 INFO namenode.NameNode: SHUTDOWN_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSHUTDOWN_MSG: Shutting down NameNode at algo-1/10.0.83.226\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:12,850 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:14,923 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode, return code 1\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:14,923 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:17,132 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode, return code 1\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:17,132 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34mWARNING: /var/log/yarn/ does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:19,607 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager, return code 1\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:19,607 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:22,180 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager, return code 1\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:22,180 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:24,586 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver, return code 1\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:24,586 - DefaultDataAnalyzer - INFO - Total number of hosts in the cluster: 1\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:34,597 - DefaultDataAnalyzer - INFO - Running command: bin/spark-submit --master yarn --deploy-mode client --conf spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider --conf spark.serializer=org.apache.spark.serializer.KryoSerializer /opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar --analytics_input /tmp/spark_job_config.json\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:37,181 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:37,787 INFO Main: Start analyzing with args: --analytics_input /tmp/spark_job_config.json\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:37,852 INFO Main: Analytics input path: DataAnalyzerParams(/tmp/spark_job_config.json,yarn)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:37,873 INFO FileUtil: Read file from path /tmp/spark_job_config.json.\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:38,691 INFO spark.SparkContext: Running Spark version 3.3.0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:38,733 INFO resource.ResourceUtils: ==============================================================\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:38,733 INFO resource.ResourceUtils: No custom resources configured for spark.driver.\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:38,734 INFO resource.ResourceUtils: ==============================================================\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:38,734 INFO spark.SparkContext: Submitted application: SageMakerDataAnalyzer\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:38,785 INFO resource.ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 5684, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:38,801 INFO resource.ResourceProfile: Limiting resource is cpus at 1 tasks per executor\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:38,803 INFO resource.ResourceProfileManager: Added ResourceProfile id: 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:38,886 INFO spark.SecurityManager: Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:38,887 INFO spark.SecurityManager: Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:38,887 INFO spark.SecurityManager: Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:38,887 INFO spark.SecurityManager: Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:38,888 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:39,442 INFO util.Utils: Successfully started service 'sparkDriver' on port 36001.\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:39,490 INFO spark.SparkEnv: Registering MapOutputTracker\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:39,542 INFO spark.SparkEnv: Registering BlockManagerMaster\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:39,575 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:39,576 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:39,623 INFO spark.SparkEnv: Registering BlockManagerMasterHeartbeat\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:39,677 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-405ffae1-451c-4e9e-932e-a3842d0524f8\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:39,702 INFO memory.MemoryStore: MemoryStore started with capacity 1458.6 MiB\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:39,768 INFO spark.SparkEnv: Registering OutputCommitCoordinator\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:39,818 INFO spark.SparkContext: Added JAR file:/opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar at spark://10.0.83.226:36001/jars/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar with timestamp 1706158298682\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:40,666 INFO client.RMProxy: Connecting to ResourceManager at /10.0.83.226:8032\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:41,705 INFO conf.Configuration: resource-types.xml not found\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:41,714 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:41,723 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (7751 MB per container)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:41,723 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:41,724 INFO yarn.Client: Setting up container launch context for our AM\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:41,724 INFO yarn.Client: Setting up the launch environment for our AM container\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:41,735 INFO yarn.Client: Preparing resources for our AM container\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:41,850 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:44,257 INFO yarn.Client: Uploading resource file:/tmp/spark-738fa2d0-2e96-49bd-9678-05c51cbd14e8/__spark_libs__1314747885320855305.zip -> hdfs://10.0.83.226/user/root/.sparkStaging/application_1706158281778_0001/__spark_libs__1314747885320855305.zip\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:46,614 INFO yarn.Client: Uploading resource file:/tmp/spark-738fa2d0-2e96-49bd-9678-05c51cbd14e8/__spark_conf__8839160348299019610.zip -> hdfs://10.0.83.226/user/root/.sparkStaging/application_1706158281778_0001/__spark_conf__.zip\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:46,677 INFO spark.SecurityManager: Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:46,678 INFO spark.SecurityManager: Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:46,678 INFO spark.SecurityManager: Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:46,678 INFO spark.SecurityManager: Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:46,679 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:46,720 INFO yarn.Client: Submitting application application_1706158281778_0001 to ResourceManager\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:46,988 INFO impl.YarnClientImpl: Submitted application application_1706158281778_0001\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:47,993 INFO yarn.Client: Application report for application_1706158281778_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:47,999 INFO yarn.Client: \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: AM container is launched, waiting for AM container to Register with RM\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: -1\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1706158306837\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1706158281778_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:49,004 INFO yarn.Client: Application report for application_1706158281778_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:50,131 INFO yarn.Client: Application report for application_1706158281778_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:51,137 INFO yarn.Client: Application report for application_1706158281778_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:52,145 INFO yarn.Client: Application report for application_1706158281778_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:53,151 INFO yarn.Client: Application report for application_1706158281778_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:53,906 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> algo-1, PROXY_URI_BASES -> http://algo-1:8088/proxy/application_1706158281778_0001), /proxy/application_1706158281778_0001\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:54,157 INFO yarn.Client: Application report for application_1706158281778_0001 (state: RUNNING)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:54,157 INFO yarn.Client: \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: 10.0.83.226\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: -1\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1706158306837\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1706158281778_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:54,159 INFO cluster.YarnClientSchedulerBackend: Application application_1706158281778_0001 has started running.\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:54,199 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42275.\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:54,199 INFO netty.NettyBlockTransferService: Server created on 10.0.83.226:42275\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:54,202 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:54,225 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.0.83.226, 42275, None)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:54,234 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.0.83.226:42275 with 1458.6 MiB RAM, BlockManagerId(driver, 10.0.83.226, 42275, None)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:54,244 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.0.83.226, 42275, None)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:54,245 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.0.83.226, 42275, None)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:54,451 INFO util.log: Logging initialized @19418ms to org.sparkproject.jetty.util.log.Slf4jLog\u001b[0m\n",
      "\u001b[34m2024-01-25 04:51:56,685 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:01,463 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.83.226:44946) with ID 1,  ResourceProfileId 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:01,763 INFO storage.BlockManagerMasterEndpoint: Registering block manager algo-1:41051 with 2.8 GiB RAM, BlockManagerId(1, algo-1, 41051, None)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:10,500 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000000000(ns)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:10,632 WARN spark.SparkContext: Spark is not running in local mode, therefore the checkpoint directory must not be on the local filesystem. Directory '/tmp' appears to be on the local filesystem.\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:10,675 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:10,678 INFO internal.SharedState: Warehouse path is 'file:/usr/spark-3.3.0/spark-warehouse'.\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:11,709 INFO datasources.InMemoryFileIndex: It took 60 ms to list leaf files for 1 paths.\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:11,946 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 417.0 KiB, free 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:12,294 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 39.1 KiB, free 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:12,297 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.83.226:42275 (size: 39.1 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:12,302 INFO spark.SparkContext: Created broadcast 0 from csv at DatasetReader.scala:99\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:12,805 INFO input.FileInputFormat: Total input files to process : 1\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:12,810 INFO input.FileInputFormat: Total input files to process : 1\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:12,817 INFO input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 484595\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:12,928 INFO spark.SparkContext: Starting job: csv at DatasetReader.scala:99\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:12,951 INFO scheduler.DAGScheduler: Got job 0 (csv at DatasetReader.scala:99) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:12,952 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (csv at DatasetReader.scala:99)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:12,954 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:12,956 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:12,963 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at csv at DatasetReader.scala:99), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:13,086 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.3 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:13,093 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:13,094 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.83.226:42275 (size: 4.2 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:13,095 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:13,126 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at csv at DatasetReader.scala:99) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:13,128 INFO cluster.YarnScheduler: Adding task set 0.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:13,186 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4668 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:13,692 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on algo-1:41051 (size: 4.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:15,077 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on algo-1:41051 (size: 39.1 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:15,651 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2486 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:15,654 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:15,669 INFO scheduler.DAGScheduler: ResultStage 0 (csv at DatasetReader.scala:99) finished in 2.655 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:15,679 INFO scheduler.DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:15,682 INFO cluster.YarnScheduler: Killing all running tasks in stage 0: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:15,687 INFO scheduler.DAGScheduler: Job 0 finished: csv at DatasetReader.scala:99, took 2.759468 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:15,999 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on 10.0.83.226:42275 in memory (size: 4.2 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:16,011 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on algo-1:41051 in memory (size: 4.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:19,070 INFO datasources.FileSourceStrategy: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:19,072 INFO datasources.FileSourceStrategy: Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:19,076 INFO datasources.FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 98 more fields>\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:19,137 WARN util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:19,522 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 416.5 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:19,546 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 39.1 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:19,547 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.0.83.226:42275 (size: 39.1 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:19,548 INFO spark.SparkContext: Created broadcast 2 from head at DataAnalyzer.scala:124\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:19,575 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:19,633 INFO spark.SparkContext: Starting job: head at DataAnalyzer.scala:124\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:19,635 INFO scheduler.DAGScheduler: Got job 1 (head at DataAnalyzer.scala:124) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:19,635 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (head at DataAnalyzer.scala:124)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:19,635 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:19,638 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:19,643 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[11] at head at DataAnalyzer.scala:124), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:19,742 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 35.7 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:19,748 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:19,749 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.0.83.226:42275 (size: 13.4 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:19,753 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:19,754 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[11] at head at DataAnalyzer.scala:124) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:19,754 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:19,759 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:19,829 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on algo-1:41051 (size: 13.4 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:21,230 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on algo-1:41051 (size: 39.1 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:21,671 INFO storage.BlockManagerInfo: Added rdd_7_0 in memory on algo-1:41051 (size: 177.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:22,049 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 2293 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:22,049 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:22,051 INFO scheduler.DAGScheduler: ResultStage 1 (head at DataAnalyzer.scala:124) finished in 2.402 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:22,055 INFO scheduler.DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:22,055 INFO cluster.YarnScheduler: Killing all running tasks in stage 1: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:22,055 INFO scheduler.DAGScheduler: Job 1 finished: head at DataAnalyzer.scala:124, took 2.422034 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:22,777 INFO codegen.CodeGenerator: Code generated in 537.78923 ms\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:23,676 INFO scheduler.DAGScheduler: Registering RDD 16 (collect at AnalysisRunner.scala:326) as input to shuffle 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:23,680 INFO scheduler.DAGScheduler: Got map stage job 2 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:23,681 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 2 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:23,681 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:23,684 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:23,689 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[16] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:23,731 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 131.0 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:23,734 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 39.9 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:23,735 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.0.83.226:42275 (size: 39.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:23,737 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:23,739 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[16] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:23,739 INFO cluster.YarnScheduler: Adding task set 2.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:23,749 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:23,774 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on algo-1:41051 (size: 39.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:25,322 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1575 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:25,323 INFO cluster.YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:25,327 INFO scheduler.DAGScheduler: ShuffleMapStage 2 (collect at AnalysisRunner.scala:326) finished in 1.630 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:25,327 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:25,328 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:25,329 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:25,329 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:25,445 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:25,448 INFO scheduler.DAGScheduler: Got job 3 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:25,449 INFO scheduler.DAGScheduler: Final stage: ResultStage 4 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:25,449 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:25,449 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:25,450 INFO scheduler.DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[19] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:25,472 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 183.5 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:25,475 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 50.2 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:25,475 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.0.83.226:42275 (size: 50.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:25,476 INFO spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:25,477 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[19] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:25,477 INFO cluster.YarnScheduler: Adding task set 4.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:25,485 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:25,511 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on algo-1:41051 (size: 50.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:25,595 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:26,044 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 560 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:26,045 INFO scheduler.DAGScheduler: ResultStage 4 (collect at AnalysisRunner.scala:326) finished in 0.580 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:26,046 INFO scheduler.DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:26,046 INFO cluster.YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:26,047 INFO cluster.YarnScheduler: Killing all running tasks in stage 4: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:26,047 INFO scheduler.DAGScheduler: Job 3 finished: collect at AnalysisRunner.scala:326, took 0.601845 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:26,116 INFO codegen.CodeGenerator: Code generated in 47.417922 ms\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:26,586 INFO codegen.CodeGenerator: Code generated in 39.535007 ms\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:26,679 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:26,682 INFO scheduler.DAGScheduler: Got job 4 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:26,682 INFO scheduler.DAGScheduler: Final stage: ResultStage 5 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:26,682 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:26,683 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:26,688 INFO scheduler.DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[29] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:26,709 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 54.9 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:26,754 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 20.8 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:26,764 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.0.83.226:42275 (size: 20.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:26,766 INFO spark.SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:26,767 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[29] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:26,767 INFO cluster.YarnScheduler: Adding task set 5.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:26,770 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:26,786 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on algo-1:41051 in memory (size: 13.4 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:26,800 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on algo-1:41051 (size: 20.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:26,801 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on 10.0.83.226:42275 in memory (size: 13.4 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:26,858 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on 10.0.83.226:42275 in memory (size: 39.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:26,876 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on algo-1:41051 in memory (size: 39.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:26,935 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on 10.0.83.226:42275 in memory (size: 50.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:26,944 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on algo-1:41051 in memory (size: 50.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:27,329 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 560 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:27,332 INFO scheduler.DAGScheduler: ResultStage 5 (treeReduce at KLLRunner.scala:107) finished in 0.643 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:27,332 INFO scheduler.DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:27,335 INFO cluster.YarnScheduler: Removed TaskSet 5.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:27,335 INFO cluster.YarnScheduler: Killing all running tasks in stage 5: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:27,336 INFO scheduler.DAGScheduler: Job 4 finished: treeReduce at KLLRunner.scala:107, took 0.655750 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,344 INFO codegen.CodeGenerator: Code generated in 165.084509 ms\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,356 INFO scheduler.DAGScheduler: Registering RDD 34 (collect at AnalysisRunner.scala:326) as input to shuffle 1\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,357 INFO scheduler.DAGScheduler: Got map stage job 5 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,357 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 6 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,357 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,358 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,364 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[34] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,372 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 90.7 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,374 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,376 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.0.83.226:42275 (size: 27.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,380 INFO spark.SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,383 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[34] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,384 INFO cluster.YarnScheduler: Adding task set 6.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,388 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 5) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,407 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on algo-1:41051 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,606 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 6.0 (TID 5) in 218 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,609 INFO cluster.YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,611 INFO scheduler.DAGScheduler: ShuffleMapStage 6 (collect at AnalysisRunner.scala:326) finished in 0.245 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,612 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,613 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,614 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,614 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,842 INFO codegen.CodeGenerator: Code generated in 115.412368 ms\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,855 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,856 INFO scheduler.DAGScheduler: Got job 6 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,856 INFO scheduler.DAGScheduler: Final stage: ResultStage 8 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,856 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,857 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,858 INFO scheduler.DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[37] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,868 INFO memory.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 66.2 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,873 INFO memory.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,874 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.0.83.226:42275 (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,876 INFO spark.SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,878 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[37] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,878 INFO cluster.YarnScheduler: Adding task set 8.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,880 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 8.0 (TID 6) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,906 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on algo-1:41051 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:28,924 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:29,071 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 8.0 (TID 6) in 192 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:29,071 INFO cluster.YarnScheduler: Removed TaskSet 8.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:29,072 INFO scheduler.DAGScheduler: ResultStage 8 (collect at AnalysisRunner.scala:326) finished in 0.210 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:29,073 INFO scheduler.DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:29,073 INFO cluster.YarnScheduler: Killing all running tasks in stage 8: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:29,073 INFO scheduler.DAGScheduler: Job 6 finished: collect at AnalysisRunner.scala:326, took 0.218269 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:29,197 INFO codegen.CodeGenerator: Code generated in 87.613409 ms\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:29,361 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:29,367 INFO scheduler.DAGScheduler: Registering RDD 45 (countByKey at ColumnProfiler.scala:592) as input to shuffle 2\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:29,368 INFO scheduler.DAGScheduler: Got job 7 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:29,368 INFO scheduler.DAGScheduler: Final stage: ResultStage 10 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:29,368 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:29,368 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 9)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:29,372 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[45] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:29,389 INFO memory.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 47.1 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:29,394 INFO memory.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:29,395 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.0.83.226:42275 (size: 18.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:29,398 INFO spark.SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:29,401 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[45] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:29,401 INFO cluster.YarnScheduler: Adding task set 9.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:29,402 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 9.0 (TID 7) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:29,419 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on algo-1:41051 (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,183 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 9.0 (TID 7) in 1780 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,184 INFO scheduler.DAGScheduler: ShuffleMapStage 9 (countByKey at ColumnProfiler.scala:592) finished in 1.811 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,184 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,185 INFO cluster.YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,185 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,186 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 10)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,186 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,187 INFO scheduler.DAGScheduler: Submitting ResultStage 10 (ShuffledRDD[46] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,195 INFO memory.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 5.1 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,199 INFO memory.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,200 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.0.83.226:42275 (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,202 INFO spark.SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,203 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (ShuffledRDD[46] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,205 INFO cluster.YarnScheduler: Adding task set 10.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,208 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 10.0 (TID 8) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,230 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on algo-1:41051 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,240 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,302 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 10.0 (TID 8) in 95 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,302 INFO cluster.YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,303 INFO scheduler.DAGScheduler: ResultStage 10 (countByKey at ColumnProfiler.scala:592) finished in 0.116 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,303 INFO scheduler.DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,303 INFO cluster.YarnScheduler: Killing all running tasks in stage 10: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,304 INFO scheduler.DAGScheduler: Job 7 finished: countByKey at ColumnProfiler.scala:592, took 1.942645 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,666 INFO scheduler.DAGScheduler: Registering RDD 51 (collect at AnalysisRunner.scala:326) as input to shuffle 3\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,666 INFO scheduler.DAGScheduler: Got map stage job 8 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,667 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 11 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,667 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,668 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,670 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[51] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,682 INFO memory.MemoryStore: Block broadcast_11 stored as values in memory (estimated size 100.0 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,686 INFO memory.MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,687 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.0.83.226:42275 (size: 32.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,688 INFO spark.SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,689 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[51] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,689 INFO cluster.YarnScheduler: Adding task set 11.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,691 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 11.0 (TID 9) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,713 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on algo-1:41051 (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,968 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 11.0 (TID 9) in 277 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,968 INFO cluster.YarnScheduler: Removed TaskSet 11.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,970 INFO scheduler.DAGScheduler: ShuffleMapStage 11 (collect at AnalysisRunner.scala:326) finished in 0.297 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,971 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,972 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,972 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:31,972 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,054 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,056 INFO scheduler.DAGScheduler: Got job 9 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,056 INFO scheduler.DAGScheduler: Final stage: ResultStage 13 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,056 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,056 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,058 INFO scheduler.DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[54] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,072 INFO memory.MemoryStore: Block broadcast_12 stored as values in memory (estimated size 184.6 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,075 INFO memory.MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 50.2 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,078 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.0.83.226:42275 (size: 50.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,079 INFO spark.SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,080 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[54] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,080 INFO cluster.YarnScheduler: Adding task set 13.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,086 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 13.0 (TID 10) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,102 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on algo-1:41051 (size: 50.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,144 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,321 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 13.0 (TID 10) in 235 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,322 INFO scheduler.DAGScheduler: ResultStage 13 (collect at AnalysisRunner.scala:326) finished in 0.263 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,323 INFO scheduler.DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,324 INFO cluster.YarnScheduler: Removed TaskSet 13.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,324 INFO cluster.YarnScheduler: Killing all running tasks in stage 13: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,325 INFO scheduler.DAGScheduler: Job 9 finished: collect at AnalysisRunner.scala:326, took 0.269596 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,652 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on algo-1:41051 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,656 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on 10.0.83.226:42275 in memory (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,682 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,683 INFO scheduler.DAGScheduler: Got job 10 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,684 INFO scheduler.DAGScheduler: Final stage: ResultStage 14 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,684 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,685 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,694 INFO scheduler.DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[64] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,714 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on algo-1:41051 in memory (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,726 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on 10.0.83.226:42275 in memory (size: 18.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,758 INFO memory.MemoryStore: Block broadcast_13 stored as values in memory (estimated size 54.8 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,763 INFO memory.MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,764 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.0.83.226:42275 (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,766 INFO spark.SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,767 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[64] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,767 INFO cluster.YarnScheduler: Adding task set 14.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,769 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 14.0 (TID 11) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,800 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on algo-1:41051 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,813 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on 10.0.83.226:42275 in memory (size: 27.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,820 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on algo-1:41051 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,878 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on 10.0.83.226:42275 in memory (size: 20.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,885 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on algo-1:41051 in memory (size: 20.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,897 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 14.0 (TID 11) in 128 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,897 INFO cluster.YarnScheduler: Removed TaskSet 14.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,898 INFO scheduler.DAGScheduler: ResultStage 14 (treeReduce at KLLRunner.scala:107) finished in 0.201 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,899 INFO scheduler.DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,899 INFO cluster.YarnScheduler: Killing all running tasks in stage 14: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,900 INFO scheduler.DAGScheduler: Job 10 finished: treeReduce at KLLRunner.scala:107, took 0.218026 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,953 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on algo-1:41051 in memory (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:32,961 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on 10.0.83.226:42275 in memory (size: 32.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,005 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on algo-1:41051 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,006 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on 10.0.83.226:42275 in memory (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,126 INFO storage.BlockManagerInfo: Removed broadcast_12_piece0 on algo-1:41051 in memory (size: 50.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,146 INFO storage.BlockManagerInfo: Removed broadcast_12_piece0 on 10.0.83.226:42275 in memory (size: 50.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,262 INFO scheduler.DAGScheduler: Registering RDD 69 (collect at AnalysisRunner.scala:326) as input to shuffle 4\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,265 INFO scheduler.DAGScheduler: Got map stage job 11 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,265 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 15 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,265 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,266 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,267 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[69] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,272 INFO memory.MemoryStore: Block broadcast_14 stored as values in memory (estimated size 90.7 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,275 INFO memory.MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,276 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.0.83.226:42275 (size: 27.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,277 INFO spark.SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,277 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[69] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,277 INFO cluster.YarnScheduler: Adding task set 15.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,279 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 15.0 (TID 12) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,297 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on algo-1:41051 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,344 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 15.0 (TID 12) in 65 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,345 INFO cluster.YarnScheduler: Removed TaskSet 15.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,347 INFO scheduler.DAGScheduler: ShuffleMapStage 15 (collect at AnalysisRunner.scala:326) finished in 0.079 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,348 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,348 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,348 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,348 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,483 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,484 INFO scheduler.DAGScheduler: Got job 12 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,484 INFO scheduler.DAGScheduler: Final stage: ResultStage 17 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,484 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,485 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,487 INFO scheduler.DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[72] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,489 INFO memory.MemoryStore: Block broadcast_15 stored as values in memory (estimated size 66.2 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,491 INFO memory.MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,491 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on 10.0.83.226:42275 (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,492 INFO spark.SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,492 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[72] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,492 INFO cluster.YarnScheduler: Adding task set 17.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,494 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 17.0 (TID 13) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,521 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on algo-1:41051 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,533 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,552 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 17.0 (TID 13) in 58 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,553 INFO cluster.YarnScheduler: Removed TaskSet 17.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,553 INFO scheduler.DAGScheduler: ResultStage 17 (collect at AnalysisRunner.scala:326) finished in 0.065 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,554 INFO scheduler.DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,554 INFO cluster.YarnScheduler: Killing all running tasks in stage 17: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,554 INFO scheduler.DAGScheduler: Job 12 finished: collect at AnalysisRunner.scala:326, took 0.071171 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,622 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,623 INFO scheduler.DAGScheduler: Registering RDD 80 (countByKey at ColumnProfiler.scala:592) as input to shuffle 5\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,625 INFO scheduler.DAGScheduler: Got job 13 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,625 INFO scheduler.DAGScheduler: Final stage: ResultStage 19 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,625 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,626 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 18)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,629 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[80] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,638 INFO memory.MemoryStore: Block broadcast_16 stored as values in memory (estimated size 47.1 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,644 INFO memory.MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,644 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.0.83.226:42275 (size: 18.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,649 INFO spark.SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,653 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[80] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,653 INFO cluster.YarnScheduler: Adding task set 18.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,655 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 18.0 (TID 14) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,673 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on algo-1:41051 (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,784 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 18.0 (TID 14) in 129 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,784 INFO cluster.YarnScheduler: Removed TaskSet 18.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,785 INFO scheduler.DAGScheduler: ShuffleMapStage 18 (countByKey at ColumnProfiler.scala:592) finished in 0.154 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,787 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,788 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,788 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 19)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,788 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,788 INFO scheduler.DAGScheduler: Submitting ResultStage 19 (ShuffledRDD[81] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,791 INFO memory.MemoryStore: Block broadcast_17 stored as values in memory (estimated size 5.1 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,793 INFO memory.MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,794 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.0.83.226:42275 (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,795 INFO spark.SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,797 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (ShuffledRDD[81] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,797 INFO cluster.YarnScheduler: Adding task set 19.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,799 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 19.0 (TID 15) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,814 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on algo-1:41051 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,820 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,861 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 19.0 (TID 15) in 62 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,866 INFO cluster.YarnScheduler: Removed TaskSet 19.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,867 INFO scheduler.DAGScheduler: ResultStage 19 (countByKey at ColumnProfiler.scala:592) finished in 0.078 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,869 INFO scheduler.DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,869 INFO cluster.YarnScheduler: Killing all running tasks in stage 19: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:33,870 INFO scheduler.DAGScheduler: Job 13 finished: countByKey at ColumnProfiler.scala:592, took 0.247519 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,085 INFO scheduler.DAGScheduler: Registering RDD 86 (collect at AnalysisRunner.scala:326) as input to shuffle 6\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,086 INFO scheduler.DAGScheduler: Got map stage job 14 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,086 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 20 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,086 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,089 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,090 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[86] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,097 INFO memory.MemoryStore: Block broadcast_18 stored as values in memory (estimated size 100.0 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,100 INFO memory.MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,101 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.0.83.226:42275 (size: 32.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,103 INFO spark.SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,103 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[86] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,103 INFO cluster.YarnScheduler: Adding task set 20.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,105 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 20.0 (TID 16) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,118 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on algo-1:41051 (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,331 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 20.0 (TID 16) in 226 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,331 INFO cluster.YarnScheduler: Removed TaskSet 20.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,334 INFO scheduler.DAGScheduler: ShuffleMapStage 20 (collect at AnalysisRunner.scala:326) finished in 0.240 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,339 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,339 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,339 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,339 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,415 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,417 INFO scheduler.DAGScheduler: Got job 15 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,417 INFO scheduler.DAGScheduler: Final stage: ResultStage 22 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,418 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,418 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,419 INFO scheduler.DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[89] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,426 INFO memory.MemoryStore: Block broadcast_19 stored as values in memory (estimated size 184.6 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,430 INFO memory.MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,431 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.0.83.226:42275 (size: 50.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,431 INFO spark.SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,432 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[89] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,432 INFO cluster.YarnScheduler: Adding task set 22.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,433 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 22.0 (TID 17) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,457 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on algo-1:41051 (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,479 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,606 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 22.0 (TID 17) in 173 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,606 INFO cluster.YarnScheduler: Removed TaskSet 22.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,607 INFO scheduler.DAGScheduler: ResultStage 22 (collect at AnalysisRunner.scala:326) finished in 0.187 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,609 INFO scheduler.DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,609 INFO cluster.YarnScheduler: Killing all running tasks in stage 22: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,610 INFO scheduler.DAGScheduler: Job 15 finished: collect at AnalysisRunner.scala:326, took 0.194095 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,806 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,807 INFO scheduler.DAGScheduler: Got job 16 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,807 INFO scheduler.DAGScheduler: Final stage: ResultStage 23 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,807 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,808 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,809 INFO scheduler.DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[99] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,816 INFO memory.MemoryStore: Block broadcast_20 stored as values in memory (estimated size 54.8 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,825 INFO memory.MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,829 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on 10.0.83.226:42275 (size: 20.7 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,830 INFO spark.SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,830 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[99] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,831 INFO cluster.YarnScheduler: Adding task set 23.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,832 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 23.0 (TID 18) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,845 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on algo-1:41051 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,919 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 23.0 (TID 18) in 87 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,920 INFO scheduler.DAGScheduler: ResultStage 23 (treeReduce at KLLRunner.scala:107) finished in 0.110 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,921 INFO scheduler.DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,923 INFO cluster.YarnScheduler: Removed TaskSet 23.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,923 INFO cluster.YarnScheduler: Killing all running tasks in stage 23: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:34,924 INFO scheduler.DAGScheduler: Job 16 finished: treeReduce at KLLRunner.scala:107, took 0.117582 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,222 INFO scheduler.DAGScheduler: Registering RDD 104 (collect at AnalysisRunner.scala:326) as input to shuffle 7\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,222 INFO scheduler.DAGScheduler: Got map stage job 17 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,223 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 24 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,223 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,223 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,224 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[104] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,233 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on 10.0.83.226:42275 in memory (size: 18.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,239 INFO memory.MemoryStore: Block broadcast_21 stored as values in memory (estimated size 90.7 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,242 INFO memory.MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,240 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on algo-1:41051 in memory (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,245 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on 10.0.83.226:42275 (size: 27.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,246 INFO spark.SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,252 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[104] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,252 INFO cluster.YarnScheduler: Adding task set 24.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,254 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 24.0 (TID 19) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,280 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on algo-1:41051 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,314 INFO storage.BlockManagerInfo: Removed broadcast_20_piece0 on algo-1:41051 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,316 INFO storage.BlockManagerInfo: Removed broadcast_20_piece0 on 10.0.83.226:42275 in memory (size: 20.7 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,344 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 24.0 (TID 19) in 90 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,344 INFO cluster.YarnScheduler: Removed TaskSet 24.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,345 INFO scheduler.DAGScheduler: ShuffleMapStage 24 (collect at AnalysisRunner.scala:326) finished in 0.119 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,346 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,347 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,347 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,347 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,382 INFO storage.BlockManagerInfo: Removed broadcast_19_piece0 on 10.0.83.226:42275 in memory (size: 50.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,386 INFO storage.BlockManagerInfo: Removed broadcast_19_piece0 on algo-1:41051 in memory (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,470 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on 10.0.83.226:42275 in memory (size: 27.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,471 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on algo-1:41051 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,510 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,512 INFO scheduler.DAGScheduler: Got job 18 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,512 INFO scheduler.DAGScheduler: Final stage: ResultStage 26 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,512 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,512 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,513 INFO scheduler.DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[107] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,516 INFO memory.MemoryStore: Block broadcast_22 stored as values in memory (estimated size 66.2 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,520 INFO memory.MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,521 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on 10.0.83.226:42275 (size: 19.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,521 INFO spark.SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,522 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[107] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,522 INFO cluster.YarnScheduler: Adding task set 26.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,523 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 26.0 (TID 20) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,537 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on 10.0.83.226:42275 in memory (size: 19.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,549 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on algo-1:41051 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,552 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on algo-1:41051 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,559 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,602 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 26.0 (TID 20) in 79 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,603 INFO cluster.YarnScheduler: Removed TaskSet 26.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,603 INFO scheduler.DAGScheduler: ResultStage 26 (collect at AnalysisRunner.scala:326) finished in 0.090 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,604 INFO scheduler.DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,605 INFO cluster.YarnScheduler: Killing all running tasks in stage 26: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,605 INFO scheduler.DAGScheduler: Job 18 finished: collect at AnalysisRunner.scala:326, took 0.094569 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,627 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on algo-1:41051 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,636 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on 10.0.83.226:42275 in memory (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,665 INFO storage.BlockManagerInfo: Removed broadcast_18_piece0 on algo-1:41051 in memory (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,672 INFO storage.BlockManagerInfo: Removed broadcast_18_piece0 on 10.0.83.226:42275 in memory (size: 32.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,702 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,704 INFO scheduler.DAGScheduler: Registering RDD 115 (countByKey at ColumnProfiler.scala:592) as input to shuffle 8\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,704 INFO scheduler.DAGScheduler: Got job 19 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,704 INFO scheduler.DAGScheduler: Final stage: ResultStage 28 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,705 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 27)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,705 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 27)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,708 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[115] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,728 INFO storage.BlockManagerInfo: Removed broadcast_17_piece0 on algo-1:41051 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,736 INFO storage.BlockManagerInfo: Removed broadcast_17_piece0 on 10.0.83.226:42275 in memory (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,763 INFO memory.MemoryStore: Block broadcast_23 stored as values in memory (estimated size 47.1 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,767 INFO memory.MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,770 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on 10.0.83.226:42275 (size: 18.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,771 INFO spark.SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,772 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[115] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,773 INFO cluster.YarnScheduler: Adding task set 27.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,775 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 27.0 (TID 21) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,792 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on algo-1:41051 (size: 18.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,892 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 27.0 (TID 21) in 118 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,892 INFO cluster.YarnScheduler: Removed TaskSet 27.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,893 INFO scheduler.DAGScheduler: ShuffleMapStage 27 (countByKey at ColumnProfiler.scala:592) finished in 0.184 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,893 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,893 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,893 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 28)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,893 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,894 INFO scheduler.DAGScheduler: Submitting ResultStage 28 (ShuffledRDD[116] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,898 INFO memory.MemoryStore: Block broadcast_24 stored as values in memory (estimated size 5.1 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,905 INFO memory.MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,908 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on 10.0.83.226:42275 (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,909 INFO spark.SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,910 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (ShuffledRDD[116] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,910 INFO cluster.YarnScheduler: Adding task set 28.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,912 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 28.0 (TID 22) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,928 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on algo-1:41051 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,934 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,952 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 28.0 (TID 22) in 40 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,952 INFO cluster.YarnScheduler: Removed TaskSet 28.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,953 INFO scheduler.DAGScheduler: ResultStage 28 (countByKey at ColumnProfiler.scala:592) finished in 0.057 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,956 INFO scheduler.DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,956 INFO cluster.YarnScheduler: Killing all running tasks in stage 28: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:35,957 INFO scheduler.DAGScheduler: Job 19 finished: countByKey at ColumnProfiler.scala:592, took 0.253908 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,159 INFO scheduler.DAGScheduler: Registering RDD 121 (collect at AnalysisRunner.scala:326) as input to shuffle 9\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,160 INFO scheduler.DAGScheduler: Got map stage job 20 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,160 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 29 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,160 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,162 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,163 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[121] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,170 INFO memory.MemoryStore: Block broadcast_25 stored as values in memory (estimated size 100.0 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,183 INFO memory.MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,183 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on 10.0.83.226:42275 (size: 32.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,184 INFO spark.SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,185 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[121] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,185 INFO cluster.YarnScheduler: Adding task set 29.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,188 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 29.0 (TID 23) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,205 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on algo-1:41051 (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,356 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 29.0 (TID 23) in 169 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,356 INFO cluster.YarnScheduler: Removed TaskSet 29.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,357 INFO scheduler.DAGScheduler: ShuffleMapStage 29 (collect at AnalysisRunner.scala:326) finished in 0.192 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,364 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,365 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,365 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,365 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,411 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,412 INFO scheduler.DAGScheduler: Got job 21 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,413 INFO scheduler.DAGScheduler: Final stage: ResultStage 31 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,413 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,413 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,414 INFO scheduler.DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[124] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,421 INFO memory.MemoryStore: Block broadcast_26 stored as values in memory (estimated size 184.6 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,426 INFO memory.MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,427 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on 10.0.83.226:42275 (size: 50.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,429 INFO spark.SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,430 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[124] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,430 INFO cluster.YarnScheduler: Adding task set 31.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,432 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 31.0 (TID 24) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,450 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on algo-1:41051 (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,472 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,743 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 31.0 (TID 24) in 311 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,749 INFO cluster.YarnScheduler: Removed TaskSet 31.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,792 INFO scheduler.DAGScheduler: ResultStage 31 (collect at AnalysisRunner.scala:326) finished in 0.377 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,827 INFO scheduler.DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,827 INFO cluster.YarnScheduler: Killing all running tasks in stage 31: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,827 INFO scheduler.DAGScheduler: Job 21 finished: collect at AnalysisRunner.scala:326, took 0.415978 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,938 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,939 INFO scheduler.DAGScheduler: Got job 22 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,939 INFO scheduler.DAGScheduler: Final stage: ResultStage 32 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,939 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,940 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,941 INFO scheduler.DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[134] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:36,951 INFO memory.MemoryStore: Block broadcast_27 stored as values in memory (estimated size 54.8 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,271 INFO memory.MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 20.8 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,272 INFO storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on 10.0.83.226:42275 (size: 20.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,274 INFO spark.SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,274 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[134] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,275 INFO cluster.YarnScheduler: Adding task set 32.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,277 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 32.0 (TID 25) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,294 INFO storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on algo-1:41051 (size: 20.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,343 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 32.0 (TID 25) in 67 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,344 INFO cluster.YarnScheduler: Removed TaskSet 32.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,344 INFO scheduler.DAGScheduler: ResultStage 32 (treeReduce at KLLRunner.scala:107) finished in 0.402 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,345 INFO scheduler.DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,345 INFO cluster.YarnScheduler: Killing all running tasks in stage 32: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,345 INFO scheduler.DAGScheduler: Job 22 finished: treeReduce at KLLRunner.scala:107, took 0.406926 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,511 INFO scheduler.DAGScheduler: Registering RDD 139 (collect at AnalysisRunner.scala:326) as input to shuffle 10\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,512 INFO scheduler.DAGScheduler: Got map stage job 23 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,512 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 33 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,512 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,512 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,512 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[139] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,517 INFO memory.MemoryStore: Block broadcast_28 stored as values in memory (estimated size 90.7 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,519 INFO memory.MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,519 INFO storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on 10.0.83.226:42275 (size: 27.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,520 INFO spark.SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,522 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[139] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,522 INFO cluster.YarnScheduler: Adding task set 33.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,524 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 33.0 (TID 26) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,535 INFO storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on algo-1:41051 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,556 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 33.0 (TID 26) in 32 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,556 INFO cluster.YarnScheduler: Removed TaskSet 33.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,557 INFO scheduler.DAGScheduler: ShuffleMapStage 33 (collect at AnalysisRunner.scala:326) finished in 0.044 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,558 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,558 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,558 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,559 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,650 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,651 INFO scheduler.DAGScheduler: Got job 24 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,651 INFO scheduler.DAGScheduler: Final stage: ResultStage 35 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,651 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,651 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,651 INFO scheduler.DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[142] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,653 INFO memory.MemoryStore: Block broadcast_29 stored as values in memory (estimated size 66.2 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,655 INFO memory.MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,656 INFO storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on 10.0.83.226:42275 (size: 19.2 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,658 INFO spark.SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,659 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[142] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,659 INFO cluster.YarnScheduler: Adding task set 35.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,660 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 35.0 (TID 27) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,671 INFO storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on algo-1:41051 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,676 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 10 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,686 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 35.0 (TID 27) in 26 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,687 INFO cluster.YarnScheduler: Removed TaskSet 35.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,688 INFO scheduler.DAGScheduler: ResultStage 35 (collect at AnalysisRunner.scala:326) finished in 0.036 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,689 INFO scheduler.DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,690 INFO cluster.YarnScheduler: Killing all running tasks in stage 35: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,690 INFO scheduler.DAGScheduler: Job 24 finished: collect at AnalysisRunner.scala:326, took 0.039915 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,824 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,827 INFO scheduler.DAGScheduler: Registering RDD 150 (countByKey at ColumnProfiler.scala:592) as input to shuffle 11\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,828 INFO scheduler.DAGScheduler: Got job 25 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,828 INFO scheduler.DAGScheduler: Final stage: ResultStage 37 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,829 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 36)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,829 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 36)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,831 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[150] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,833 INFO storage.BlockManagerInfo: Removed broadcast_28_piece0 on 10.0.83.226:42275 in memory (size: 27.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,833 INFO storage.BlockManagerInfo: Removed broadcast_28_piece0 on algo-1:41051 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,849 INFO storage.BlockManagerInfo: Removed broadcast_22_piece0 on 10.0.83.226:42275 in memory (size: 19.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,855 INFO storage.BlockManagerInfo: Removed broadcast_22_piece0 on algo-1:41051 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,866 INFO memory.MemoryStore: Block broadcast_30 stored as values in memory (estimated size 47.1 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,872 INFO memory.MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,873 INFO storage.BlockManagerInfo: Added broadcast_30_piece0 in memory on 10.0.83.226:42275 (size: 18.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,873 INFO spark.SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,874 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[150] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,874 INFO cluster.YarnScheduler: Adding task set 36.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,875 INFO storage.BlockManagerInfo: Removed broadcast_26_piece0 on 10.0.83.226:42275 in memory (size: 50.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,876 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 36.0 (TID 28) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,891 INFO storage.BlockManagerInfo: Added broadcast_30_piece0 in memory on algo-1:41051 (size: 18.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,894 INFO storage.BlockManagerInfo: Removed broadcast_26_piece0 on algo-1:41051 in memory (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,939 INFO storage.BlockManagerInfo: Removed broadcast_24_piece0 on 10.0.83.226:42275 in memory (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,945 INFO storage.BlockManagerInfo: Removed broadcast_24_piece0 on algo-1:41051 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,956 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 36.0 (TID 28) in 80 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,956 INFO cluster.YarnScheduler: Removed TaskSet 36.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,957 INFO scheduler.DAGScheduler: ShuffleMapStage 36 (countByKey at ColumnProfiler.scala:592) finished in 0.124 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,957 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,957 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,957 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 37)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,957 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,958 INFO scheduler.DAGScheduler: Submitting ResultStage 37 (ShuffledRDD[151] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,959 INFO memory.MemoryStore: Block broadcast_31 stored as values in memory (estimated size 5.1 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,961 INFO memory.MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,962 INFO storage.BlockManagerInfo: Added broadcast_31_piece0 in memory on 10.0.83.226:42275 (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,964 INFO spark.SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,965 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (ShuffledRDD[151] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,965 INFO cluster.YarnScheduler: Adding task set 37.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,967 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 37.0 (TID 29) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,981 INFO storage.BlockManagerInfo: Added broadcast_31_piece0 in memory on algo-1:41051 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:37,986 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,004 INFO storage.BlockManagerInfo: Removed broadcast_29_piece0 on algo-1:41051 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,008 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 37.0 (TID 29) in 41 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,008 INFO cluster.YarnScheduler: Removed TaskSet 37.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,009 INFO scheduler.DAGScheduler: ResultStage 37 (countByKey at ColumnProfiler.scala:592) finished in 0.050 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,009 INFO scheduler.DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,010 INFO cluster.YarnScheduler: Killing all running tasks in stage 37: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,010 INFO scheduler.DAGScheduler: Job 25 finished: countByKey at ColumnProfiler.scala:592, took 0.183662 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,012 INFO storage.BlockManagerInfo: Removed broadcast_29_piece0 on 10.0.83.226:42275 in memory (size: 19.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,041 INFO storage.BlockManagerInfo: Removed broadcast_23_piece0 on 10.0.83.226:42275 in memory (size: 18.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,045 INFO storage.BlockManagerInfo: Removed broadcast_23_piece0 on algo-1:41051 in memory (size: 18.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,049 INFO storage.BlockManagerInfo: Removed broadcast_25_piece0 on 10.0.83.226:42275 in memory (size: 32.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,051 INFO storage.BlockManagerInfo: Removed broadcast_25_piece0 on algo-1:41051 in memory (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,064 INFO storage.BlockManagerInfo: Removed broadcast_27_piece0 on 10.0.83.226:42275 in memory (size: 20.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,067 INFO storage.BlockManagerInfo: Removed broadcast_27_piece0 on algo-1:41051 in memory (size: 20.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,071 INFO storage.BlockManagerInfo: Removed broadcast_21_piece0 on 10.0.83.226:42275 in memory (size: 27.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,075 INFO storage.BlockManagerInfo: Removed broadcast_21_piece0 on algo-1:41051 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,221 INFO scheduler.DAGScheduler: Registering RDD 156 (collect at AnalysisRunner.scala:326) as input to shuffle 12\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,221 INFO scheduler.DAGScheduler: Got map stage job 26 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,221 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 38 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,221 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,222 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,222 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[156] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,228 INFO memory.MemoryStore: Block broadcast_32 stored as values in memory (estimated size 100.0 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,230 INFO memory.MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,231 INFO storage.BlockManagerInfo: Added broadcast_32_piece0 in memory on 10.0.83.226:42275 (size: 32.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,232 INFO spark.SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,232 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[156] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,232 INFO cluster.YarnScheduler: Adding task set 38.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,234 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 38.0 (TID 30) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,248 INFO storage.BlockManagerInfo: Added broadcast_32_piece0 in memory on algo-1:41051 (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,409 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 38.0 (TID 30) in 175 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,410 INFO cluster.YarnScheduler: Removed TaskSet 38.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,411 INFO scheduler.DAGScheduler: ShuffleMapStage 38 (collect at AnalysisRunner.scala:326) finished in 0.187 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,412 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,412 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,412 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,412 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,451 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,454 INFO scheduler.DAGScheduler: Got job 27 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,454 INFO scheduler.DAGScheduler: Final stage: ResultStage 40 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,454 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 39)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,454 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,455 INFO scheduler.DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[159] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,465 INFO memory.MemoryStore: Block broadcast_33 stored as values in memory (estimated size 184.6 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,467 INFO memory.MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 50.2 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,468 INFO storage.BlockManagerInfo: Added broadcast_33_piece0 in memory on 10.0.83.226:42275 (size: 50.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,468 INFO spark.SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,469 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[159] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,469 INFO cluster.YarnScheduler: Adding task set 40.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,471 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 40.0 (TID 31) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,489 INFO storage.BlockManagerInfo: Added broadcast_33_piece0 in memory on algo-1:41051 (size: 50.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,508 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,625 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 40.0 (TID 31) in 154 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,625 INFO cluster.YarnScheduler: Removed TaskSet 40.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,626 INFO scheduler.DAGScheduler: ResultStage 40 (collect at AnalysisRunner.scala:326) finished in 0.169 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,628 INFO scheduler.DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,628 INFO cluster.YarnScheduler: Killing all running tasks in stage 40: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,629 INFO scheduler.DAGScheduler: Job 27 finished: collect at AnalysisRunner.scala:326, took 0.177591 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,852 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,853 INFO scheduler.DAGScheduler: Got job 28 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,853 INFO scheduler.DAGScheduler: Final stage: ResultStage 41 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,853 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,853 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,854 INFO scheduler.DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[169] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,865 INFO memory.MemoryStore: Block broadcast_34 stored as values in memory (estimated size 54.8 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,867 INFO memory.MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,867 INFO storage.BlockManagerInfo: Added broadcast_34_piece0 in memory on 10.0.83.226:42275 (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,868 INFO spark.SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,868 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[169] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,868 INFO cluster.YarnScheduler: Adding task set 41.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,870 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 41.0 (TID 32) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,885 INFO storage.BlockManagerInfo: Added broadcast_34_piece0 in memory on algo-1:41051 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,936 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 41.0 (TID 32) in 67 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,937 INFO cluster.YarnScheduler: Removed TaskSet 41.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,938 INFO scheduler.DAGScheduler: ResultStage 41 (treeReduce at KLLRunner.scala:107) finished in 0.081 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,938 INFO scheduler.DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,939 INFO cluster.YarnScheduler: Killing all running tasks in stage 41: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:38,939 INFO scheduler.DAGScheduler: Job 28 finished: treeReduce at KLLRunner.scala:107, took 0.087277 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,069 INFO scheduler.DAGScheduler: Registering RDD 174 (collect at AnalysisRunner.scala:326) as input to shuffle 13\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,069 INFO scheduler.DAGScheduler: Got map stage job 29 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,069 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 42 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,069 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,070 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,071 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 42 (MapPartitionsRDD[174] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,074 INFO memory.MemoryStore: Block broadcast_35 stored as values in memory (estimated size 90.7 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,078 INFO memory.MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,079 INFO storage.BlockManagerInfo: Added broadcast_35_piece0 in memory on 10.0.83.226:42275 (size: 27.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,081 INFO spark.SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,082 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[174] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,082 INFO cluster.YarnScheduler: Adding task set 42.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,083 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 42.0 (TID 33) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,109 INFO storage.BlockManagerInfo: Added broadcast_35_piece0 in memory on algo-1:41051 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,141 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 42.0 (TID 33) in 58 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,142 INFO cluster.YarnScheduler: Removed TaskSet 42.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,142 INFO scheduler.DAGScheduler: ShuffleMapStage 42 (collect at AnalysisRunner.scala:326) finished in 0.071 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,143 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,143 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,143 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,143 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,209 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,211 INFO scheduler.DAGScheduler: Got job 30 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,212 INFO scheduler.DAGScheduler: Final stage: ResultStage 44 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,212 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 43)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,212 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,213 INFO scheduler.DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[177] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,215 INFO memory.MemoryStore: Block broadcast_36 stored as values in memory (estimated size 66.2 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,217 INFO memory.MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,217 INFO storage.BlockManagerInfo: Added broadcast_36_piece0 in memory on 10.0.83.226:42275 (size: 19.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,218 INFO spark.SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,219 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[177] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,219 INFO cluster.YarnScheduler: Adding task set 44.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,221 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 44.0 (TID 34) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,239 INFO storage.BlockManagerInfo: Added broadcast_36_piece0 in memory on algo-1:41051 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,243 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 13 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,252 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 44.0 (TID 34) in 30 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,252 INFO cluster.YarnScheduler: Removed TaskSet 44.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,253 INFO scheduler.DAGScheduler: ResultStage 44 (collect at AnalysisRunner.scala:326) finished in 0.040 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,254 INFO scheduler.DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,254 INFO cluster.YarnScheduler: Killing all running tasks in stage 44: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,255 INFO scheduler.DAGScheduler: Job 30 finished: collect at AnalysisRunner.scala:326, took 0.045674 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,336 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,337 INFO scheduler.DAGScheduler: Registering RDD 185 (countByKey at ColumnProfiler.scala:592) as input to shuffle 14\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,338 INFO scheduler.DAGScheduler: Got job 31 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,338 INFO scheduler.DAGScheduler: Final stage: ResultStage 46 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,338 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 45)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,338 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 45)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,340 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 45 (MapPartitionsRDD[185] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,345 INFO memory.MemoryStore: Block broadcast_37 stored as values in memory (estimated size 47.1 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,347 INFO memory.MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,348 INFO storage.BlockManagerInfo: Added broadcast_37_piece0 in memory on 10.0.83.226:42275 (size: 18.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,348 INFO spark.SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,349 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[185] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,349 INFO cluster.YarnScheduler: Adding task set 45.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,351 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 45.0 (TID 35) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,364 INFO storage.BlockManagerInfo: Added broadcast_37_piece0 in memory on algo-1:41051 (size: 18.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,404 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 45.0 (TID 35) in 53 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,405 INFO cluster.YarnScheduler: Removed TaskSet 45.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,406 INFO scheduler.DAGScheduler: ShuffleMapStage 45 (countByKey at ColumnProfiler.scala:592) finished in 0.066 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,406 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,406 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,407 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 46)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,407 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,408 INFO scheduler.DAGScheduler: Submitting ResultStage 46 (ShuffledRDD[186] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,409 INFO memory.MemoryStore: Block broadcast_38 stored as values in memory (estimated size 5.1 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,412 INFO memory.MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,413 INFO storage.BlockManagerInfo: Added broadcast_38_piece0 in memory on 10.0.83.226:42275 (size: 3.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,413 INFO spark.SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,414 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (ShuffledRDD[186] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,414 INFO cluster.YarnScheduler: Adding task set 46.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,415 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 46.0 (TID 36) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,434 INFO storage.BlockManagerInfo: Added broadcast_38_piece0 in memory on algo-1:41051 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,446 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 14 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,478 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 46.0 (TID 36) in 63 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,478 INFO cluster.YarnScheduler: Removed TaskSet 46.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,479 INFO scheduler.DAGScheduler: ResultStage 46 (countByKey at ColumnProfiler.scala:592) finished in 0.070 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,479 INFO scheduler.DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,479 INFO cluster.YarnScheduler: Killing all running tasks in stage 46: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,480 INFO scheduler.DAGScheduler: Job 31 finished: countByKey at ColumnProfiler.scala:592, took 0.143629 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,660 INFO scheduler.DAGScheduler: Registering RDD 191 (collect at AnalysisRunner.scala:326) as input to shuffle 15\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,660 INFO scheduler.DAGScheduler: Got map stage job 32 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,660 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 47 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,660 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,661 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,661 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 47 (MapPartitionsRDD[191] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,666 INFO memory.MemoryStore: Block broadcast_39 stored as values in memory (estimated size 100.0 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,668 INFO memory.MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,669 INFO storage.BlockManagerInfo: Added broadcast_39_piece0 in memory on 10.0.83.226:42275 (size: 32.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,669 INFO spark.SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,670 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 47 (MapPartitionsRDD[191] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,670 INFO cluster.YarnScheduler: Adding task set 47.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,671 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 47.0 (TID 37) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,688 INFO storage.BlockManagerInfo: Added broadcast_39_piece0 in memory on algo-1:41051 (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,877 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 47.0 (TID 37) in 206 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,877 INFO cluster.YarnScheduler: Removed TaskSet 47.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,878 INFO scheduler.DAGScheduler: ShuffleMapStage 47 (collect at AnalysisRunner.scala:326) finished in 0.216 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,879 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,879 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,880 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,880 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,959 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,961 INFO scheduler.DAGScheduler: Got job 33 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,961 INFO scheduler.DAGScheduler: Final stage: ResultStage 49 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,961 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 48)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,961 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,962 INFO scheduler.DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[194] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,970 INFO memory.MemoryStore: Block broadcast_40 stored as values in memory (estimated size 184.6 KiB, free 1456.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,976 INFO memory.MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 50.2 KiB, free 1456.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,979 INFO storage.BlockManagerInfo: Added broadcast_40_piece0 in memory on 10.0.83.226:42275 (size: 50.2 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,980 INFO spark.SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,980 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[194] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,983 INFO cluster.YarnScheduler: Adding task set 49.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,985 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 49.0 (TID 38) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:39,998 INFO storage.BlockManagerInfo: Added broadcast_40_piece0 in memory on algo-1:41051 (size: 50.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,024 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,205 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 49.0 (TID 38) in 221 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,206 INFO scheduler.DAGScheduler: ResultStage 49 (collect at AnalysisRunner.scala:326) finished in 0.243 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,207 INFO cluster.YarnScheduler: Removed TaskSet 49.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,208 INFO scheduler.DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,208 INFO cluster.YarnScheduler: Killing all running tasks in stage 49: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,208 INFO scheduler.DAGScheduler: Job 33 finished: collect at AnalysisRunner.scala:326, took 0.248463 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,313 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,314 INFO scheduler.DAGScheduler: Got job 34 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,314 INFO scheduler.DAGScheduler: Final stage: ResultStage 50 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,314 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,315 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,315 INFO scheduler.DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[204] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,323 INFO memory.MemoryStore: Block broadcast_41 stored as values in memory (estimated size 54.8 KiB, free 1456.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,326 INFO memory.MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1456.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,327 INFO storage.BlockManagerInfo: Added broadcast_41_piece0 in memory on 10.0.83.226:42275 (size: 20.7 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,327 INFO spark.SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,341 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[204] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,342 INFO cluster.YarnScheduler: Adding task set 50.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,353 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 50.0 (TID 39) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,362 INFO storage.BlockManagerInfo: Added broadcast_41_piece0 in memory on algo-1:41051 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,429 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 50.0 (TID 39) in 77 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,429 INFO cluster.YarnScheduler: Removed TaskSet 50.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,430 INFO scheduler.DAGScheduler: ResultStage 50 (treeReduce at KLLRunner.scala:107) finished in 0.113 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,431 INFO scheduler.DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,431 INFO cluster.YarnScheduler: Killing all running tasks in stage 50: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,432 INFO scheduler.DAGScheduler: Job 34 finished: treeReduce at KLLRunner.scala:107, took 0.118450 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,576 INFO storage.BlockManagerInfo: Removed broadcast_32_piece0 on algo-1:41051 in memory (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,581 INFO storage.BlockManagerInfo: Removed broadcast_32_piece0 on 10.0.83.226:42275 in memory (size: 32.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,595 INFO storage.BlockManagerInfo: Removed broadcast_33_piece0 on algo-1:41051 in memory (size: 50.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,603 INFO storage.BlockManagerInfo: Removed broadcast_33_piece0 on 10.0.83.226:42275 in memory (size: 50.2 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,632 INFO storage.BlockManagerInfo: Removed broadcast_30_piece0 on algo-1:41051 in memory (size: 18.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,636 INFO storage.BlockManagerInfo: Removed broadcast_30_piece0 on 10.0.83.226:42275 in memory (size: 18.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,640 INFO storage.BlockManagerInfo: Removed broadcast_40_piece0 on algo-1:41051 in memory (size: 50.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,650 INFO storage.BlockManagerInfo: Removed broadcast_40_piece0 on 10.0.83.226:42275 in memory (size: 50.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,654 INFO storage.BlockManagerInfo: Removed broadcast_37_piece0 on algo-1:41051 in memory (size: 18.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,667 INFO storage.BlockManagerInfo: Removed broadcast_37_piece0 on 10.0.83.226:42275 in memory (size: 18.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,672 INFO storage.BlockManagerInfo: Removed broadcast_34_piece0 on 10.0.83.226:42275 in memory (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,672 INFO storage.BlockManagerInfo: Removed broadcast_34_piece0 on algo-1:41051 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,682 INFO storage.BlockManagerInfo: Removed broadcast_36_piece0 on 10.0.83.226:42275 in memory (size: 19.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,686 INFO storage.BlockManagerInfo: Removed broadcast_36_piece0 on algo-1:41051 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,702 INFO storage.BlockManagerInfo: Removed broadcast_41_piece0 on algo-1:41051 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,710 INFO storage.BlockManagerInfo: Removed broadcast_41_piece0 on 10.0.83.226:42275 in memory (size: 20.7 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,719 INFO storage.BlockManagerInfo: Removed broadcast_35_piece0 on algo-1:41051 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,720 INFO storage.BlockManagerInfo: Removed broadcast_35_piece0 on 10.0.83.226:42275 in memory (size: 27.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,729 INFO storage.BlockManagerInfo: Removed broadcast_38_piece0 on 10.0.83.226:42275 in memory (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,734 INFO storage.BlockManagerInfo: Removed broadcast_38_piece0 on algo-1:41051 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,749 INFO storage.BlockManagerInfo: Removed broadcast_39_piece0 on algo-1:41051 in memory (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,750 INFO storage.BlockManagerInfo: Removed broadcast_39_piece0 on 10.0.83.226:42275 in memory (size: 32.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,755 INFO storage.BlockManagerInfo: Removed broadcast_31_piece0 on algo-1:41051 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,764 INFO storage.BlockManagerInfo: Removed broadcast_31_piece0 on 10.0.83.226:42275 in memory (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,828 INFO scheduler.DAGScheduler: Registering RDD 209 (collect at AnalysisRunner.scala:326) as input to shuffle 16\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,828 INFO scheduler.DAGScheduler: Got map stage job 35 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,828 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 51 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,829 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,830 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,831 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 51 (MapPartitionsRDD[209] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,836 INFO memory.MemoryStore: Block broadcast_42 stored as values in memory (estimated size 90.7 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,839 INFO memory.MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,840 INFO storage.BlockManagerInfo: Added broadcast_42_piece0 in memory on 10.0.83.226:42275 (size: 27.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,841 INFO spark.SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,842 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 51 (MapPartitionsRDD[209] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,842 INFO cluster.YarnScheduler: Adding task set 51.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,850 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 51.0 (TID 40) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,863 INFO storage.BlockManagerInfo: Added broadcast_42_piece0 in memory on algo-1:41051 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,881 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 51.0 (TID 40) in 30 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,881 INFO cluster.YarnScheduler: Removed TaskSet 51.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,881 INFO scheduler.DAGScheduler: ShuffleMapStage 51 (collect at AnalysisRunner.scala:326) finished in 0.050 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,883 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,884 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,884 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,884 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,983 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,984 INFO scheduler.DAGScheduler: Got job 36 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,984 INFO scheduler.DAGScheduler: Final stage: ResultStage 53 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,984 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,985 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,985 INFO scheduler.DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[212] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,989 INFO memory.MemoryStore: Block broadcast_43 stored as values in memory (estimated size 66.2 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,990 INFO memory.MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,991 INFO storage.BlockManagerInfo: Added broadcast_43_piece0 in memory on 10.0.83.226:42275 (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,991 INFO spark.SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,992 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[212] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,992 INFO cluster.YarnScheduler: Adding task set 53.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:40,994 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 53.0 (TID 41) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,010 INFO storage.BlockManagerInfo: Added broadcast_43_piece0 in memory on algo-1:41051 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,033 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 16 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,047 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 53.0 (TID 41) in 53 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,047 INFO cluster.YarnScheduler: Removed TaskSet 53.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,047 INFO scheduler.DAGScheduler: ResultStage 53 (collect at AnalysisRunner.scala:326) finished in 0.060 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,049 INFO scheduler.DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,049 INFO cluster.YarnScheduler: Killing all running tasks in stage 53: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,050 INFO scheduler.DAGScheduler: Job 36 finished: collect at AnalysisRunner.scala:326, took 0.066246 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,140 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,141 INFO scheduler.DAGScheduler: Registering RDD 220 (countByKey at ColumnProfiler.scala:592) as input to shuffle 17\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,142 INFO scheduler.DAGScheduler: Got job 37 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,142 INFO scheduler.DAGScheduler: Final stage: ResultStage 55 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,142 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 54)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,142 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 54)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,147 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 54 (MapPartitionsRDD[220] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,154 INFO memory.MemoryStore: Block broadcast_44 stored as values in memory (estimated size 47.1 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,156 INFO memory.MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,157 INFO storage.BlockManagerInfo: Added broadcast_44_piece0 in memory on 10.0.83.226:42275 (size: 18.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,158 INFO spark.SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,158 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[220] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,158 INFO cluster.YarnScheduler: Adding task set 54.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,161 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 54.0 (TID 42) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,173 INFO storage.BlockManagerInfo: Added broadcast_44_piece0 in memory on algo-1:41051 (size: 18.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,247 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 54.0 (TID 42) in 87 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,247 INFO cluster.YarnScheduler: Removed TaskSet 54.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,248 INFO scheduler.DAGScheduler: ShuffleMapStage 54 (countByKey at ColumnProfiler.scala:592) finished in 0.101 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,248 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,249 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,249 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 55)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,249 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,250 INFO scheduler.DAGScheduler: Submitting ResultStage 55 (ShuffledRDD[221] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,251 INFO memory.MemoryStore: Block broadcast_45 stored as values in memory (estimated size 5.1 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,254 INFO memory.MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,255 INFO storage.BlockManagerInfo: Added broadcast_45_piece0 in memory on 10.0.83.226:42275 (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,255 INFO spark.SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,256 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (ShuffledRDD[221] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,256 INFO cluster.YarnScheduler: Adding task set 55.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,258 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 55.0 (TID 43) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,271 INFO storage.BlockManagerInfo: Added broadcast_45_piece0 in memory on algo-1:41051 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,274 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 17 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,292 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 55.0 (TID 43) in 34 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,292 INFO cluster.YarnScheduler: Removed TaskSet 55.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,293 INFO scheduler.DAGScheduler: ResultStage 55 (countByKey at ColumnProfiler.scala:592) finished in 0.043 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,294 INFO scheduler.DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,294 INFO cluster.YarnScheduler: Killing all running tasks in stage 55: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,294 INFO scheduler.DAGScheduler: Job 37 finished: countByKey at ColumnProfiler.scala:592, took 0.153822 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,646 INFO scheduler.DAGScheduler: Registering RDD 226 (collect at AnalysisRunner.scala:326) as input to shuffle 18\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,647 INFO scheduler.DAGScheduler: Got map stage job 38 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,647 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 56 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,647 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,647 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,648 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 56 (MapPartitionsRDD[226] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,653 INFO memory.MemoryStore: Block broadcast_46 stored as values in memory (estimated size 100.0 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,656 INFO memory.MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,657 INFO storage.BlockManagerInfo: Added broadcast_46_piece0 in memory on 10.0.83.226:42275 (size: 32.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,657 INFO spark.SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,658 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 56 (MapPartitionsRDD[226] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,658 INFO cluster.YarnScheduler: Adding task set 56.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,661 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 56.0 (TID 44) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,674 INFO storage.BlockManagerInfo: Added broadcast_46_piece0 in memory on algo-1:41051 (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,815 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 56.0 (TID 44) in 154 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,815 INFO cluster.YarnScheduler: Removed TaskSet 56.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,816 INFO scheduler.DAGScheduler: ShuffleMapStage 56 (collect at AnalysisRunner.scala:326) finished in 0.167 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,818 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,818 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,818 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,819 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,910 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,911 INFO scheduler.DAGScheduler: Got job 39 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,912 INFO scheduler.DAGScheduler: Final stage: ResultStage 58 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,912 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 57)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,912 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,912 INFO scheduler.DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[229] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,926 INFO memory.MemoryStore: Block broadcast_47 stored as values in memory (estimated size 184.6 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,928 INFO memory.MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,930 INFO storage.BlockManagerInfo: Added broadcast_47_piece0 in memory on 10.0.83.226:42275 (size: 50.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,931 INFO spark.SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,931 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[229] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,934 INFO cluster.YarnScheduler: Adding task set 58.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,935 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 58.0 (TID 45) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,946 INFO storage.BlockManagerInfo: Added broadcast_47_piece0 in memory on algo-1:41051 (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:41,969 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 18 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,154 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 58.0 (TID 45) in 219 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,154 INFO scheduler.DAGScheduler: ResultStage 58 (collect at AnalysisRunner.scala:326) finished in 0.241 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,155 INFO scheduler.DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,155 INFO cluster.YarnScheduler: Removed TaskSet 58.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,155 INFO cluster.YarnScheduler: Killing all running tasks in stage 58: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,155 INFO scheduler.DAGScheduler: Job 39 finished: collect at AnalysisRunner.scala:326, took 0.244839 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,255 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,256 INFO scheduler.DAGScheduler: Got job 40 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,256 INFO scheduler.DAGScheduler: Final stage: ResultStage 59 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,256 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,257 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,257 INFO scheduler.DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[239] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,267 INFO memory.MemoryStore: Block broadcast_48 stored as values in memory (estimated size 54.8 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,270 INFO memory.MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,270 INFO storage.BlockManagerInfo: Added broadcast_48_piece0 in memory on 10.0.83.226:42275 (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,271 INFO spark.SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,271 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[239] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,273 INFO cluster.YarnScheduler: Adding task set 59.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,274 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 59.0 (TID 46) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,283 INFO storage.BlockManagerInfo: Added broadcast_48_piece0 in memory on algo-1:41051 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,340 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 59.0 (TID 46) in 66 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,343 INFO scheduler.DAGScheduler: ResultStage 59 (treeReduce at KLLRunner.scala:107) finished in 0.083 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,343 INFO cluster.YarnScheduler: Removed TaskSet 59.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,344 INFO scheduler.DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,345 INFO cluster.YarnScheduler: Killing all running tasks in stage 59: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,345 INFO scheduler.DAGScheduler: Job 40 finished: treeReduce at KLLRunner.scala:107, took 0.089851 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,579 INFO scheduler.DAGScheduler: Registering RDD 244 (collect at AnalysisRunner.scala:326) as input to shuffle 19\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,579 INFO scheduler.DAGScheduler: Got map stage job 41 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,580 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 60 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,580 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,581 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,581 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 60 (MapPartitionsRDD[244] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,585 INFO memory.MemoryStore: Block broadcast_49 stored as values in memory (estimated size 90.7 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,587 INFO memory.MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,588 INFO storage.BlockManagerInfo: Added broadcast_49_piece0 in memory on 10.0.83.226:42275 (size: 27.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,589 INFO spark.SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,589 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 60 (MapPartitionsRDD[244] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,589 INFO cluster.YarnScheduler: Adding task set 60.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,592 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 60.0 (TID 47) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,601 INFO storage.BlockManagerInfo: Added broadcast_49_piece0 in memory on algo-1:41051 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,628 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 60.0 (TID 47) in 36 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,628 INFO cluster.YarnScheduler: Removed TaskSet 60.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,629 INFO scheduler.DAGScheduler: ShuffleMapStage 60 (collect at AnalysisRunner.scala:326) finished in 0.047 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,631 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,631 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,631 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,632 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,732 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,733 INFO scheduler.DAGScheduler: Got job 42 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,733 INFO scheduler.DAGScheduler: Final stage: ResultStage 62 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,734 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 61)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,734 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,734 INFO scheduler.DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[247] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,736 INFO memory.MemoryStore: Block broadcast_50 stored as values in memory (estimated size 66.2 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,739 INFO memory.MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,739 INFO storage.BlockManagerInfo: Added broadcast_50_piece0 in memory on 10.0.83.226:42275 (size: 19.2 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,740 INFO spark.SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,740 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[247] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,741 INFO cluster.YarnScheduler: Adding task set 62.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,742 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 62.0 (TID 48) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,752 INFO storage.BlockManagerInfo: Added broadcast_50_piece0 in memory on algo-1:41051 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,766 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 19 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,779 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 62.0 (TID 48) in 37 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,779 INFO cluster.YarnScheduler: Removed TaskSet 62.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,780 INFO scheduler.DAGScheduler: ResultStage 62 (collect at AnalysisRunner.scala:326) finished in 0.045 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,780 INFO scheduler.DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,781 INFO cluster.YarnScheduler: Killing all running tasks in stage 62: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,781 INFO scheduler.DAGScheduler: Job 42 finished: collect at AnalysisRunner.scala:326, took 0.048988 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,902 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,903 INFO scheduler.DAGScheduler: Registering RDD 255 (countByKey at ColumnProfiler.scala:592) as input to shuffle 20\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,904 INFO scheduler.DAGScheduler: Got job 43 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,905 INFO scheduler.DAGScheduler: Final stage: ResultStage 64 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,906 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 63)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,906 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 63)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,907 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 63 (MapPartitionsRDD[255] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,914 INFO memory.MemoryStore: Block broadcast_51 stored as values in memory (estimated size 47.1 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,916 INFO memory.MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 1456.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,916 INFO storage.BlockManagerInfo: Added broadcast_51_piece0 in memory on 10.0.83.226:42275 (size: 18.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,917 INFO spark.SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,918 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 63 (MapPartitionsRDD[255] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,918 INFO cluster.YarnScheduler: Adding task set 63.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,919 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 63.0 (TID 49) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,935 INFO storage.BlockManagerInfo: Added broadcast_51_piece0 in memory on algo-1:41051 (size: 18.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,977 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 63.0 (TID 49) in 58 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,977 INFO cluster.YarnScheduler: Removed TaskSet 63.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,978 INFO scheduler.DAGScheduler: ShuffleMapStage 63 (countByKey at ColumnProfiler.scala:592) finished in 0.069 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,978 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,978 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,978 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 64)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,979 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,979 INFO scheduler.DAGScheduler: Submitting ResultStage 64 (ShuffledRDD[256] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,983 INFO memory.MemoryStore: Block broadcast_52 stored as values in memory (estimated size 5.1 KiB, free 1456.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,984 INFO memory.MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1456.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,985 INFO storage.BlockManagerInfo: Added broadcast_52_piece0 in memory on 10.0.83.226:42275 (size: 3.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,985 INFO spark.SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,986 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (ShuffledRDD[256] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,986 INFO cluster.YarnScheduler: Adding task set 64.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,988 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 64.0 (TID 50) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,995 INFO storage.BlockManagerInfo: Added broadcast_52_piece0 in memory on algo-1:41051 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:42,998 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 20 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,056 INFO storage.BlockManagerInfo: Removed broadcast_47_piece0 on 10.0.83.226:42275 in memory (size: 50.3 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,057 INFO storage.BlockManagerInfo: Removed broadcast_47_piece0 on algo-1:41051 in memory (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,066 INFO storage.BlockManagerInfo: Removed broadcast_43_piece0 on 10.0.83.226:42275 in memory (size: 19.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,076 INFO storage.BlockManagerInfo: Removed broadcast_43_piece0 on algo-1:41051 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,077 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 64.0 (TID 50) in 90 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,077 INFO scheduler.DAGScheduler: ResultStage 64 (countByKey at ColumnProfiler.scala:592) finished in 0.097 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,078 INFO scheduler.DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,078 INFO cluster.YarnScheduler: Removed TaskSet 64.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,078 INFO cluster.YarnScheduler: Killing all running tasks in stage 64: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,078 INFO scheduler.DAGScheduler: Job 43 finished: countByKey at ColumnProfiler.scala:592, took 0.175536 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,087 INFO storage.BlockManagerInfo: Removed broadcast_48_piece0 on 10.0.83.226:42275 in memory (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,099 INFO storage.BlockManagerInfo: Removed broadcast_48_piece0 on algo-1:41051 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,104 INFO storage.BlockManagerInfo: Removed broadcast_45_piece0 on 10.0.83.226:42275 in memory (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,107 INFO storage.BlockManagerInfo: Removed broadcast_45_piece0 on algo-1:41051 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,110 INFO storage.BlockManagerInfo: Removed broadcast_42_piece0 on 10.0.83.226:42275 in memory (size: 27.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,112 INFO storage.BlockManagerInfo: Removed broadcast_42_piece0 on algo-1:41051 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,116 INFO storage.BlockManagerInfo: Removed broadcast_51_piece0 on 10.0.83.226:42275 in memory (size: 18.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,117 INFO storage.BlockManagerInfo: Removed broadcast_51_piece0 on algo-1:41051 in memory (size: 18.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,131 INFO storage.BlockManagerInfo: Removed broadcast_49_piece0 on 10.0.83.226:42275 in memory (size: 27.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,141 INFO storage.BlockManagerInfo: Removed broadcast_49_piece0 on algo-1:41051 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,152 INFO storage.BlockManagerInfo: Removed broadcast_46_piece0 on algo-1:41051 in memory (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,153 INFO storage.BlockManagerInfo: Removed broadcast_46_piece0 on 10.0.83.226:42275 in memory (size: 32.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,158 INFO storage.BlockManagerInfo: Removed broadcast_44_piece0 on algo-1:41051 in memory (size: 18.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,159 INFO storage.BlockManagerInfo: Removed broadcast_44_piece0 on 10.0.83.226:42275 in memory (size: 18.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,162 INFO storage.BlockManagerInfo: Removed broadcast_50_piece0 on 10.0.83.226:42275 in memory (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,164 INFO storage.BlockManagerInfo: Removed broadcast_50_piece0 on algo-1:41051 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,382 INFO scheduler.DAGScheduler: Registering RDD 261 (collect at AnalysisRunner.scala:326) as input to shuffle 21\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,383 INFO scheduler.DAGScheduler: Got map stage job 44 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,383 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 65 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,383 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,384 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,384 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 65 (MapPartitionsRDD[261] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,388 INFO memory.MemoryStore: Block broadcast_53 stored as values in memory (estimated size 100.0 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,390 INFO memory.MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,391 INFO storage.BlockManagerInfo: Added broadcast_53_piece0 in memory on 10.0.83.226:42275 (size: 32.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,391 INFO spark.SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,392 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 65 (MapPartitionsRDD[261] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,392 INFO cluster.YarnScheduler: Adding task set 65.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,396 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 65.0 (TID 51) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,415 INFO storage.BlockManagerInfo: Added broadcast_53_piece0 in memory on algo-1:41051 (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,550 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 65.0 (TID 51) in 155 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,550 INFO cluster.YarnScheduler: Removed TaskSet 65.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,551 INFO scheduler.DAGScheduler: ShuffleMapStage 65 (collect at AnalysisRunner.scala:326) finished in 0.166 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,552 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,553 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,553 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,553 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,603 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,604 INFO scheduler.DAGScheduler: Got job 45 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,605 INFO scheduler.DAGScheduler: Final stage: ResultStage 67 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,605 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 66)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,605 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,606 INFO scheduler.DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[264] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,615 INFO memory.MemoryStore: Block broadcast_54 stored as values in memory (estimated size 184.6 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,617 INFO memory.MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,618 INFO storage.BlockManagerInfo: Added broadcast_54_piece0 in memory on 10.0.83.226:42275 (size: 50.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,621 INFO spark.SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,622 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[264] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,622 INFO cluster.YarnScheduler: Adding task set 67.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,624 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 67.0 (TID 52) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,638 INFO storage.BlockManagerInfo: Added broadcast_54_piece0 in memory on algo-1:41051 (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,655 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 21 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,754 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 67.0 (TID 52) in 131 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,755 INFO cluster.YarnScheduler: Removed TaskSet 67.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,756 INFO scheduler.DAGScheduler: ResultStage 67 (collect at AnalysisRunner.scala:326) finished in 0.150 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,760 INFO scheduler.DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,760 INFO cluster.YarnScheduler: Killing all running tasks in stage 67: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,761 INFO scheduler.DAGScheduler: Job 45 finished: collect at AnalysisRunner.scala:326, took 0.157029 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,908 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,909 INFO scheduler.DAGScheduler: Got job 46 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,909 INFO scheduler.DAGScheduler: Final stage: ResultStage 68 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,909 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,910 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,911 INFO scheduler.DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[274] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,931 INFO memory.MemoryStore: Block broadcast_55 stored as values in memory (estimated size 54.8 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,934 INFO memory.MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,934 INFO storage.BlockManagerInfo: Added broadcast_55_piece0 in memory on 10.0.83.226:42275 (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,935 INFO spark.SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,936 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[274] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,936 INFO cluster.YarnScheduler: Adding task set 68.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,937 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 68.0 (TID 53) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,948 INFO storage.BlockManagerInfo: Added broadcast_55_piece0 in memory on algo-1:41051 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,988 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 68.0 (TID 53) in 51 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,988 INFO cluster.YarnScheduler: Removed TaskSet 68.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,989 INFO scheduler.DAGScheduler: ResultStage 68 (treeReduce at KLLRunner.scala:107) finished in 0.076 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,989 INFO scheduler.DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,989 INFO cluster.YarnScheduler: Killing all running tasks in stage 68: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:43,990 INFO scheduler.DAGScheduler: Job 46 finished: treeReduce at KLLRunner.scala:107, took 0.081670 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,183 INFO scheduler.DAGScheduler: Registering RDD 279 (collect at AnalysisRunner.scala:326) as input to shuffle 22\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,183 INFO scheduler.DAGScheduler: Got map stage job 47 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,183 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 69 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,183 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,184 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,184 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 69 (MapPartitionsRDD[279] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,189 INFO memory.MemoryStore: Block broadcast_56 stored as values in memory (estimated size 90.7 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,191 INFO memory.MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,191 INFO storage.BlockManagerInfo: Added broadcast_56_piece0 in memory on 10.0.83.226:42275 (size: 27.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,191 INFO spark.SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,192 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 69 (MapPartitionsRDD[279] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,192 INFO cluster.YarnScheduler: Adding task set 69.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,193 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 69.0 (TID 54) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,202 INFO storage.BlockManagerInfo: Added broadcast_56_piece0 in memory on algo-1:41051 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,231 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 69.0 (TID 54) in 38 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,231 INFO cluster.YarnScheduler: Removed TaskSet 69.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,232 INFO scheduler.DAGScheduler: ShuffleMapStage 69 (collect at AnalysisRunner.scala:326) finished in 0.047 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,233 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,233 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,233 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,233 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,299 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,300 INFO scheduler.DAGScheduler: Got job 48 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,300 INFO scheduler.DAGScheduler: Final stage: ResultStage 71 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,300 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 70)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,300 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,301 INFO scheduler.DAGScheduler: Submitting ResultStage 71 (MapPartitionsRDD[282] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,302 INFO memory.MemoryStore: Block broadcast_57 stored as values in memory (estimated size 66.2 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,304 INFO memory.MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,304 INFO storage.BlockManagerInfo: Added broadcast_57_piece0 in memory on 10.0.83.226:42275 (size: 19.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,305 INFO spark.SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,305 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 71 (MapPartitionsRDD[282] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,305 INFO cluster.YarnScheduler: Adding task set 71.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,306 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 71.0 (TID 55) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,317 INFO storage.BlockManagerInfo: Added broadcast_57_piece0 in memory on algo-1:41051 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,323 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 22 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,329 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 71.0 (TID 55) in 23 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,329 INFO cluster.YarnScheduler: Removed TaskSet 71.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,330 INFO scheduler.DAGScheduler: ResultStage 71 (collect at AnalysisRunner.scala:326) finished in 0.029 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,330 INFO scheduler.DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,330 INFO cluster.YarnScheduler: Killing all running tasks in stage 71: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,331 INFO scheduler.DAGScheduler: Job 48 finished: collect at AnalysisRunner.scala:326, took 0.031647 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,437 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,438 INFO scheduler.DAGScheduler: Registering RDD 290 (countByKey at ColumnProfiler.scala:592) as input to shuffle 23\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,439 INFO scheduler.DAGScheduler: Got job 49 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,439 INFO scheduler.DAGScheduler: Final stage: ResultStage 73 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,439 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 72)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,439 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 72)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,440 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 72 (MapPartitionsRDD[290] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,451 INFO memory.MemoryStore: Block broadcast_58 stored as values in memory (estimated size 47.1 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,453 INFO memory.MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,453 INFO storage.BlockManagerInfo: Added broadcast_58_piece0 in memory on 10.0.83.226:42275 (size: 18.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,454 INFO spark.SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,454 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 72 (MapPartitionsRDD[290] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,454 INFO cluster.YarnScheduler: Adding task set 72.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,456 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 72.0 (TID 56) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,471 INFO storage.BlockManagerInfo: Added broadcast_58_piece0 in memory on algo-1:41051 (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,562 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 72.0 (TID 56) in 106 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,562 INFO cluster.YarnScheduler: Removed TaskSet 72.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,563 INFO scheduler.DAGScheduler: ShuffleMapStage 72 (countByKey at ColumnProfiler.scala:592) finished in 0.122 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,563 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,563 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,564 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 73)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,564 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,564 INFO scheduler.DAGScheduler: Submitting ResultStage 73 (ShuffledRDD[291] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,566 INFO memory.MemoryStore: Block broadcast_59 stored as values in memory (estimated size 5.1 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,567 INFO memory.MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,568 INFO storage.BlockManagerInfo: Added broadcast_59_piece0 in memory on 10.0.83.226:42275 (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,569 INFO spark.SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,569 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 73 (ShuffledRDD[291] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,569 INFO cluster.YarnScheduler: Adding task set 73.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,570 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 73.0 (TID 57) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,580 INFO storage.BlockManagerInfo: Added broadcast_59_piece0 in memory on algo-1:41051 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,583 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 23 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,596 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 73.0 (TID 57) in 26 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,596 INFO cluster.YarnScheduler: Removed TaskSet 73.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,597 INFO scheduler.DAGScheduler: ResultStage 73 (countByKey at ColumnProfiler.scala:592) finished in 0.032 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,598 INFO scheduler.DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,598 INFO cluster.YarnScheduler: Killing all running tasks in stage 73: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,598 INFO scheduler.DAGScheduler: Job 49 finished: countByKey at ColumnProfiler.scala:592, took 0.160869 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,697 INFO scheduler.DAGScheduler: Registering RDD 296 (collect at AnalysisRunner.scala:326) as input to shuffle 24\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,698 INFO scheduler.DAGScheduler: Got map stage job 50 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,698 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 74 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,698 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,698 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,699 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 74 (MapPartitionsRDD[296] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,704 INFO memory.MemoryStore: Block broadcast_60 stored as values in memory (estimated size 100.0 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,705 INFO memory.MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,706 INFO storage.BlockManagerInfo: Added broadcast_60_piece0 in memory on 10.0.83.226:42275 (size: 32.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,706 INFO spark.SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,706 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 74 (MapPartitionsRDD[296] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,706 INFO cluster.YarnScheduler: Adding task set 74.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,708 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 74.0 (TID 58) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,721 INFO storage.BlockManagerInfo: Added broadcast_60_piece0 in memory on algo-1:41051 (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,870 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 74.0 (TID 58) in 163 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,871 INFO scheduler.DAGScheduler: ShuffleMapStage 74 (collect at AnalysisRunner.scala:326) finished in 0.170 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,871 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,871 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,872 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,871 INFO cluster.YarnScheduler: Removed TaskSet 74.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,872 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,903 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,904 INFO scheduler.DAGScheduler: Got job 51 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,904 INFO scheduler.DAGScheduler: Final stage: ResultStage 76 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,905 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 75)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,905 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,905 INFO scheduler.DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[299] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,911 INFO memory.MemoryStore: Block broadcast_61 stored as values in memory (estimated size 184.6 KiB, free 1456.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,912 INFO memory.MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1456.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,913 INFO storage.BlockManagerInfo: Added broadcast_61_piece0 in memory on 10.0.83.226:42275 (size: 50.3 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,913 INFO spark.SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,913 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[299] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,914 INFO cluster.YarnScheduler: Adding task set 76.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,915 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 76.0 (TID 59) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,923 INFO storage.BlockManagerInfo: Added broadcast_61_piece0 in memory on algo-1:41051 (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:44,935 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 24 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,018 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 76.0 (TID 59) in 103 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,019 INFO scheduler.DAGScheduler: ResultStage 76 (collect at AnalysisRunner.scala:326) finished in 0.113 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,019 INFO scheduler.DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,020 INFO cluster.YarnScheduler: Removed TaskSet 76.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,020 INFO cluster.YarnScheduler: Killing all running tasks in stage 76: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,020 INFO scheduler.DAGScheduler: Job 51 finished: collect at AnalysisRunner.scala:326, took 0.116943 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,220 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,223 INFO scheduler.DAGScheduler: Got job 52 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,223 INFO scheduler.DAGScheduler: Final stage: ResultStage 77 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,223 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,224 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,224 INFO scheduler.DAGScheduler: Submitting ResultStage 77 (MapPartitionsRDD[309] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,230 INFO memory.MemoryStore: Block broadcast_62 stored as values in memory (estimated size 54.8 KiB, free 1456.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,232 INFO memory.MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1456.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,232 INFO storage.BlockManagerInfo: Added broadcast_62_piece0 in memory on 10.0.83.226:42275 (size: 20.7 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,233 INFO spark.SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,233 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 77 (MapPartitionsRDD[309] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,233 INFO cluster.YarnScheduler: Adding task set 77.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,235 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 77.0 (TID 60) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,247 INFO storage.BlockManagerInfo: Added broadcast_62_piece0 in memory on algo-1:41051 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,294 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 77.0 (TID 60) in 60 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,295 INFO scheduler.DAGScheduler: ResultStage 77 (treeReduce at KLLRunner.scala:107) finished in 0.070 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,296 INFO scheduler.DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,296 INFO cluster.YarnScheduler: Removed TaskSet 77.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,296 INFO cluster.YarnScheduler: Killing all running tasks in stage 77: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,296 INFO scheduler.DAGScheduler: Job 52 finished: treeReduce at KLLRunner.scala:107, took 0.074102 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,484 INFO scheduler.DAGScheduler: Registering RDD 314 (collect at AnalysisRunner.scala:326) as input to shuffle 25\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,484 INFO scheduler.DAGScheduler: Got map stage job 53 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,484 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 78 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,484 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,485 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,485 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 78 (MapPartitionsRDD[314] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,488 INFO memory.MemoryStore: Block broadcast_63 stored as values in memory (estimated size 90.7 KiB, free 1456.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,495 INFO memory.MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1456.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,495 INFO storage.BlockManagerInfo: Added broadcast_63_piece0 in memory on 10.0.83.226:42275 (size: 27.9 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,496 INFO spark.SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,496 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 78 (MapPartitionsRDD[314] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,496 INFO cluster.YarnScheduler: Adding task set 78.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,498 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 78.0 (TID 61) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,511 INFO storage.BlockManagerInfo: Added broadcast_63_piece0 in memory on algo-1:41051 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,542 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 78.0 (TID 61) in 44 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,542 INFO cluster.YarnScheduler: Removed TaskSet 78.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,543 INFO scheduler.DAGScheduler: ShuffleMapStage 78 (collect at AnalysisRunner.scala:326) finished in 0.057 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,543 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,544 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,544 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,544 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,597 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,598 INFO scheduler.DAGScheduler: Got job 54 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,599 INFO scheduler.DAGScheduler: Final stage: ResultStage 80 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,599 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 79)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,599 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,599 INFO scheduler.DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[317] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,602 INFO memory.MemoryStore: Block broadcast_64 stored as values in memory (estimated size 66.2 KiB, free 1456.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,662 INFO memory.MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1456.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,663 INFO storage.BlockManagerInfo: Added broadcast_64_piece0 in memory on 10.0.83.226:42275 (size: 19.2 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,664 INFO spark.SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,664 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 80 (MapPartitionsRDD[317] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,665 INFO cluster.YarnScheduler: Adding task set 80.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,668 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 80.0 (TID 62) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,674 INFO storage.BlockManagerInfo: Removed broadcast_56_piece0 on 10.0.83.226:42275 in memory (size: 27.9 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,675 INFO storage.BlockManagerInfo: Removed broadcast_56_piece0 on algo-1:41051 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,679 INFO storage.BlockManagerInfo: Removed broadcast_53_piece0 on 10.0.83.226:42275 in memory (size: 32.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,682 INFO storage.BlockManagerInfo: Removed broadcast_53_piece0 on algo-1:41051 in memory (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,685 INFO storage.BlockManagerInfo: Removed broadcast_59_piece0 on 10.0.83.226:42275 in memory (size: 3.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,686 INFO storage.BlockManagerInfo: Added broadcast_64_piece0 in memory on algo-1:41051 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,688 INFO storage.BlockManagerInfo: Removed broadcast_59_piece0 on algo-1:41051 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,693 INFO storage.BlockManagerInfo: Removed broadcast_61_piece0 on 10.0.83.226:42275 in memory (size: 50.3 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,695 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 25 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,697 INFO storage.BlockManagerInfo: Removed broadcast_61_piece0 on algo-1:41051 in memory (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,701 INFO storage.BlockManagerInfo: Removed broadcast_63_piece0 on 10.0.83.226:42275 in memory (size: 27.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,704 INFO storage.BlockManagerInfo: Removed broadcast_63_piece0 on algo-1:41051 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,706 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 80.0 (TID 62) in 38 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,707 INFO cluster.YarnScheduler: Removed TaskSet 80.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,707 INFO scheduler.DAGScheduler: ResultStage 80 (collect at AnalysisRunner.scala:326) finished in 0.106 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,708 INFO scheduler.DAGScheduler: Job 54 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,709 INFO cluster.YarnScheduler: Killing all running tasks in stage 80: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,709 INFO scheduler.DAGScheduler: Job 54 finished: collect at AnalysisRunner.scala:326, took 0.111364 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,718 INFO storage.BlockManagerInfo: Removed broadcast_57_piece0 on 10.0.83.226:42275 in memory (size: 19.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,724 INFO storage.BlockManagerInfo: Removed broadcast_57_piece0 on algo-1:41051 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,728 INFO storage.BlockManagerInfo: Removed broadcast_58_piece0 on 10.0.83.226:42275 in memory (size: 18.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,734 INFO storage.BlockManagerInfo: Removed broadcast_58_piece0 on algo-1:41051 in memory (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,738 INFO storage.BlockManagerInfo: Removed broadcast_54_piece0 on 10.0.83.226:42275 in memory (size: 50.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,740 INFO storage.BlockManagerInfo: Removed broadcast_54_piece0 on algo-1:41051 in memory (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,742 INFO storage.BlockManagerInfo: Removed broadcast_60_piece0 on 10.0.83.226:42275 in memory (size: 32.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,744 INFO storage.BlockManagerInfo: Removed broadcast_60_piece0 on algo-1:41051 in memory (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,754 INFO storage.BlockManagerInfo: Removed broadcast_55_piece0 on 10.0.83.226:42275 in memory (size: 20.7 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,757 INFO storage.BlockManagerInfo: Removed broadcast_55_piece0 on algo-1:41051 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,760 INFO storage.BlockManagerInfo: Removed broadcast_62_piece0 on 10.0.83.226:42275 in memory (size: 20.7 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,766 INFO storage.BlockManagerInfo: Removed broadcast_62_piece0 on algo-1:41051 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,773 INFO storage.BlockManagerInfo: Removed broadcast_52_piece0 on 10.0.83.226:42275 in memory (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,782 INFO storage.BlockManagerInfo: Removed broadcast_52_piece0 on algo-1:41051 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,835 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,836 INFO scheduler.DAGScheduler: Registering RDD 325 (countByKey at ColumnProfiler.scala:592) as input to shuffle 26\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,837 INFO scheduler.DAGScheduler: Got job 55 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,837 INFO scheduler.DAGScheduler: Final stage: ResultStage 82 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,837 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 81)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,838 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 81)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,838 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 81 (MapPartitionsRDD[325] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,842 INFO memory.MemoryStore: Block broadcast_65 stored as values in memory (estimated size 47.1 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,843 INFO memory.MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,844 INFO storage.BlockManagerInfo: Added broadcast_65_piece0 in memory on 10.0.83.226:42275 (size: 18.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,844 INFO spark.SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,845 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 81 (MapPartitionsRDD[325] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,845 INFO cluster.YarnScheduler: Adding task set 81.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,851 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 81.0 (TID 63) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,863 INFO storage.BlockManagerInfo: Added broadcast_65_piece0 in memory on algo-1:41051 (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,911 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 81.0 (TID 63) in 60 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,912 INFO cluster.YarnScheduler: Removed TaskSet 81.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,912 INFO scheduler.DAGScheduler: ShuffleMapStage 81 (countByKey at ColumnProfiler.scala:592) finished in 0.073 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,913 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,914 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,914 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 82)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,914 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,914 INFO scheduler.DAGScheduler: Submitting ResultStage 82 (ShuffledRDD[326] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,916 INFO memory.MemoryStore: Block broadcast_66 stored as values in memory (estimated size 5.1 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,917 INFO memory.MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,917 INFO storage.BlockManagerInfo: Added broadcast_66_piece0 in memory on 10.0.83.226:42275 (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,921 INFO spark.SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,922 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 82 (ShuffledRDD[326] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,922 INFO cluster.YarnScheduler: Adding task set 82.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,923 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 82.0 (TID 64) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,943 INFO storage.BlockManagerInfo: Added broadcast_66_piece0 in memory on algo-1:41051 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,947 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 26 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,957 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 82.0 (TID 64) in 34 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,958 INFO scheduler.DAGScheduler: ResultStage 82 (countByKey at ColumnProfiler.scala:592) finished in 0.043 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,959 INFO scheduler.DAGScheduler: Job 55 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,959 INFO cluster.YarnScheduler: Removed TaskSet 82.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,960 INFO cluster.YarnScheduler: Killing all running tasks in stage 82: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:45,960 INFO scheduler.DAGScheduler: Job 55 finished: countByKey at ColumnProfiler.scala:592, took 0.124696 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,111 INFO scheduler.DAGScheduler: Registering RDD 331 (collect at AnalysisRunner.scala:326) as input to shuffle 27\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,111 INFO scheduler.DAGScheduler: Got map stage job 56 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,112 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 83 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,112 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,113 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,113 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 83 (MapPartitionsRDD[331] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,118 INFO memory.MemoryStore: Block broadcast_67 stored as values in memory (estimated size 100.0 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,120 INFO memory.MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,121 INFO storage.BlockManagerInfo: Added broadcast_67_piece0 in memory on 10.0.83.226:42275 (size: 32.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,121 INFO spark.SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,122 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 83 (MapPartitionsRDD[331] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,122 INFO cluster.YarnScheduler: Adding task set 83.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,123 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 83.0 (TID 65) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,132 INFO storage.BlockManagerInfo: Added broadcast_67_piece0 in memory on algo-1:41051 (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,262 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 83.0 (TID 65) in 139 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,262 INFO cluster.YarnScheduler: Removed TaskSet 83.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,263 INFO scheduler.DAGScheduler: ShuffleMapStage 83 (collect at AnalysisRunner.scala:326) finished in 0.148 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,264 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,265 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,265 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,265 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,306 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,308 INFO scheduler.DAGScheduler: Got job 57 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,308 INFO scheduler.DAGScheduler: Final stage: ResultStage 85 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,308 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 84)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,309 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,309 INFO scheduler.DAGScheduler: Submitting ResultStage 85 (MapPartitionsRDD[334] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,319 INFO memory.MemoryStore: Block broadcast_68 stored as values in memory (estimated size 184.6 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,321 INFO memory.MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,322 INFO storage.BlockManagerInfo: Added broadcast_68_piece0 in memory on 10.0.83.226:42275 (size: 50.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,323 INFO spark.SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,323 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 85 (MapPartitionsRDD[334] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,323 INFO cluster.YarnScheduler: Adding task set 85.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,325 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 85.0 (TID 66) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,334 INFO storage.BlockManagerInfo: Added broadcast_68_piece0 in memory on algo-1:41051 (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,346 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 27 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,438 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 85.0 (TID 66) in 114 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,438 INFO cluster.YarnScheduler: Removed TaskSet 85.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,439 INFO scheduler.DAGScheduler: ResultStage 85 (collect at AnalysisRunner.scala:326) finished in 0.127 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,440 INFO scheduler.DAGScheduler: Job 57 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,441 INFO cluster.YarnScheduler: Killing all running tasks in stage 85: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,441 INFO scheduler.DAGScheduler: Job 57 finished: collect at AnalysisRunner.scala:326, took 0.134460 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,548 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,549 INFO scheduler.DAGScheduler: Got job 58 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,550 INFO scheduler.DAGScheduler: Final stage: ResultStage 86 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,550 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,551 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,551 INFO scheduler.DAGScheduler: Submitting ResultStage 86 (MapPartitionsRDD[344] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,557 INFO memory.MemoryStore: Block broadcast_69 stored as values in memory (estimated size 54.8 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,558 INFO memory.MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,559 INFO storage.BlockManagerInfo: Added broadcast_69_piece0 in memory on 10.0.83.226:42275 (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,559 INFO spark.SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,560 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 86 (MapPartitionsRDD[344] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,560 INFO cluster.YarnScheduler: Adding task set 86.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,561 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 86.0 (TID 67) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,568 INFO storage.BlockManagerInfo: Added broadcast_69_piece0 in memory on algo-1:41051 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,611 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 86.0 (TID 67) in 50 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,613 INFO scheduler.DAGScheduler: ResultStage 86 (treeReduce at KLLRunner.scala:107) finished in 0.060 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,613 INFO scheduler.DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,614 INFO cluster.YarnScheduler: Removed TaskSet 86.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,614 INFO cluster.YarnScheduler: Killing all running tasks in stage 86: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,615 INFO scheduler.DAGScheduler: Job 58 finished: treeReduce at KLLRunner.scala:107, took 0.065791 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,740 INFO scheduler.DAGScheduler: Registering RDD 349 (collect at AnalysisRunner.scala:326) as input to shuffle 28\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,740 INFO scheduler.DAGScheduler: Got map stage job 59 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,741 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 87 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,741 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,741 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,742 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 87 (MapPartitionsRDD[349] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,745 INFO memory.MemoryStore: Block broadcast_70 stored as values in memory (estimated size 90.7 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,747 INFO memory.MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,748 INFO storage.BlockManagerInfo: Added broadcast_70_piece0 in memory on 10.0.83.226:42275 (size: 27.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,749 INFO spark.SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,749 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 87 (MapPartitionsRDD[349] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,749 INFO cluster.YarnScheduler: Adding task set 87.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,751 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 87.0 (TID 68) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,760 INFO storage.BlockManagerInfo: Added broadcast_70_piece0 in memory on algo-1:41051 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,793 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 87.0 (TID 68) in 41 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,793 INFO cluster.YarnScheduler: Removed TaskSet 87.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,794 INFO scheduler.DAGScheduler: ShuffleMapStage 87 (collect at AnalysisRunner.scala:326) finished in 0.051 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,795 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,795 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,795 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,796 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,850 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,851 INFO scheduler.DAGScheduler: Got job 60 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,851 INFO scheduler.DAGScheduler: Final stage: ResultStage 89 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,851 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 88)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,852 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,852 INFO scheduler.DAGScheduler: Submitting ResultStage 89 (MapPartitionsRDD[352] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,855 INFO memory.MemoryStore: Block broadcast_71 stored as values in memory (estimated size 66.2 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,857 INFO memory.MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,858 INFO storage.BlockManagerInfo: Added broadcast_71_piece0 in memory on 10.0.83.226:42275 (size: 19.2 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,858 INFO spark.SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,859 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 89 (MapPartitionsRDD[352] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,859 INFO cluster.YarnScheduler: Adding task set 89.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,860 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 89.0 (TID 69) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,871 INFO storage.BlockManagerInfo: Added broadcast_71_piece0 in memory on algo-1:41051 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,875 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 28 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,887 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 89.0 (TID 69) in 27 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,887 INFO cluster.YarnScheduler: Removed TaskSet 89.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,888 INFO scheduler.DAGScheduler: ResultStage 89 (collect at AnalysisRunner.scala:326) finished in 0.034 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,888 INFO scheduler.DAGScheduler: Job 60 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,888 INFO cluster.YarnScheduler: Killing all running tasks in stage 89: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,889 INFO scheduler.DAGScheduler: Job 60 finished: collect at AnalysisRunner.scala:326, took 0.039287 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,950 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,951 INFO scheduler.DAGScheduler: Registering RDD 360 (countByKey at ColumnProfiler.scala:592) as input to shuffle 29\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,951 INFO scheduler.DAGScheduler: Got job 61 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,951 INFO scheduler.DAGScheduler: Final stage: ResultStage 91 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,951 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 90)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,951 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 90)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,953 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 90 (MapPartitionsRDD[360] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,961 INFO memory.MemoryStore: Block broadcast_72 stored as values in memory (estimated size 47.1 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,962 INFO memory.MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,962 INFO storage.BlockManagerInfo: Added broadcast_72_piece0 in memory on 10.0.83.226:42275 (size: 18.8 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,963 INFO spark.SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,963 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 90 (MapPartitionsRDD[360] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,963 INFO cluster.YarnScheduler: Adding task set 90.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,964 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 90.0 (TID 70) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:46,974 INFO storage.BlockManagerInfo: Added broadcast_72_piece0 in memory on algo-1:41051 (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,014 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 90.0 (TID 70) in 50 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,015 INFO cluster.YarnScheduler: Removed TaskSet 90.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,015 INFO scheduler.DAGScheduler: ShuffleMapStage 90 (countByKey at ColumnProfiler.scala:592) finished in 0.062 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,016 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,016 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,016 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 91)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,016 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,017 INFO scheduler.DAGScheduler: Submitting ResultStage 91 (ShuffledRDD[361] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,019 INFO memory.MemoryStore: Block broadcast_73 stored as values in memory (estimated size 5.1 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,021 INFO memory.MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,021 INFO storage.BlockManagerInfo: Added broadcast_73_piece0 in memory on 10.0.83.226:42275 (size: 3.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,025 INFO spark.SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,026 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 91 (ShuffledRDD[361] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,026 INFO cluster.YarnScheduler: Adding task set 91.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,027 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 91.0 (TID 71) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,037 INFO storage.BlockManagerInfo: Added broadcast_73_piece0 in memory on algo-1:41051 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,042 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,056 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 91.0 (TID 71) in 29 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,057 INFO scheduler.DAGScheduler: ResultStage 91 (countByKey at ColumnProfiler.scala:592) finished in 0.038 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,057 INFO cluster.YarnScheduler: Removed TaskSet 91.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,057 INFO scheduler.DAGScheduler: Job 61 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,057 INFO cluster.YarnScheduler: Killing all running tasks in stage 91: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,058 INFO scheduler.DAGScheduler: Job 61 finished: countByKey at ColumnProfiler.scala:592, took 0.107457 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,173 INFO scheduler.DAGScheduler: Registering RDD 366 (collect at AnalysisRunner.scala:326) as input to shuffle 30\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,173 INFO scheduler.DAGScheduler: Got map stage job 62 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,173 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 92 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,173 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,174 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,174 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 92 (MapPartitionsRDD[366] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,178 INFO memory.MemoryStore: Block broadcast_74 stored as values in memory (estimated size 100.0 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,179 INFO memory.MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1456.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,180 INFO storage.BlockManagerInfo: Added broadcast_74_piece0 in memory on 10.0.83.226:42275 (size: 32.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,180 INFO spark.SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,181 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 92 (MapPartitionsRDD[366] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,181 INFO cluster.YarnScheduler: Adding task set 92.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,182 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 92.0 (TID 72) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,190 INFO storage.BlockManagerInfo: Added broadcast_74_piece0 in memory on algo-1:41051 (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,340 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 92.0 (TID 72) in 158 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,341 INFO cluster.YarnScheduler: Removed TaskSet 92.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,341 INFO scheduler.DAGScheduler: ShuffleMapStage 92 (collect at AnalysisRunner.scala:326) finished in 0.167 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,342 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,342 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,342 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,342 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,412 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,414 INFO scheduler.DAGScheduler: Got job 63 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,415 INFO scheduler.DAGScheduler: Final stage: ResultStage 94 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,415 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 93)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,415 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,416 INFO scheduler.DAGScheduler: Submitting ResultStage 94 (MapPartitionsRDD[369] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,423 INFO memory.MemoryStore: Block broadcast_75 stored as values in memory (estimated size 184.6 KiB, free 1456.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,429 INFO memory.MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1456.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,431 INFO storage.BlockManagerInfo: Added broadcast_75_piece0 in memory on 10.0.83.226:42275 (size: 50.3 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,432 INFO spark.SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,437 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 94 (MapPartitionsRDD[369] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,438 INFO cluster.YarnScheduler: Adding task set 94.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,442 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 94.0 (TID 73) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,451 INFO storage.BlockManagerInfo: Added broadcast_75_piece0 in memory on algo-1:41051 (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,470 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 30 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,605 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 94.0 (TID 73) in 163 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,606 INFO cluster.YarnScheduler: Removed TaskSet 94.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,607 INFO scheduler.DAGScheduler: ResultStage 94 (collect at AnalysisRunner.scala:326) finished in 0.190 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,608 INFO scheduler.DAGScheduler: Job 63 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,608 INFO cluster.YarnScheduler: Killing all running tasks in stage 94: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,609 INFO scheduler.DAGScheduler: Job 63 finished: collect at AnalysisRunner.scala:326, took 0.196454 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,719 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,720 INFO scheduler.DAGScheduler: Got job 64 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,720 INFO scheduler.DAGScheduler: Final stage: ResultStage 95 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,721 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,721 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,722 INFO scheduler.DAGScheduler: Submitting ResultStage 95 (MapPartitionsRDD[379] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,729 INFO memory.MemoryStore: Block broadcast_76 stored as values in memory (estimated size 54.8 KiB, free 1456.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,734 INFO memory.MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1456.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,738 INFO storage.BlockManagerInfo: Added broadcast_76_piece0 in memory on 10.0.83.226:42275 (size: 20.7 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,738 INFO spark.SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,739 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 95 (MapPartitionsRDD[379] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,739 INFO cluster.YarnScheduler: Adding task set 95.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,740 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 95.0 (TID 74) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,761 INFO storage.BlockManagerInfo: Added broadcast_76_piece0 in memory on algo-1:41051 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,785 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 95.0 (TID 74) in 45 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,785 INFO cluster.YarnScheduler: Removed TaskSet 95.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,786 INFO scheduler.DAGScheduler: ResultStage 95 (treeReduce at KLLRunner.scala:107) finished in 0.062 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,786 INFO scheduler.DAGScheduler: Job 64 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,786 INFO cluster.YarnScheduler: Killing all running tasks in stage 95: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,787 INFO scheduler.DAGScheduler: Job 64 finished: treeReduce at KLLRunner.scala:107, took 0.067382 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,977 INFO storage.BlockManagerInfo: Removed broadcast_72_piece0 on 10.0.83.226:42275 in memory (size: 18.8 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,977 INFO storage.BlockManagerInfo: Removed broadcast_72_piece0 on algo-1:41051 in memory (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,986 INFO scheduler.DAGScheduler: Registering RDD 384 (collect at AnalysisRunner.scala:326) as input to shuffle 31\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,986 INFO scheduler.DAGScheduler: Got map stage job 65 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,986 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 96 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,986 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,987 INFO storage.BlockManagerInfo: Removed broadcast_76_piece0 on 10.0.83.226:42275 in memory (size: 20.7 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,987 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,988 INFO storage.BlockManagerInfo: Removed broadcast_76_piece0 on algo-1:41051 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,988 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 96 (MapPartitionsRDD[384] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,991 INFO memory.MemoryStore: Block broadcast_77 stored as values in memory (estimated size 90.7 KiB, free 1456.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,992 INFO storage.BlockManagerInfo: Removed broadcast_74_piece0 on 10.0.83.226:42275 in memory (size: 32.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,993 INFO memory.MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1456.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,994 INFO storage.BlockManagerInfo: Removed broadcast_74_piece0 on algo-1:41051 in memory (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,994 INFO storage.BlockManagerInfo: Added broadcast_77_piece0 in memory on 10.0.83.226:42275 (size: 27.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,995 INFO spark.SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,995 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 96 (MapPartitionsRDD[384] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,996 INFO cluster.YarnScheduler: Adding task set 96.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:47,997 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 96.0 (TID 75) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,000 INFO storage.BlockManagerInfo: Removed broadcast_73_piece0 on 10.0.83.226:42275 in memory (size: 3.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,002 INFO storage.BlockManagerInfo: Removed broadcast_73_piece0 on algo-1:41051 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,005 INFO storage.BlockManagerInfo: Added broadcast_77_piece0 in memory on algo-1:41051 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,010 INFO storage.BlockManagerInfo: Removed broadcast_69_piece0 on 10.0.83.226:42275 in memory (size: 20.7 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,014 INFO storage.BlockManagerInfo: Removed broadcast_69_piece0 on algo-1:41051 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,020 INFO storage.BlockManagerInfo: Removed broadcast_75_piece0 on 10.0.83.226:42275 in memory (size: 50.3 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,021 INFO storage.BlockManagerInfo: Removed broadcast_75_piece0 on algo-1:41051 in memory (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,026 INFO storage.BlockManagerInfo: Removed broadcast_64_piece0 on 10.0.83.226:42275 in memory (size: 19.2 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,027 INFO storage.BlockManagerInfo: Removed broadcast_64_piece0 on algo-1:41051 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,031 INFO storage.BlockManagerInfo: Removed broadcast_67_piece0 on 10.0.83.226:42275 in memory (size: 32.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,032 INFO storage.BlockManagerInfo: Removed broadcast_67_piece0 on algo-1:41051 in memory (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,035 INFO storage.BlockManagerInfo: Removed broadcast_71_piece0 on 10.0.83.226:42275 in memory (size: 19.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,036 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 96.0 (TID 75) in 39 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,036 INFO cluster.YarnScheduler: Removed TaskSet 96.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,037 INFO scheduler.DAGScheduler: ShuffleMapStage 96 (collect at AnalysisRunner.scala:326) finished in 0.048 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,038 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,038 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,038 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,039 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,045 INFO storage.BlockManagerInfo: Removed broadcast_71_piece0 on algo-1:41051 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,048 INFO storage.BlockManagerInfo: Removed broadcast_65_piece0 on 10.0.83.226:42275 in memory (size: 18.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,049 INFO storage.BlockManagerInfo: Removed broadcast_65_piece0 on algo-1:41051 in memory (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,054 INFO storage.BlockManagerInfo: Removed broadcast_66_piece0 on 10.0.83.226:42275 in memory (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,055 INFO storage.BlockManagerInfo: Removed broadcast_66_piece0 on algo-1:41051 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,067 INFO storage.BlockManagerInfo: Removed broadcast_68_piece0 on 10.0.83.226:42275 in memory (size: 50.3 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,068 INFO storage.BlockManagerInfo: Removed broadcast_68_piece0 on algo-1:41051 in memory (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,075 INFO storage.BlockManagerInfo: Removed broadcast_70_piece0 on algo-1:41051 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,078 INFO storage.BlockManagerInfo: Removed broadcast_70_piece0 on 10.0.83.226:42275 in memory (size: 27.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,113 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,114 INFO scheduler.DAGScheduler: Got job 66 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,114 INFO scheduler.DAGScheduler: Final stage: ResultStage 98 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,114 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 97)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,115 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,115 INFO scheduler.DAGScheduler: Submitting ResultStage 98 (MapPartitionsRDD[387] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,118 INFO memory.MemoryStore: Block broadcast_78 stored as values in memory (estimated size 66.2 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,120 INFO memory.MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,120 INFO storage.BlockManagerInfo: Added broadcast_78_piece0 in memory on 10.0.83.226:42275 (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,121 INFO spark.SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,121 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 98 (MapPartitionsRDD[387] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,121 INFO cluster.YarnScheduler: Adding task set 98.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,123 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 98.0 (TID 76) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,130 INFO storage.BlockManagerInfo: Added broadcast_78_piece0 in memory on algo-1:41051 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,136 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,142 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 98.0 (TID 76) in 19 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,142 INFO cluster.YarnScheduler: Removed TaskSet 98.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,143 INFO scheduler.DAGScheduler: ResultStage 98 (collect at AnalysisRunner.scala:326) finished in 0.026 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,144 INFO scheduler.DAGScheduler: Job 66 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,144 INFO cluster.YarnScheduler: Killing all running tasks in stage 98: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,145 INFO scheduler.DAGScheduler: Job 66 finished: collect at AnalysisRunner.scala:326, took 0.031424 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,207 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,208 INFO scheduler.DAGScheduler: Registering RDD 395 (countByKey at ColumnProfiler.scala:592) as input to shuffle 32\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,209 INFO scheduler.DAGScheduler: Got job 67 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,210 INFO scheduler.DAGScheduler: Final stage: ResultStage 100 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,210 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 99)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,210 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 99)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,212 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 99 (MapPartitionsRDD[395] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,216 INFO memory.MemoryStore: Block broadcast_79 stored as values in memory (estimated size 47.1 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,220 INFO memory.MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,220 INFO storage.BlockManagerInfo: Added broadcast_79_piece0 in memory on 10.0.83.226:42275 (size: 18.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,221 INFO spark.SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,222 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 99 (MapPartitionsRDD[395] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,222 INFO cluster.YarnScheduler: Adding task set 99.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,223 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 99.0 (TID 77) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,235 INFO storage.BlockManagerInfo: Added broadcast_79_piece0 in memory on algo-1:41051 (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,263 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 99.0 (TID 77) in 40 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,263 INFO cluster.YarnScheduler: Removed TaskSet 99.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,264 INFO scheduler.DAGScheduler: ShuffleMapStage 99 (countByKey at ColumnProfiler.scala:592) finished in 0.052 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,264 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,265 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,265 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 100)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,265 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,265 INFO scheduler.DAGScheduler: Submitting ResultStage 100 (ShuffledRDD[396] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,267 INFO memory.MemoryStore: Block broadcast_80 stored as values in memory (estimated size 5.1 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,268 INFO memory.MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,269 INFO storage.BlockManagerInfo: Added broadcast_80_piece0 in memory on 10.0.83.226:42275 (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,269 INFO spark.SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,269 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 100 (ShuffledRDD[396] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,269 INFO cluster.YarnScheduler: Adding task set 100.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,270 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 100.0 (TID 78) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,283 INFO storage.BlockManagerInfo: Added broadcast_80_piece0 in memory on algo-1:41051 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,286 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,302 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 100.0 (TID 78) in 32 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,303 INFO cluster.YarnScheduler: Removed TaskSet 100.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,303 INFO scheduler.DAGScheduler: ResultStage 100 (countByKey at ColumnProfiler.scala:592) finished in 0.037 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,303 INFO scheduler.DAGScheduler: Job 67 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,303 INFO cluster.YarnScheduler: Killing all running tasks in stage 100: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,304 INFO scheduler.DAGScheduler: Job 67 finished: countByKey at ColumnProfiler.scala:592, took 0.096573 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,452 INFO scheduler.DAGScheduler: Registering RDD 401 (collect at AnalysisRunner.scala:326) as input to shuffle 33\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,453 INFO scheduler.DAGScheduler: Got map stage job 68 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,453 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 101 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,453 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,454 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,454 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 101 (MapPartitionsRDD[401] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,460 INFO memory.MemoryStore: Block broadcast_81 stored as values in memory (estimated size 100.0 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,462 INFO memory.MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 33.0 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,462 INFO storage.BlockManagerInfo: Added broadcast_81_piece0 in memory on 10.0.83.226:42275 (size: 33.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,463 INFO spark.SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,464 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 101 (MapPartitionsRDD[401] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,464 INFO cluster.YarnScheduler: Adding task set 101.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,465 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 101.0 (TID 79) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,479 INFO storage.BlockManagerInfo: Added broadcast_81_piece0 in memory on algo-1:41051 (size: 33.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,604 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 101.0 (TID 79) in 139 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,604 INFO cluster.YarnScheduler: Removed TaskSet 101.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,605 INFO scheduler.DAGScheduler: ShuffleMapStage 101 (collect at AnalysisRunner.scala:326) finished in 0.149 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,606 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,606 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,607 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,607 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,642 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,643 INFO scheduler.DAGScheduler: Got job 69 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,644 INFO scheduler.DAGScheduler: Final stage: ResultStage 103 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,644 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 102)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,644 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,645 INFO scheduler.DAGScheduler: Submitting ResultStage 103 (MapPartitionsRDD[404] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,653 INFO memory.MemoryStore: Block broadcast_82 stored as values in memory (estimated size 184.6 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,655 INFO memory.MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,656 INFO storage.BlockManagerInfo: Added broadcast_82_piece0 in memory on 10.0.83.226:42275 (size: 50.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,656 INFO spark.SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,657 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 103 (MapPartitionsRDD[404] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,657 INFO cluster.YarnScheduler: Adding task set 103.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,658 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 103.0 (TID 80) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,666 INFO storage.BlockManagerInfo: Added broadcast_82_piece0 in memory on algo-1:41051 (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,675 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,766 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 103.0 (TID 80) in 108 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,766 INFO cluster.YarnScheduler: Removed TaskSet 103.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,767 INFO scheduler.DAGScheduler: ResultStage 103 (collect at AnalysisRunner.scala:326) finished in 0.120 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,768 INFO scheduler.DAGScheduler: Job 69 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,769 INFO cluster.YarnScheduler: Killing all running tasks in stage 103: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,770 INFO scheduler.DAGScheduler: Job 69 finished: collect at AnalysisRunner.scala:326, took 0.126739 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,905 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,915 INFO scheduler.DAGScheduler: Got job 70 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,916 INFO scheduler.DAGScheduler: Final stage: ResultStage 104 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,916 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,917 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,917 INFO scheduler.DAGScheduler: Submitting ResultStage 104 (MapPartitionsRDD[414] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,923 INFO memory.MemoryStore: Block broadcast_83 stored as values in memory (estimated size 54.8 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,931 INFO memory.MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,931 INFO storage.BlockManagerInfo: Added broadcast_83_piece0 in memory on 10.0.83.226:42275 (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,932 INFO spark.SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,932 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 104 (MapPartitionsRDD[414] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,933 INFO cluster.YarnScheduler: Adding task set 104.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,934 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 104.0 (TID 81) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,945 INFO storage.BlockManagerInfo: Added broadcast_83_piece0 in memory on algo-1:41051 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,983 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 104.0 (TID 81) in 49 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,983 INFO cluster.YarnScheduler: Removed TaskSet 104.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,984 INFO scheduler.DAGScheduler: ResultStage 104 (treeReduce at KLLRunner.scala:107) finished in 0.066 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,984 INFO scheduler.DAGScheduler: Job 70 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,984 INFO cluster.YarnScheduler: Killing all running tasks in stage 104: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:48,985 INFO scheduler.DAGScheduler: Job 70 finished: treeReduce at KLLRunner.scala:107, took 0.070223 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,127 INFO scheduler.DAGScheduler: Registering RDD 419 (collect at AnalysisRunner.scala:326) as input to shuffle 34\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,128 INFO scheduler.DAGScheduler: Got map stage job 71 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,128 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 105 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,129 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,129 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,130 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 105 (MapPartitionsRDD[419] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,134 INFO memory.MemoryStore: Block broadcast_84 stored as values in memory (estimated size 90.7 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,135 INFO memory.MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,136 INFO storage.BlockManagerInfo: Added broadcast_84_piece0 in memory on 10.0.83.226:42275 (size: 27.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,137 INFO spark.SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,137 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 105 (MapPartitionsRDD[419] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,137 INFO cluster.YarnScheduler: Adding task set 105.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,139 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 105.0 (TID 82) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,149 INFO storage.BlockManagerInfo: Added broadcast_84_piece0 in memory on algo-1:41051 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,167 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 105.0 (TID 82) in 29 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,167 INFO cluster.YarnScheduler: Removed TaskSet 105.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,168 INFO scheduler.DAGScheduler: ShuffleMapStage 105 (collect at AnalysisRunner.scala:326) finished in 0.037 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,168 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,168 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,168 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,168 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,226 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,227 INFO scheduler.DAGScheduler: Got job 72 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,227 INFO scheduler.DAGScheduler: Final stage: ResultStage 107 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,227 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 106)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,228 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,228 INFO scheduler.DAGScheduler: Submitting ResultStage 107 (MapPartitionsRDD[422] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,234 INFO memory.MemoryStore: Block broadcast_85 stored as values in memory (estimated size 66.2 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,236 INFO memory.MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,237 INFO storage.BlockManagerInfo: Added broadcast_85_piece0 in memory on 10.0.83.226:42275 (size: 19.2 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,238 INFO spark.SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,239 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 107 (MapPartitionsRDD[422] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,239 INFO cluster.YarnScheduler: Adding task set 107.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,240 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 107.0 (TID 83) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,252 INFO storage.BlockManagerInfo: Added broadcast_85_piece0 in memory on algo-1:41051 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,257 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,276 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 107.0 (TID 83) in 36 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,276 INFO cluster.YarnScheduler: Removed TaskSet 107.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,277 INFO scheduler.DAGScheduler: ResultStage 107 (collect at AnalysisRunner.scala:326) finished in 0.047 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,278 INFO scheduler.DAGScheduler: Job 72 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,278 INFO cluster.YarnScheduler: Killing all running tasks in stage 107: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,278 INFO scheduler.DAGScheduler: Job 72 finished: collect at AnalysisRunner.scala:326, took 0.052042 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,324 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,325 INFO scheduler.DAGScheduler: Registering RDD 430 (countByKey at ColumnProfiler.scala:592) as input to shuffle 35\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,327 INFO scheduler.DAGScheduler: Got job 73 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,328 INFO scheduler.DAGScheduler: Final stage: ResultStage 109 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,328 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 108)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,328 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 108)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,330 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 108 (MapPartitionsRDD[430] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,336 INFO memory.MemoryStore: Block broadcast_86 stored as values in memory (estimated size 47.1 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,338 INFO memory.MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1456.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,338 INFO storage.BlockManagerInfo: Added broadcast_86_piece0 in memory on 10.0.83.226:42275 (size: 18.8 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,339 INFO spark.SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,339 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 108 (MapPartitionsRDD[430] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,339 INFO cluster.YarnScheduler: Adding task set 108.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,340 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 108.0 (TID 84) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,351 INFO storage.BlockManagerInfo: Added broadcast_86_piece0 in memory on algo-1:41051 (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,397 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 108.0 (TID 84) in 57 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,397 INFO cluster.YarnScheduler: Removed TaskSet 108.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,398 INFO scheduler.DAGScheduler: ShuffleMapStage 108 (countByKey at ColumnProfiler.scala:592) finished in 0.066 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,398 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,400 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,400 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 109)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,400 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,400 INFO scheduler.DAGScheduler: Submitting ResultStage 109 (ShuffledRDD[431] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,402 INFO memory.MemoryStore: Block broadcast_87 stored as values in memory (estimated size 5.1 KiB, free 1456.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,403 INFO memory.MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1456.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,403 INFO storage.BlockManagerInfo: Added broadcast_87_piece0 in memory on 10.0.83.226:42275 (size: 3.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,404 INFO spark.SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,404 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 109 (ShuffledRDD[431] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,404 INFO cluster.YarnScheduler: Adding task set 109.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,405 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 109.0 (TID 85) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,414 INFO storage.BlockManagerInfo: Added broadcast_87_piece0 in memory on algo-1:41051 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,417 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,427 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 109.0 (TID 85) in 22 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,427 INFO cluster.YarnScheduler: Removed TaskSet 109.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,428 INFO scheduler.DAGScheduler: ResultStage 109 (countByKey at ColumnProfiler.scala:592) finished in 0.027 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,428 INFO scheduler.DAGScheduler: Job 73 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,428 INFO cluster.YarnScheduler: Killing all running tasks in stage 109: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,428 INFO scheduler.DAGScheduler: Job 73 finished: countByKey at ColumnProfiler.scala:592, took 0.103765 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,524 INFO scheduler.DAGScheduler: Registering RDD 436 (collect at AnalysisRunner.scala:326) as input to shuffle 36\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,525 INFO scheduler.DAGScheduler: Got map stage job 74 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,525 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 110 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,525 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,526 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,526 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 110 (MapPartitionsRDD[436] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,532 INFO memory.MemoryStore: Block broadcast_88 stored as values in memory (estimated size 100.0 KiB, free 1456.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,535 INFO memory.MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1456.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,535 INFO storage.BlockManagerInfo: Added broadcast_88_piece0 in memory on 10.0.83.226:42275 (size: 32.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,536 INFO spark.SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,536 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 110 (MapPartitionsRDD[436] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,537 INFO cluster.YarnScheduler: Adding task set 110.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,538 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 110.0 (TID 86) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,551 INFO storage.BlockManagerInfo: Added broadcast_88_piece0 in memory on algo-1:41051 (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,704 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 110.0 (TID 86) in 166 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,705 INFO cluster.YarnScheduler: Removed TaskSet 110.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,705 INFO scheduler.DAGScheduler: ShuffleMapStage 110 (collect at AnalysisRunner.scala:326) finished in 0.177 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,706 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,707 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,707 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,707 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,736 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,737 INFO scheduler.DAGScheduler: Got job 75 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,737 INFO scheduler.DAGScheduler: Final stage: ResultStage 112 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,737 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 111)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,738 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,738 INFO scheduler.DAGScheduler: Submitting ResultStage 112 (MapPartitionsRDD[439] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,745 INFO memory.MemoryStore: Block broadcast_89 stored as values in memory (estimated size 184.6 KiB, free 1456.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,747 INFO memory.MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1456.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,748 INFO storage.BlockManagerInfo: Added broadcast_89_piece0 in memory on 10.0.83.226:42275 (size: 50.3 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,749 INFO spark.SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,749 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 112 (MapPartitionsRDD[439] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,749 INFO cluster.YarnScheduler: Adding task set 112.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,751 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 112.0 (TID 87) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,762 INFO storage.BlockManagerInfo: Added broadcast_89_piece0 in memory on algo-1:41051 (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,777 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,877 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 112.0 (TID 87) in 126 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,878 INFO cluster.YarnScheduler: Removed TaskSet 112.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,878 INFO scheduler.DAGScheduler: ResultStage 112 (collect at AnalysisRunner.scala:326) finished in 0.139 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,881 INFO scheduler.DAGScheduler: Job 75 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,881 INFO cluster.YarnScheduler: Killing all running tasks in stage 112: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,881 INFO scheduler.DAGScheduler: Job 75 finished: collect at AnalysisRunner.scala:326, took 0.145226 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,965 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,966 INFO scheduler.DAGScheduler: Got job 76 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,966 INFO scheduler.DAGScheduler: Final stage: ResultStage 113 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,966 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,967 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,967 INFO scheduler.DAGScheduler: Submitting ResultStage 113 (MapPartitionsRDD[449] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,972 INFO memory.MemoryStore: Block broadcast_90 stored as values in memory (estimated size 54.8 KiB, free 1456.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,974 INFO memory.MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 20.8 KiB, free 1456.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,975 INFO storage.BlockManagerInfo: Added broadcast_90_piece0 in memory on 10.0.83.226:42275 (size: 20.8 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,975 INFO spark.SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,976 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 113 (MapPartitionsRDD[449] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,976 INFO cluster.YarnScheduler: Adding task set 113.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,977 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 113.0 (TID 88) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:49,990 INFO storage.BlockManagerInfo: Added broadcast_90_piece0 in memory on algo-1:41051 (size: 20.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,010 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 113.0 (TID 88) in 33 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,010 INFO cluster.YarnScheduler: Removed TaskSet 113.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,011 INFO scheduler.DAGScheduler: ResultStage 113 (treeReduce at KLLRunner.scala:107) finished in 0.043 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,011 INFO scheduler.DAGScheduler: Job 76 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,012 INFO cluster.YarnScheduler: Killing all running tasks in stage 113: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,012 INFO scheduler.DAGScheduler: Job 76 finished: treeReduce at KLLRunner.scala:107, took 0.046702 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,170 INFO scheduler.DAGScheduler: Registering RDD 454 (collect at AnalysisRunner.scala:326) as input to shuffle 37\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,170 INFO scheduler.DAGScheduler: Got map stage job 77 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,170 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 114 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,171 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,171 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,171 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 114 (MapPartitionsRDD[454] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,174 INFO memory.MemoryStore: Block broadcast_91 stored as values in memory (estimated size 90.7 KiB, free 1456.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,176 INFO memory.MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1456.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,176 INFO storage.BlockManagerInfo: Added broadcast_91_piece0 in memory on 10.0.83.226:42275 (size: 27.9 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,178 INFO spark.SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,178 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 114 (MapPartitionsRDD[454] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,178 INFO cluster.YarnScheduler: Adding task set 114.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,179 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 114.0 (TID 89) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,195 INFO storage.BlockManagerInfo: Added broadcast_91_piece0 in memory on algo-1:41051 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,210 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 114.0 (TID 89) in 31 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,210 INFO cluster.YarnScheduler: Removed TaskSet 114.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,210 INFO scheduler.DAGScheduler: ShuffleMapStage 114 (collect at AnalysisRunner.scala:326) finished in 0.038 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,211 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,211 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,211 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,211 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,333 INFO storage.BlockManagerInfo: Removed broadcast_83_piece0 on 10.0.83.226:42275 in memory (size: 20.7 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,336 INFO storage.BlockManagerInfo: Removed broadcast_83_piece0 on algo-1:41051 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,338 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,343 INFO storage.BlockManagerInfo: Removed broadcast_84_piece0 on 10.0.83.226:42275 in memory (size: 27.9 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,344 INFO storage.BlockManagerInfo: Removed broadcast_84_piece0 on algo-1:41051 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,349 INFO scheduler.DAGScheduler: Got job 78 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,349 INFO scheduler.DAGScheduler: Final stage: ResultStage 116 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,350 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 115)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,350 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,350 INFO scheduler.DAGScheduler: Submitting ResultStage 116 (MapPartitionsRDD[457] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,352 INFO storage.BlockManagerInfo: Removed broadcast_82_piece0 on 10.0.83.226:42275 in memory (size: 50.3 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,354 INFO memory.MemoryStore: Block broadcast_92 stored as values in memory (estimated size 66.2 KiB, free 1456.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,356 INFO storage.BlockManagerInfo: Removed broadcast_82_piece0 on algo-1:41051 in memory (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,357 INFO memory.MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1456.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,357 INFO storage.BlockManagerInfo: Added broadcast_92_piece0 in memory on 10.0.83.226:42275 (size: 19.2 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,357 INFO spark.SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,358 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 116 (MapPartitionsRDD[457] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,358 INFO cluster.YarnScheduler: Adding task set 116.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,359 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 116.0 (TID 90) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,361 INFO storage.BlockManagerInfo: Removed broadcast_81_piece0 on 10.0.83.226:42275 in memory (size: 33.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,364 INFO storage.BlockManagerInfo: Removed broadcast_81_piece0 on algo-1:41051 in memory (size: 33.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,369 INFO storage.BlockManagerInfo: Added broadcast_92_piece0 in memory on algo-1:41051 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,370 INFO storage.BlockManagerInfo: Removed broadcast_80_piece0 on 10.0.83.226:42275 in memory (size: 3.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,382 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,382 INFO storage.BlockManagerInfo: Removed broadcast_80_piece0 on algo-1:41051 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,390 INFO storage.BlockManagerInfo: Removed broadcast_77_piece0 on 10.0.83.226:42275 in memory (size: 27.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,393 INFO storage.BlockManagerInfo: Removed broadcast_77_piece0 on algo-1:41051 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,395 INFO storage.BlockManagerInfo: Removed broadcast_90_piece0 on 10.0.83.226:42275 in memory (size: 20.8 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,403 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 116.0 (TID 90) in 44 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,403 INFO cluster.YarnScheduler: Removed TaskSet 116.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,404 INFO scheduler.DAGScheduler: ResultStage 116 (collect at AnalysisRunner.scala:326) finished in 0.052 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,404 INFO scheduler.DAGScheduler: Job 78 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,404 INFO cluster.YarnScheduler: Killing all running tasks in stage 116: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,405 INFO scheduler.DAGScheduler: Job 78 finished: collect at AnalysisRunner.scala:326, took 0.066450 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,414 INFO storage.BlockManagerInfo: Removed broadcast_90_piece0 on algo-1:41051 in memory (size: 20.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,418 INFO storage.BlockManagerInfo: Removed broadcast_78_piece0 on 10.0.83.226:42275 in memory (size: 19.2 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,421 INFO storage.BlockManagerInfo: Removed broadcast_78_piece0 on algo-1:41051 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,430 INFO storage.BlockManagerInfo: Removed broadcast_86_piece0 on 10.0.83.226:42275 in memory (size: 18.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,434 INFO storage.BlockManagerInfo: Removed broadcast_86_piece0 on algo-1:41051 in memory (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,436 INFO storage.BlockManagerInfo: Removed broadcast_91_piece0 on 10.0.83.226:42275 in memory (size: 27.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,439 INFO storage.BlockManagerInfo: Removed broadcast_91_piece0 on algo-1:41051 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,441 INFO storage.BlockManagerInfo: Removed broadcast_89_piece0 on 10.0.83.226:42275 in memory (size: 50.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,442 INFO storage.BlockManagerInfo: Removed broadcast_89_piece0 on algo-1:41051 in memory (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,444 INFO storage.BlockManagerInfo: Removed broadcast_88_piece0 on 10.0.83.226:42275 in memory (size: 32.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,449 INFO storage.BlockManagerInfo: Removed broadcast_88_piece0 on algo-1:41051 in memory (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,452 INFO storage.BlockManagerInfo: Removed broadcast_85_piece0 on 10.0.83.226:42275 in memory (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,455 INFO storage.BlockManagerInfo: Removed broadcast_85_piece0 on algo-1:41051 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,460 INFO storage.BlockManagerInfo: Removed broadcast_79_piece0 on 10.0.83.226:42275 in memory (size: 18.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,461 INFO storage.BlockManagerInfo: Removed broadcast_79_piece0 on algo-1:41051 in memory (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,463 INFO storage.BlockManagerInfo: Removed broadcast_87_piece0 on 10.0.83.226:42275 in memory (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,465 INFO storage.BlockManagerInfo: Removed broadcast_87_piece0 on algo-1:41051 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,489 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,490 INFO scheduler.DAGScheduler: Registering RDD 465 (countByKey at ColumnProfiler.scala:592) as input to shuffle 38\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,490 INFO scheduler.DAGScheduler: Got job 79 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,491 INFO scheduler.DAGScheduler: Final stage: ResultStage 118 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,491 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 117)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,491 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 117)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,492 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 117 (MapPartitionsRDD[465] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,499 INFO memory.MemoryStore: Block broadcast_93 stored as values in memory (estimated size 47.1 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,501 INFO memory.MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,502 INFO storage.BlockManagerInfo: Added broadcast_93_piece0 in memory on 10.0.83.226:42275 (size: 18.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,502 INFO spark.SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,503 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 117 (MapPartitionsRDD[465] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,503 INFO cluster.YarnScheduler: Adding task set 117.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,504 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 117.0 (TID 91) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,518 INFO storage.BlockManagerInfo: Added broadcast_93_piece0 in memory on algo-1:41051 (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,558 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 117.0 (TID 91) in 54 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,562 INFO cluster.YarnScheduler: Removed TaskSet 117.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,562 INFO scheduler.DAGScheduler: ShuffleMapStage 117 (countByKey at ColumnProfiler.scala:592) finished in 0.068 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,562 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,563 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,563 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 118)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,563 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,563 INFO scheduler.DAGScheduler: Submitting ResultStage 118 (ShuffledRDD[466] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,564 INFO memory.MemoryStore: Block broadcast_94 stored as values in memory (estimated size 5.1 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,566 INFO memory.MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,566 INFO storage.BlockManagerInfo: Added broadcast_94_piece0 in memory on 10.0.83.226:42275 (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,567 INFO spark.SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,567 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 118 (ShuffledRDD[466] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,567 INFO cluster.YarnScheduler: Adding task set 118.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,568 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 118.0 (TID 92) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,576 INFO storage.BlockManagerInfo: Added broadcast_94_piece0 in memory on algo-1:41051 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,583 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,592 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 118.0 (TID 92) in 24 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,593 INFO scheduler.DAGScheduler: ResultStage 118 (countByKey at ColumnProfiler.scala:592) finished in 0.029 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,594 INFO scheduler.DAGScheduler: Job 79 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,594 INFO cluster.YarnScheduler: Removed TaskSet 118.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,595 INFO cluster.YarnScheduler: Killing all running tasks in stage 118: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,595 INFO scheduler.DAGScheduler: Job 79 finished: countByKey at ColumnProfiler.scala:592, took 0.106139 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,736 INFO scheduler.DAGScheduler: Registering RDD 471 (collect at AnalysisRunner.scala:326) as input to shuffle 39\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,737 INFO scheduler.DAGScheduler: Got map stage job 80 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,737 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 119 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,737 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,738 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,738 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 119 (MapPartitionsRDD[471] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,743 INFO memory.MemoryStore: Block broadcast_95 stored as values in memory (estimated size 100.0 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,745 INFO memory.MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 32.8 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,746 INFO storage.BlockManagerInfo: Added broadcast_95_piece0 in memory on 10.0.83.226:42275 (size: 32.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,746 INFO spark.SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,747 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 119 (MapPartitionsRDD[471] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,747 INFO cluster.YarnScheduler: Adding task set 119.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,749 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 119.0 (TID 93) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,758 INFO storage.BlockManagerInfo: Added broadcast_95_piece0 in memory on algo-1:41051 (size: 32.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,845 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 119.0 (TID 93) in 97 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,846 INFO scheduler.DAGScheduler: ShuffleMapStage 119 (collect at AnalysisRunner.scala:326) finished in 0.106 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,847 INFO cluster.YarnScheduler: Removed TaskSet 119.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,847 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,847 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,847 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,848 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,885 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,886 INFO scheduler.DAGScheduler: Got job 81 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,886 INFO scheduler.DAGScheduler: Final stage: ResultStage 121 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,886 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 120)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,886 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,887 INFO scheduler.DAGScheduler: Submitting ResultStage 121 (MapPartitionsRDD[474] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,894 INFO memory.MemoryStore: Block broadcast_96 stored as values in memory (estimated size 184.6 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,896 INFO memory.MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,896 INFO storage.BlockManagerInfo: Added broadcast_96_piece0 in memory on 10.0.83.226:42275 (size: 50.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,897 INFO spark.SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,897 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 121 (MapPartitionsRDD[474] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,897 INFO cluster.YarnScheduler: Adding task set 121.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,899 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 121.0 (TID 94) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,912 INFO storage.BlockManagerInfo: Added broadcast_96_piece0 in memory on algo-1:41051 (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,924 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,988 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 121.0 (TID 94) in 90 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,988 INFO scheduler.DAGScheduler: ResultStage 121 (collect at AnalysisRunner.scala:326) finished in 0.100 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,990 INFO scheduler.DAGScheduler: Job 81 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,989 INFO cluster.YarnScheduler: Removed TaskSet 121.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,990 INFO cluster.YarnScheduler: Killing all running tasks in stage 121: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:50,991 INFO scheduler.DAGScheduler: Job 81 finished: collect at AnalysisRunner.scala:326, took 0.105819 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,150 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,150 INFO scheduler.DAGScheduler: Got job 82 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,150 INFO scheduler.DAGScheduler: Final stage: ResultStage 122 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,150 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,151 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,151 INFO scheduler.DAGScheduler: Submitting ResultStage 122 (MapPartitionsRDD[484] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,157 INFO memory.MemoryStore: Block broadcast_97 stored as values in memory (estimated size 54.8 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,159 INFO memory.MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,159 INFO storage.BlockManagerInfo: Added broadcast_97_piece0 in memory on 10.0.83.226:42275 (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,159 INFO spark.SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,160 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 122 (MapPartitionsRDD[484] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,160 INFO cluster.YarnScheduler: Adding task set 122.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,161 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 122.0 (TID 95) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,172 INFO storage.BlockManagerInfo: Added broadcast_97_piece0 in memory on algo-1:41051 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,192 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 122.0 (TID 95) in 31 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,193 INFO cluster.YarnScheduler: Removed TaskSet 122.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,193 INFO scheduler.DAGScheduler: ResultStage 122 (treeReduce at KLLRunner.scala:107) finished in 0.041 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,193 INFO scheduler.DAGScheduler: Job 82 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,194 INFO cluster.YarnScheduler: Killing all running tasks in stage 122: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,194 INFO scheduler.DAGScheduler: Job 82 finished: treeReduce at KLLRunner.scala:107, took 0.044158 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,292 INFO scheduler.DAGScheduler: Registering RDD 489 (collect at AnalysisRunner.scala:326) as input to shuffle 40\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,292 INFO scheduler.DAGScheduler: Got map stage job 83 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,292 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 123 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,293 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,293 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,293 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 123 (MapPartitionsRDD[489] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,296 INFO memory.MemoryStore: Block broadcast_98 stored as values in memory (estimated size 90.7 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,298 INFO memory.MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,298 INFO storage.BlockManagerInfo: Added broadcast_98_piece0 in memory on 10.0.83.226:42275 (size: 27.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,298 INFO spark.SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,299 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 123 (MapPartitionsRDD[489] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,299 INFO cluster.YarnScheduler: Adding task set 123.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,300 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 123.0 (TID 96) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,311 INFO storage.BlockManagerInfo: Added broadcast_98_piece0 in memory on algo-1:41051 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,327 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 123.0 (TID 96) in 27 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,328 INFO cluster.YarnScheduler: Removed TaskSet 123.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,328 INFO scheduler.DAGScheduler: ShuffleMapStage 123 (collect at AnalysisRunner.scala:326) finished in 0.034 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,328 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,328 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,328 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,328 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,368 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,369 INFO scheduler.DAGScheduler: Got job 84 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,369 INFO scheduler.DAGScheduler: Final stage: ResultStage 125 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,369 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 124)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,369 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,370 INFO scheduler.DAGScheduler: Submitting ResultStage 125 (MapPartitionsRDD[492] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,371 INFO memory.MemoryStore: Block broadcast_99 stored as values in memory (estimated size 66.2 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,372 INFO memory.MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,373 INFO storage.BlockManagerInfo: Added broadcast_99_piece0 in memory on 10.0.83.226:42275 (size: 19.2 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,374 INFO spark.SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,374 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 125 (MapPartitionsRDD[492] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,374 INFO cluster.YarnScheduler: Adding task set 125.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,375 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 125.0 (TID 97) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,383 INFO storage.BlockManagerInfo: Added broadcast_99_piece0 in memory on algo-1:41051 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,386 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 40 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,391 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 125.0 (TID 97) in 16 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,391 INFO cluster.YarnScheduler: Removed TaskSet 125.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,392 INFO scheduler.DAGScheduler: ResultStage 125 (collect at AnalysisRunner.scala:326) finished in 0.022 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,392 INFO scheduler.DAGScheduler: Job 84 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,392 INFO cluster.YarnScheduler: Killing all running tasks in stage 125: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,393 INFO scheduler.DAGScheduler: Job 84 finished: collect at AnalysisRunner.scala:326, took 0.024127 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,438 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,439 INFO scheduler.DAGScheduler: Registering RDD 500 (countByKey at ColumnProfiler.scala:592) as input to shuffle 41\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,439 INFO scheduler.DAGScheduler: Got job 85 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,439 INFO scheduler.DAGScheduler: Final stage: ResultStage 127 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,439 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 126)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,439 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 126)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,440 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 126 (MapPartitionsRDD[500] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,443 INFO memory.MemoryStore: Block broadcast_100 stored as values in memory (estimated size 47.1 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,444 INFO memory.MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,445 INFO storage.BlockManagerInfo: Added broadcast_100_piece0 in memory on 10.0.83.226:42275 (size: 18.8 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,445 INFO spark.SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,446 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 126 (MapPartitionsRDD[500] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,446 INFO cluster.YarnScheduler: Adding task set 126.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,447 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 126.0 (TID 98) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,453 INFO storage.BlockManagerInfo: Added broadcast_100_piece0 in memory on algo-1:41051 (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,477 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 126.0 (TID 98) in 30 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,477 INFO cluster.YarnScheduler: Removed TaskSet 126.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,478 INFO scheduler.DAGScheduler: ShuffleMapStage 126 (countByKey at ColumnProfiler.scala:592) finished in 0.037 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,478 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,478 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,478 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 127)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,479 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,479 INFO scheduler.DAGScheduler: Submitting ResultStage 127 (ShuffledRDD[501] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,481 INFO memory.MemoryStore: Block broadcast_101 stored as values in memory (estimated size 5.1 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,482 INFO memory.MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,485 INFO storage.BlockManagerInfo: Added broadcast_101_piece0 in memory on 10.0.83.226:42275 (size: 3.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,487 INFO spark.SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,488 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 127 (ShuffledRDD[501] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,488 INFO cluster.YarnScheduler: Adding task set 127.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,489 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 127.0 (TID 99) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,499 INFO storage.BlockManagerInfo: Added broadcast_101_piece0 in memory on algo-1:41051 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,511 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,530 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 127.0 (TID 99) in 41 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,531 INFO cluster.YarnScheduler: Removed TaskSet 127.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,532 INFO scheduler.DAGScheduler: ResultStage 127 (countByKey at ColumnProfiler.scala:592) finished in 0.052 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,532 INFO scheduler.DAGScheduler: Job 85 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,532 INFO cluster.YarnScheduler: Killing all running tasks in stage 127: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,533 INFO scheduler.DAGScheduler: Job 85 finished: countByKey at ColumnProfiler.scala:592, took 0.095022 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,647 INFO scheduler.DAGScheduler: Registering RDD 506 (collect at AnalysisRunner.scala:326) as input to shuffle 42\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,648 INFO scheduler.DAGScheduler: Got map stage job 86 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,648 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 128 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,648 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,649 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,650 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 128 (MapPartitionsRDD[506] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,655 INFO memory.MemoryStore: Block broadcast_102 stored as values in memory (estimated size 100.0 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,658 INFO memory.MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1456.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,658 INFO storage.BlockManagerInfo: Added broadcast_102_piece0 in memory on 10.0.83.226:42275 (size: 32.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,659 INFO spark.SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,659 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 128 (MapPartitionsRDD[506] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,660 INFO cluster.YarnScheduler: Adding task set 128.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,661 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 128.0 (TID 100) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,671 INFO storage.BlockManagerInfo: Added broadcast_102_piece0 in memory on algo-1:41051 (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,801 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 128.0 (TID 100) in 141 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,802 INFO cluster.YarnScheduler: Removed TaskSet 128.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,802 INFO scheduler.DAGScheduler: ShuffleMapStage 128 (collect at AnalysisRunner.scala:326) finished in 0.151 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,803 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,804 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,804 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,804 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,836 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,837 INFO scheduler.DAGScheduler: Got job 87 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,838 INFO scheduler.DAGScheduler: Final stage: ResultStage 130 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,838 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 129)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,838 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,839 INFO scheduler.DAGScheduler: Submitting ResultStage 130 (MapPartitionsRDD[509] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,845 INFO memory.MemoryStore: Block broadcast_103 stored as values in memory (estimated size 184.6 KiB, free 1456.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,847 INFO memory.MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1456.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,847 INFO storage.BlockManagerInfo: Added broadcast_103_piece0 in memory on 10.0.83.226:42275 (size: 50.3 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,848 INFO spark.SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,848 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 130 (MapPartitionsRDD[509] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,848 INFO cluster.YarnScheduler: Adding task set 130.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,850 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 130.0 (TID 101) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,858 INFO storage.BlockManagerInfo: Added broadcast_103_piece0 in memory on algo-1:41051 (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:51,870 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 42 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,046 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 130.0 (TID 101) in 197 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,047 INFO cluster.YarnScheduler: Removed TaskSet 130.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,047 INFO scheduler.DAGScheduler: ResultStage 130 (collect at AnalysisRunner.scala:326) finished in 0.208 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,048 INFO scheduler.DAGScheduler: Job 87 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,048 INFO cluster.YarnScheduler: Killing all running tasks in stage 130: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,048 INFO scheduler.DAGScheduler: Job 87 finished: collect at AnalysisRunner.scala:326, took 0.211557 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,171 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,175 INFO scheduler.DAGScheduler: Got job 88 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,176 INFO scheduler.DAGScheduler: Final stage: ResultStage 131 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,176 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,177 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,177 INFO scheduler.DAGScheduler: Submitting ResultStage 131 (MapPartitionsRDD[519] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,182 INFO memory.MemoryStore: Block broadcast_104 stored as values in memory (estimated size 54.8 KiB, free 1456.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,184 INFO memory.MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1456.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,185 INFO storage.BlockManagerInfo: Added broadcast_104_piece0 in memory on 10.0.83.226:42275 (size: 20.7 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,185 INFO spark.SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,185 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 131 (MapPartitionsRDD[519] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,186 INFO cluster.YarnScheduler: Adding task set 131.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,187 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 131.0 (TID 102) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,194 INFO storage.BlockManagerInfo: Added broadcast_104_piece0 in memory on algo-1:41051 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,237 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 131.0 (TID 102) in 50 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,237 INFO cluster.YarnScheduler: Removed TaskSet 131.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,238 INFO scheduler.DAGScheduler: ResultStage 131 (treeReduce at KLLRunner.scala:107) finished in 0.060 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,238 INFO scheduler.DAGScheduler: Job 88 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,239 INFO cluster.YarnScheduler: Killing all running tasks in stage 131: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,239 INFO scheduler.DAGScheduler: Job 88 finished: treeReduce at KLLRunner.scala:107, took 0.067834 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,350 INFO scheduler.DAGScheduler: Registering RDD 524 (collect at AnalysisRunner.scala:326) as input to shuffle 43\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,350 INFO scheduler.DAGScheduler: Got map stage job 89 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,350 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 132 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,350 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,351 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,352 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 132 (MapPartitionsRDD[524] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,354 INFO memory.MemoryStore: Block broadcast_105 stored as values in memory (estimated size 90.7 KiB, free 1456.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,356 INFO memory.MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1456.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,356 INFO storage.BlockManagerInfo: Added broadcast_105_piece0 in memory on 10.0.83.226:42275 (size: 27.9 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,357 INFO spark.SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,357 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 132 (MapPartitionsRDD[524] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,357 INFO cluster.YarnScheduler: Adding task set 132.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,358 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 132.0 (TID 103) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,371 INFO storage.BlockManagerInfo: Added broadcast_105_piece0 in memory on algo-1:41051 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,392 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 132.0 (TID 103) in 34 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,392 INFO cluster.YarnScheduler: Removed TaskSet 132.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,393 INFO scheduler.DAGScheduler: ShuffleMapStage 132 (collect at AnalysisRunner.scala:326) finished in 0.040 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,395 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,396 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,396 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,396 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,455 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,456 INFO scheduler.DAGScheduler: Got job 90 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,457 INFO scheduler.DAGScheduler: Final stage: ResultStage 134 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,457 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 133)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,457 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,457 INFO scheduler.DAGScheduler: Submitting ResultStage 134 (MapPartitionsRDD[527] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,459 INFO memory.MemoryStore: Block broadcast_106 stored as values in memory (estimated size 66.2 KiB, free 1456.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,461 INFO memory.MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1456.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,461 INFO storage.BlockManagerInfo: Added broadcast_106_piece0 in memory on 10.0.83.226:42275 (size: 19.2 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,462 INFO spark.SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,462 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 134 (MapPartitionsRDD[527] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,463 INFO cluster.YarnScheduler: Adding task set 134.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,464 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 134.0 (TID 104) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,477 INFO storage.BlockManagerInfo: Added broadcast_106_piece0 in memory on algo-1:41051 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,482 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,497 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 134.0 (TID 104) in 33 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,497 INFO cluster.YarnScheduler: Removed TaskSet 134.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,498 INFO scheduler.DAGScheduler: ResultStage 134 (collect at AnalysisRunner.scala:326) finished in 0.038 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,498 INFO scheduler.DAGScheduler: Job 90 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,498 INFO cluster.YarnScheduler: Killing all running tasks in stage 134: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,498 INFO scheduler.DAGScheduler: Job 90 finished: collect at AnalysisRunner.scala:326, took 0.042614 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,542 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,543 INFO scheduler.DAGScheduler: Registering RDD 535 (countByKey at ColumnProfiler.scala:592) as input to shuffle 44\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,543 INFO scheduler.DAGScheduler: Got job 91 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,543 INFO scheduler.DAGScheduler: Final stage: ResultStage 136 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,543 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 135)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,543 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 135)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,544 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 135 (MapPartitionsRDD[535] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,548 INFO memory.MemoryStore: Block broadcast_107 stored as values in memory (estimated size 47.1 KiB, free 1456.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,549 INFO memory.MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1456.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,550 INFO storage.BlockManagerInfo: Added broadcast_107_piece0 in memory on 10.0.83.226:42275 (size: 18.8 KiB, free: 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,550 INFO spark.SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,551 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 135 (MapPartitionsRDD[535] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,551 INFO cluster.YarnScheduler: Adding task set 135.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,553 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 135.0 (TID 105) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,559 INFO storage.BlockManagerInfo: Added broadcast_107_piece0 in memory on algo-1:41051 (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,597 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 135.0 (TID 105) in 44 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,597 INFO cluster.YarnScheduler: Removed TaskSet 135.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,598 INFO scheduler.DAGScheduler: ShuffleMapStage 135 (countByKey at ColumnProfiler.scala:592) finished in 0.054 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,598 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,599 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,599 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 136)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,599 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,599 INFO scheduler.DAGScheduler: Submitting ResultStage 136 (ShuffledRDD[536] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,601 INFO memory.MemoryStore: Block broadcast_108 stored as values in memory (estimated size 5.1 KiB, free 1456.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,630 INFO memory.MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1456.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,631 INFO storage.BlockManagerInfo: Added broadcast_108_piece0 in memory on 10.0.83.226:42275 (size: 3.0 KiB, free: 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,632 INFO spark.SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,632 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 136 (ShuffledRDD[536] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,632 INFO cluster.YarnScheduler: Adding task set 136.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,633 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 136.0 (TID 106) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,643 INFO storage.BlockManagerInfo: Removed broadcast_105_piece0 on 10.0.83.226:42275 in memory (size: 27.9 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,646 INFO storage.BlockManagerInfo: Removed broadcast_105_piece0 on algo-1:41051 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,647 INFO storage.BlockManagerInfo: Added broadcast_108_piece0 in memory on algo-1:41051 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,650 INFO storage.BlockManagerInfo: Removed broadcast_92_piece0 on 10.0.83.226:42275 in memory (size: 19.2 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,654 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 44 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,654 INFO storage.BlockManagerInfo: Removed broadcast_92_piece0 on algo-1:41051 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,656 INFO storage.BlockManagerInfo: Removed broadcast_103_piece0 on 10.0.83.226:42275 in memory (size: 50.3 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,657 INFO storage.BlockManagerInfo: Removed broadcast_103_piece0 on algo-1:41051 in memory (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,659 INFO storage.BlockManagerInfo: Removed broadcast_96_piece0 on 10.0.83.226:42275 in memory (size: 50.3 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,660 INFO storage.BlockManagerInfo: Removed broadcast_96_piece0 on algo-1:41051 in memory (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,669 INFO storage.BlockManagerInfo: Removed broadcast_104_piece0 on 10.0.83.226:42275 in memory (size: 20.7 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,670 INFO storage.BlockManagerInfo: Removed broadcast_104_piece0 on algo-1:41051 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,673 INFO storage.BlockManagerInfo: Removed broadcast_98_piece0 on 10.0.83.226:42275 in memory (size: 27.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,674 INFO storage.BlockManagerInfo: Removed broadcast_98_piece0 on algo-1:41051 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,677 INFO storage.BlockManagerInfo: Removed broadcast_100_piece0 on 10.0.83.226:42275 in memory (size: 18.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,679 INFO storage.BlockManagerInfo: Removed broadcast_100_piece0 on algo-1:41051 in memory (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,681 INFO storage.BlockManagerInfo: Removed broadcast_97_piece0 on 10.0.83.226:42275 in memory (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,683 INFO storage.BlockManagerInfo: Removed broadcast_97_piece0 on algo-1:41051 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,690 INFO storage.BlockManagerInfo: Removed broadcast_95_piece0 on 10.0.83.226:42275 in memory (size: 32.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,691 INFO storage.BlockManagerInfo: Removed broadcast_95_piece0 on algo-1:41051 in memory (size: 32.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,696 INFO storage.BlockManagerInfo: Removed broadcast_93_piece0 on 10.0.83.226:42275 in memory (size: 18.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,696 INFO storage.BlockManagerInfo: Removed broadcast_93_piece0 on algo-1:41051 in memory (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,701 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 136.0 (TID 106) in 68 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,702 INFO cluster.YarnScheduler: Removed TaskSet 136.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,702 INFO storage.BlockManagerInfo: Removed broadcast_102_piece0 on 10.0.83.226:42275 in memory (size: 32.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,702 INFO scheduler.DAGScheduler: ResultStage 136 (countByKey at ColumnProfiler.scala:592) finished in 0.102 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,703 INFO storage.BlockManagerInfo: Removed broadcast_102_piece0 on algo-1:41051 in memory (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,704 INFO scheduler.DAGScheduler: Job 91 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,704 INFO cluster.YarnScheduler: Killing all running tasks in stage 136: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,704 INFO scheduler.DAGScheduler: Job 91 finished: countByKey at ColumnProfiler.scala:592, took 0.162206 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,707 INFO storage.BlockManagerInfo: Removed broadcast_106_piece0 on algo-1:41051 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,707 INFO storage.BlockManagerInfo: Removed broadcast_106_piece0 on 10.0.83.226:42275 in memory (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,710 INFO storage.BlockManagerInfo: Removed broadcast_101_piece0 on 10.0.83.226:42275 in memory (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,711 INFO storage.BlockManagerInfo: Removed broadcast_101_piece0 on algo-1:41051 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,714 INFO storage.BlockManagerInfo: Removed broadcast_99_piece0 on 10.0.83.226:42275 in memory (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,715 INFO storage.BlockManagerInfo: Removed broadcast_99_piece0 on algo-1:41051 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,718 INFO storage.BlockManagerInfo: Removed broadcast_94_piece0 on 10.0.83.226:42275 in memory (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,719 INFO storage.BlockManagerInfo: Removed broadcast_94_piece0 on algo-1:41051 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,933 INFO scheduler.DAGScheduler: Registering RDD 541 (collect at AnalysisRunner.scala:326) as input to shuffle 45\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,933 INFO scheduler.DAGScheduler: Got map stage job 92 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,933 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 137 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,933 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,934 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,934 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 137 (MapPartitionsRDD[541] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,938 INFO memory.MemoryStore: Block broadcast_109 stored as values in memory (estimated size 100.0 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,939 INFO memory.MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 32.8 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,940 INFO storage.BlockManagerInfo: Added broadcast_109_piece0 in memory on 10.0.83.226:42275 (size: 32.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,940 INFO spark.SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,941 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 137 (MapPartitionsRDD[541] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,941 INFO cluster.YarnScheduler: Adding task set 137.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,942 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 137.0 (TID 107) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:52,950 INFO storage.BlockManagerInfo: Added broadcast_109_piece0 in memory on algo-1:41051 (size: 32.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,097 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 137.0 (TID 107) in 155 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,097 INFO cluster.YarnScheduler: Removed TaskSet 137.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,098 INFO scheduler.DAGScheduler: ShuffleMapStage 137 (collect at AnalysisRunner.scala:326) finished in 0.163 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,099 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,099 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,099 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,099 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,138 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,139 INFO scheduler.DAGScheduler: Got job 93 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,139 INFO scheduler.DAGScheduler: Final stage: ResultStage 139 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,139 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 138)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,139 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,140 INFO scheduler.DAGScheduler: Submitting ResultStage 139 (MapPartitionsRDD[544] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,147 INFO memory.MemoryStore: Block broadcast_110 stored as values in memory (estimated size 184.6 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,149 INFO memory.MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,149 INFO storage.BlockManagerInfo: Added broadcast_110_piece0 in memory on 10.0.83.226:42275 (size: 50.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,150 INFO spark.SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,151 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 139 (MapPartitionsRDD[544] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,151 INFO cluster.YarnScheduler: Adding task set 139.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,154 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 139.0 (TID 108) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,161 INFO storage.BlockManagerInfo: Added broadcast_110_piece0 in memory on algo-1:41051 (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,186 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 45 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,314 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 139.0 (TID 108) in 160 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,314 INFO cluster.YarnScheduler: Removed TaskSet 139.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,315 INFO scheduler.DAGScheduler: ResultStage 139 (collect at AnalysisRunner.scala:326) finished in 0.175 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,315 INFO scheduler.DAGScheduler: Job 93 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,316 INFO cluster.YarnScheduler: Killing all running tasks in stage 139: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,316 INFO scheduler.DAGScheduler: Job 93 finished: collect at AnalysisRunner.scala:326, took 0.177993 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,444 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,445 INFO scheduler.DAGScheduler: Got job 94 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,445 INFO scheduler.DAGScheduler: Final stage: ResultStage 140 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,446 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,446 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,446 INFO scheduler.DAGScheduler: Submitting ResultStage 140 (MapPartitionsRDD[554] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,458 INFO memory.MemoryStore: Block broadcast_111 stored as values in memory (estimated size 54.8 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,460 INFO memory.MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,460 INFO storage.BlockManagerInfo: Added broadcast_111_piece0 in memory on 10.0.83.226:42275 (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,461 INFO spark.SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,461 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 140 (MapPartitionsRDD[554] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,462 INFO cluster.YarnScheduler: Adding task set 140.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,464 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 140.0 (TID 109) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,472 INFO storage.BlockManagerInfo: Added broadcast_111_piece0 in memory on algo-1:41051 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,517 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 140.0 (TID 109) in 53 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,517 INFO cluster.YarnScheduler: Removed TaskSet 140.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,518 INFO scheduler.DAGScheduler: ResultStage 140 (treeReduce at KLLRunner.scala:107) finished in 0.071 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,518 INFO scheduler.DAGScheduler: Job 94 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,518 INFO cluster.YarnScheduler: Killing all running tasks in stage 140: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,519 INFO scheduler.DAGScheduler: Job 94 finished: treeReduce at KLLRunner.scala:107, took 0.074247 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,707 INFO scheduler.DAGScheduler: Registering RDD 559 (collect at AnalysisRunner.scala:326) as input to shuffle 46\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,707 INFO scheduler.DAGScheduler: Got map stage job 95 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,707 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 141 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,707 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,708 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,709 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 141 (MapPartitionsRDD[559] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,711 INFO memory.MemoryStore: Block broadcast_112 stored as values in memory (estimated size 90.7 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,713 INFO memory.MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,713 INFO storage.BlockManagerInfo: Added broadcast_112_piece0 in memory on 10.0.83.226:42275 (size: 27.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,714 INFO spark.SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,714 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 141 (MapPartitionsRDD[559] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,714 INFO cluster.YarnScheduler: Adding task set 141.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,715 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 141.0 (TID 110) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,722 INFO storage.BlockManagerInfo: Added broadcast_112_piece0 in memory on algo-1:41051 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,746 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 141.0 (TID 110) in 31 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,746 INFO cluster.YarnScheduler: Removed TaskSet 141.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,747 INFO scheduler.DAGScheduler: ShuffleMapStage 141 (collect at AnalysisRunner.scala:326) finished in 0.038 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,750 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,750 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,751 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,751 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,796 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,797 INFO scheduler.DAGScheduler: Got job 96 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,797 INFO scheduler.DAGScheduler: Final stage: ResultStage 143 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,797 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 142)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,797 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,798 INFO scheduler.DAGScheduler: Submitting ResultStage 143 (MapPartitionsRDD[562] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,800 INFO memory.MemoryStore: Block broadcast_113 stored as values in memory (estimated size 66.2 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,805 INFO memory.MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,806 INFO storage.BlockManagerInfo: Added broadcast_113_piece0 in memory on 10.0.83.226:42275 (size: 19.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,807 INFO spark.SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,807 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 143 (MapPartitionsRDD[562] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,808 INFO cluster.YarnScheduler: Adding task set 143.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,809 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 143.0 (TID 111) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,817 INFO storage.BlockManagerInfo: Added broadcast_113_piece0 in memory on algo-1:41051 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,821 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 46 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,830 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 143.0 (TID 111) in 22 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,830 INFO cluster.YarnScheduler: Removed TaskSet 143.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,840 INFO scheduler.DAGScheduler: ResultStage 143 (collect at AnalysisRunner.scala:326) finished in 0.041 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,841 INFO scheduler.DAGScheduler: Job 96 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,841 INFO cluster.YarnScheduler: Killing all running tasks in stage 143: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,842 INFO scheduler.DAGScheduler: Job 96 finished: collect at AnalysisRunner.scala:326, took 0.046453 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,928 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,938 INFO scheduler.DAGScheduler: Registering RDD 570 (countByKey at ColumnProfiler.scala:592) as input to shuffle 47\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,939 INFO scheduler.DAGScheduler: Got job 97 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,939 INFO scheduler.DAGScheduler: Final stage: ResultStage 145 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,939 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 144)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,939 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 144)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,941 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 144 (MapPartitionsRDD[570] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,955 INFO memory.MemoryStore: Block broadcast_114 stored as values in memory (estimated size 47.1 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,957 INFO memory.MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,957 INFO storage.BlockManagerInfo: Added broadcast_114_piece0 in memory on 10.0.83.226:42275 (size: 18.8 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,957 INFO spark.SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,958 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 144 (MapPartitionsRDD[570] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,958 INFO cluster.YarnScheduler: Adding task set 144.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,959 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 144.0 (TID 112) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:53,967 INFO storage.BlockManagerInfo: Added broadcast_114_piece0 in memory on algo-1:41051 (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,004 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 144.0 (TID 112) in 45 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,004 INFO cluster.YarnScheduler: Removed TaskSet 144.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,005 INFO scheduler.DAGScheduler: ShuffleMapStage 144 (countByKey at ColumnProfiler.scala:592) finished in 0.062 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,005 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,005 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,006 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 145)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,006 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,006 INFO scheduler.DAGScheduler: Submitting ResultStage 145 (ShuffledRDD[571] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,007 INFO memory.MemoryStore: Block broadcast_115 stored as values in memory (estimated size 5.1 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,009 INFO memory.MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,009 INFO storage.BlockManagerInfo: Added broadcast_115_piece0 in memory on 10.0.83.226:42275 (size: 3.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,010 INFO spark.SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,010 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 145 (ShuffledRDD[571] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,010 INFO cluster.YarnScheduler: Adding task set 145.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,011 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 145.0 (TID 113) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,021 INFO storage.BlockManagerInfo: Added broadcast_115_piece0 in memory on algo-1:41051 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,023 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 47 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,031 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 145.0 (TID 113) in 20 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,031 INFO cluster.YarnScheduler: Removed TaskSet 145.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,032 INFO scheduler.DAGScheduler: ResultStage 145 (countByKey at ColumnProfiler.scala:592) finished in 0.025 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,033 INFO scheduler.DAGScheduler: Job 97 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,033 INFO cluster.YarnScheduler: Killing all running tasks in stage 145: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,033 INFO scheduler.DAGScheduler: Job 97 finished: countByKey at ColumnProfiler.scala:592, took 0.095503 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,117 INFO scheduler.DAGScheduler: Registering RDD 576 (collect at AnalysisRunner.scala:326) as input to shuffle 48\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,118 INFO scheduler.DAGScheduler: Got map stage job 98 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,118 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 146 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,118 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,118 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,119 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 146 (MapPartitionsRDD[576] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,123 INFO memory.MemoryStore: Block broadcast_116 stored as values in memory (estimated size 100.0 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,125 INFO memory.MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,126 INFO storage.BlockManagerInfo: Added broadcast_116_piece0 in memory on 10.0.83.226:42275 (size: 32.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,126 INFO spark.SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,127 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 146 (MapPartitionsRDD[576] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,127 INFO cluster.YarnScheduler: Adding task set 146.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,128 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 146.0 (TID 114) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,135 INFO storage.BlockManagerInfo: Added broadcast_116_piece0 in memory on algo-1:41051 (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,310 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 146.0 (TID 114) in 182 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,311 INFO cluster.YarnScheduler: Removed TaskSet 146.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,311 INFO scheduler.DAGScheduler: ShuffleMapStage 146 (collect at AnalysisRunner.scala:326) finished in 0.191 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,312 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,312 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,312 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,312 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,348 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,349 INFO scheduler.DAGScheduler: Got job 99 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,349 INFO scheduler.DAGScheduler: Final stage: ResultStage 148 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,349 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 147)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,350 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,350 INFO scheduler.DAGScheduler: Submitting ResultStage 148 (MapPartitionsRDD[579] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,357 INFO memory.MemoryStore: Block broadcast_117 stored as values in memory (estimated size 184.6 KiB, free 1456.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,359 INFO memory.MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1456.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,360 INFO storage.BlockManagerInfo: Added broadcast_117_piece0 in memory on 10.0.83.226:42275 (size: 50.3 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,360 INFO spark.SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,361 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 148 (MapPartitionsRDD[579] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,361 INFO cluster.YarnScheduler: Adding task set 148.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,362 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 148.0 (TID 115) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,368 INFO storage.BlockManagerInfo: Added broadcast_117_piece0 in memory on algo-1:41051 (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,388 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 48 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,490 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 148.0 (TID 115) in 128 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,490 INFO cluster.YarnScheduler: Removed TaskSet 148.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,491 INFO scheduler.DAGScheduler: ResultStage 148 (collect at AnalysisRunner.scala:326) finished in 0.140 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,492 INFO scheduler.DAGScheduler: Job 99 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,492 INFO cluster.YarnScheduler: Killing all running tasks in stage 148: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,492 INFO scheduler.DAGScheduler: Job 99 finished: collect at AnalysisRunner.scala:326, took 0.143391 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,592 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,593 INFO scheduler.DAGScheduler: Got job 100 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,593 INFO scheduler.DAGScheduler: Final stage: ResultStage 149 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,593 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,594 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,594 INFO scheduler.DAGScheduler: Submitting ResultStage 149 (MapPartitionsRDD[589] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,598 INFO memory.MemoryStore: Block broadcast_118 stored as values in memory (estimated size 54.8 KiB, free 1456.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,600 INFO memory.MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1456.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,600 INFO storage.BlockManagerInfo: Added broadcast_118_piece0 in memory on 10.0.83.226:42275 (size: 20.7 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,600 INFO spark.SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,600 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 149 (MapPartitionsRDD[589] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,600 INFO cluster.YarnScheduler: Adding task set 149.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,601 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 149.0 (TID 116) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,611 INFO storage.BlockManagerInfo: Added broadcast_118_piece0 in memory on algo-1:41051 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,624 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 149.0 (TID 116) in 23 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,624 INFO cluster.YarnScheduler: Removed TaskSet 149.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,625 INFO scheduler.DAGScheduler: ResultStage 149 (treeReduce at KLLRunner.scala:107) finished in 0.030 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,625 INFO scheduler.DAGScheduler: Job 100 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,625 INFO cluster.YarnScheduler: Killing all running tasks in stage 149: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,626 INFO scheduler.DAGScheduler: Job 100 finished: treeReduce at KLLRunner.scala:107, took 0.033738 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,710 INFO scheduler.DAGScheduler: Registering RDD 594 (collect at AnalysisRunner.scala:326) as input to shuffle 49\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,710 INFO scheduler.DAGScheduler: Got map stage job 101 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,710 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 150 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,710 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,711 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,711 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 150 (MapPartitionsRDD[594] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,713 INFO memory.MemoryStore: Block broadcast_119 stored as values in memory (estimated size 90.7 KiB, free 1456.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,715 INFO memory.MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1456.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,715 INFO storage.BlockManagerInfo: Added broadcast_119_piece0 in memory on 10.0.83.226:42275 (size: 27.9 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,715 INFO spark.SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,716 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 150 (MapPartitionsRDD[594] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,716 INFO cluster.YarnScheduler: Adding task set 150.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,717 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 150.0 (TID 117) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,725 INFO storage.BlockManagerInfo: Added broadcast_119_piece0 in memory on algo-1:41051 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,738 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 150.0 (TID 117) in 21 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,738 INFO cluster.YarnScheduler: Removed TaskSet 150.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,739 INFO scheduler.DAGScheduler: ShuffleMapStage 150 (collect at AnalysisRunner.scala:326) finished in 0.027 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,741 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,742 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,742 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,742 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,781 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,782 INFO scheduler.DAGScheduler: Got job 102 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,782 INFO scheduler.DAGScheduler: Final stage: ResultStage 152 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,782 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 151)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,782 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,783 INFO scheduler.DAGScheduler: Submitting ResultStage 152 (MapPartitionsRDD[597] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,784 INFO memory.MemoryStore: Block broadcast_120 stored as values in memory (estimated size 66.2 KiB, free 1456.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,786 INFO memory.MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1456.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,786 INFO storage.BlockManagerInfo: Added broadcast_120_piece0 in memory on 10.0.83.226:42275 (size: 19.2 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,787 INFO spark.SparkContext: Created broadcast 120 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,787 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 152 (MapPartitionsRDD[597] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,787 INFO cluster.YarnScheduler: Adding task set 152.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,788 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 152.0 (TID 118) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,795 INFO storage.BlockManagerInfo: Added broadcast_120_piece0 in memory on algo-1:41051 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,800 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 49 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,809 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 152.0 (TID 118) in 21 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,809 INFO cluster.YarnScheduler: Removed TaskSet 152.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,810 INFO scheduler.DAGScheduler: ResultStage 152 (collect at AnalysisRunner.scala:326) finished in 0.027 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,810 INFO scheduler.DAGScheduler: Job 102 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,810 INFO cluster.YarnScheduler: Killing all running tasks in stage 152: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,810 INFO scheduler.DAGScheduler: Job 102 finished: collect at AnalysisRunner.scala:326, took 0.028944 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,858 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,859 INFO scheduler.DAGScheduler: Registering RDD 605 (countByKey at ColumnProfiler.scala:592) as input to shuffle 50\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,859 INFO scheduler.DAGScheduler: Got job 103 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,860 INFO scheduler.DAGScheduler: Final stage: ResultStage 154 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,860 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 153)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,860 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 153)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,861 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 153 (MapPartitionsRDD[605] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,864 INFO memory.MemoryStore: Block broadcast_121 stored as values in memory (estimated size 47.1 KiB, free 1456.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,865 INFO memory.MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 1456.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,866 INFO storage.BlockManagerInfo: Added broadcast_121_piece0 in memory on 10.0.83.226:42275 (size: 18.8 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,866 INFO spark.SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,867 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 153 (MapPartitionsRDD[605] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,867 INFO cluster.YarnScheduler: Adding task set 153.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,868 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 153.0 (TID 119) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,874 INFO storage.BlockManagerInfo: Added broadcast_121_piece0 in memory on algo-1:41051 (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,901 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 153.0 (TID 119) in 33 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,901 INFO cluster.YarnScheduler: Removed TaskSet 153.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,902 INFO scheduler.DAGScheduler: ShuffleMapStage 153 (countByKey at ColumnProfiler.scala:592) finished in 0.041 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,902 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,902 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,903 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 154)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,903 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,903 INFO scheduler.DAGScheduler: Submitting ResultStage 154 (ShuffledRDD[606] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,904 INFO memory.MemoryStore: Block broadcast_122 stored as values in memory (estimated size 5.1 KiB, free 1456.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,906 INFO memory.MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1456.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,906 INFO storage.BlockManagerInfo: Added broadcast_122_piece0 in memory on 10.0.83.226:42275 (size: 3.0 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,906 INFO spark.SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,907 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 154 (ShuffledRDD[606] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,907 INFO cluster.YarnScheduler: Adding task set 154.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,908 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 154.0 (TID 120) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,917 INFO storage.BlockManagerInfo: Added broadcast_122_piece0 in memory on algo-1:41051 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,921 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 50 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,930 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 154.0 (TID 120) in 22 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,930 INFO cluster.YarnScheduler: Removed TaskSet 154.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,931 INFO scheduler.DAGScheduler: ResultStage 154 (countByKey at ColumnProfiler.scala:592) finished in 0.026 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,931 INFO scheduler.DAGScheduler: Job 103 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,931 INFO cluster.YarnScheduler: Killing all running tasks in stage 154: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:54,931 INFO scheduler.DAGScheduler: Job 103 finished: countByKey at ColumnProfiler.scala:592, took 0.072769 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,013 INFO scheduler.DAGScheduler: Registering RDD 611 (collect at AnalysisRunner.scala:326) as input to shuffle 51\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,013 INFO scheduler.DAGScheduler: Got map stage job 104 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,014 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 155 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,014 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,014 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,014 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 155 (MapPartitionsRDD[611] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,019 INFO memory.MemoryStore: Block broadcast_123 stored as values in memory (estimated size 100.0 KiB, free 1456.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,020 INFO memory.MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1456.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,021 INFO storage.BlockManagerInfo: Added broadcast_123_piece0 in memory on 10.0.83.226:42275 (size: 32.9 KiB, free: 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,021 INFO spark.SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,022 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 155 (MapPartitionsRDD[611] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,022 INFO cluster.YarnScheduler: Adding task set 155.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,023 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 155.0 (TID 121) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,030 INFO storage.BlockManagerInfo: Added broadcast_123_piece0 in memory on algo-1:41051 (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,111 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 155.0 (TID 121) in 88 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,111 INFO cluster.YarnScheduler: Removed TaskSet 155.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,112 INFO scheduler.DAGScheduler: ShuffleMapStage 155 (collect at AnalysisRunner.scala:326) finished in 0.097 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,112 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,112 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,113 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,113 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,146 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,147 INFO scheduler.DAGScheduler: Got job 105 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,147 INFO scheduler.DAGScheduler: Final stage: ResultStage 157 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,147 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 156)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,148 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,148 INFO scheduler.DAGScheduler: Submitting ResultStage 157 (MapPartitionsRDD[614] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,154 INFO memory.MemoryStore: Block broadcast_124 stored as values in memory (estimated size 184.6 KiB, free 1455.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,156 INFO memory.MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1455.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,157 INFO storage.BlockManagerInfo: Added broadcast_124_piece0 in memory on 10.0.83.226:42275 (size: 50.3 KiB, free: 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,157 INFO spark.SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,158 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 157 (MapPartitionsRDD[614] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,158 INFO cluster.YarnScheduler: Adding task set 157.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,159 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 157.0 (TID 122) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,167 INFO storage.BlockManagerInfo: Added broadcast_124_piece0 in memory on algo-1:41051 (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,184 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 51 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,278 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 157.0 (TID 122) in 119 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,278 INFO cluster.YarnScheduler: Removed TaskSet 157.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,279 INFO scheduler.DAGScheduler: ResultStage 157 (collect at AnalysisRunner.scala:326) finished in 0.130 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,279 INFO scheduler.DAGScheduler: Job 105 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,280 INFO cluster.YarnScheduler: Killing all running tasks in stage 157: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,280 INFO scheduler.DAGScheduler: Job 105 finished: collect at AnalysisRunner.scala:326, took 0.133375 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,397 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,398 INFO scheduler.DAGScheduler: Got job 106 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,399 INFO scheduler.DAGScheduler: Final stage: ResultStage 158 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,399 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,400 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,400 INFO scheduler.DAGScheduler: Submitting ResultStage 158 (MapPartitionsRDD[624] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,406 INFO memory.MemoryStore: Block broadcast_125 stored as values in memory (estimated size 54.8 KiB, free 1455.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,408 INFO memory.MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1455.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,408 INFO storage.BlockManagerInfo: Added broadcast_125_piece0 in memory on 10.0.83.226:42275 (size: 20.7 KiB, free: 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,409 INFO spark.SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,409 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 158 (MapPartitionsRDD[624] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,409 INFO cluster.YarnScheduler: Adding task set 158.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,411 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 158.0 (TID 123) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,422 INFO storage.BlockManagerInfo: Added broadcast_125_piece0 in memory on algo-1:41051 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,442 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 158.0 (TID 123) in 31 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,445 INFO cluster.YarnScheduler: Removed TaskSet 158.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,446 INFO scheduler.DAGScheduler: ResultStage 158 (treeReduce at KLLRunner.scala:107) finished in 0.045 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,447 INFO scheduler.DAGScheduler: Job 106 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,447 INFO cluster.YarnScheduler: Killing all running tasks in stage 158: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,447 INFO scheduler.DAGScheduler: Job 106 finished: treeReduce at KLLRunner.scala:107, took 0.049213 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,568 INFO storage.BlockManagerInfo: Removed broadcast_117_piece0 on 10.0.83.226:42275 in memory (size: 50.3 KiB, free: 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,569 INFO storage.BlockManagerInfo: Removed broadcast_117_piece0 on algo-1:41051 in memory (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,574 INFO storage.BlockManagerInfo: Removed broadcast_114_piece0 on 10.0.83.226:42275 in memory (size: 18.8 KiB, free: 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,574 INFO storage.BlockManagerInfo: Removed broadcast_114_piece0 on algo-1:41051 in memory (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,578 INFO storage.BlockManagerInfo: Removed broadcast_113_piece0 on 10.0.83.226:42275 in memory (size: 19.2 KiB, free: 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,579 INFO storage.BlockManagerInfo: Removed broadcast_113_piece0 on algo-1:41051 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,581 INFO storage.BlockManagerInfo: Removed broadcast_112_piece0 on 10.0.83.226:42275 in memory (size: 27.9 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,583 INFO storage.BlockManagerInfo: Removed broadcast_112_piece0 on algo-1:41051 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,590 INFO storage.BlockManagerInfo: Removed broadcast_122_piece0 on 10.0.83.226:42275 in memory (size: 3.0 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,591 INFO storage.BlockManagerInfo: Removed broadcast_122_piece0 on algo-1:41051 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,597 INFO storage.BlockManagerInfo: Removed broadcast_124_piece0 on 10.0.83.226:42275 in memory (size: 50.3 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,598 INFO storage.BlockManagerInfo: Removed broadcast_124_piece0 on algo-1:41051 in memory (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,601 INFO storage.BlockManagerInfo: Removed broadcast_111_piece0 on 10.0.83.226:42275 in memory (size: 20.7 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,602 INFO storage.BlockManagerInfo: Removed broadcast_111_piece0 on algo-1:41051 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,607 INFO storage.BlockManagerInfo: Removed broadcast_110_piece0 on 10.0.83.226:42275 in memory (size: 50.3 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,608 INFO storage.BlockManagerInfo: Removed broadcast_110_piece0 on algo-1:41051 in memory (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,613 INFO storage.BlockManagerInfo: Removed broadcast_108_piece0 on 10.0.83.226:42275 in memory (size: 3.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,614 INFO storage.BlockManagerInfo: Removed broadcast_108_piece0 on algo-1:41051 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,619 INFO storage.BlockManagerInfo: Removed broadcast_116_piece0 on 10.0.83.226:42275 in memory (size: 32.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,620 INFO storage.BlockManagerInfo: Removed broadcast_116_piece0 on algo-1:41051 in memory (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,622 INFO storage.BlockManagerInfo: Removed broadcast_125_piece0 on algo-1:41051 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,622 INFO storage.BlockManagerInfo: Removed broadcast_125_piece0 on 10.0.83.226:42275 in memory (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,625 INFO storage.BlockManagerInfo: Removed broadcast_118_piece0 on algo-1:41051 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,625 INFO storage.BlockManagerInfo: Removed broadcast_118_piece0 on 10.0.83.226:42275 in memory (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,629 INFO storage.BlockManagerInfo: Removed broadcast_115_piece0 on 10.0.83.226:42275 in memory (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,630 INFO storage.BlockManagerInfo: Removed broadcast_115_piece0 on algo-1:41051 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,632 INFO storage.BlockManagerInfo: Removed broadcast_119_piece0 on algo-1:41051 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,632 INFO storage.BlockManagerInfo: Removed broadcast_119_piece0 on 10.0.83.226:42275 in memory (size: 27.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,635 INFO storage.BlockManagerInfo: Removed broadcast_121_piece0 on 10.0.83.226:42275 in memory (size: 18.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,636 INFO storage.BlockManagerInfo: Removed broadcast_121_piece0 on algo-1:41051 in memory (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,638 INFO storage.BlockManagerInfo: Removed broadcast_123_piece0 on 10.0.83.226:42275 in memory (size: 32.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,639 INFO storage.BlockManagerInfo: Removed broadcast_123_piece0 on algo-1:41051 in memory (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,653 INFO storage.BlockManagerInfo: Removed broadcast_109_piece0 on 10.0.83.226:42275 in memory (size: 32.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,661 INFO storage.BlockManagerInfo: Removed broadcast_109_piece0 on algo-1:41051 in memory (size: 32.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,666 INFO storage.BlockManagerInfo: Removed broadcast_120_piece0 on 10.0.83.226:42275 in memory (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,677 INFO storage.BlockManagerInfo: Removed broadcast_120_piece0 on algo-1:41051 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,682 INFO storage.BlockManagerInfo: Removed broadcast_107_piece0 on 10.0.83.226:42275 in memory (size: 18.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,683 INFO storage.BlockManagerInfo: Removed broadcast_107_piece0 on algo-1:41051 in memory (size: 18.8 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,704 INFO scheduler.DAGScheduler: Registering RDD 629 (collect at AnalysisRunner.scala:326) as input to shuffle 52\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,704 INFO scheduler.DAGScheduler: Got map stage job 107 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,704 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 159 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,704 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,705 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,705 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 159 (MapPartitionsRDD[629] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,707 INFO memory.MemoryStore: Block broadcast_126 stored as values in memory (estimated size 90.7 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,709 INFO memory.MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,709 INFO storage.BlockManagerInfo: Added broadcast_126_piece0 in memory on 10.0.83.226:42275 (size: 27.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,709 INFO spark.SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,710 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 159 (MapPartitionsRDD[629] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,710 INFO cluster.YarnScheduler: Adding task set 159.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,711 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 159.0 (TID 124) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,723 INFO storage.BlockManagerInfo: Added broadcast_126_piece0 in memory on algo-1:41051 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,732 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 159.0 (TID 124) in 21 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,733 INFO cluster.YarnScheduler: Removed TaskSet 159.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,736 INFO scheduler.DAGScheduler: ShuffleMapStage 159 (collect at AnalysisRunner.scala:326) finished in 0.031 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,736 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,736 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,736 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,736 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,778 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,779 INFO scheduler.DAGScheduler: Got job 108 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,780 INFO scheduler.DAGScheduler: Final stage: ResultStage 161 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,780 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 160)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,780 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,780 INFO scheduler.DAGScheduler: Submitting ResultStage 161 (MapPartitionsRDD[632] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,783 INFO memory.MemoryStore: Block broadcast_127 stored as values in memory (estimated size 66.2 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,784 INFO memory.MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,785 INFO storage.BlockManagerInfo: Added broadcast_127_piece0 in memory on 10.0.83.226:42275 (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,785 INFO spark.SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,786 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 161 (MapPartitionsRDD[632] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,786 INFO cluster.YarnScheduler: Adding task set 161.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,787 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 161.0 (TID 125) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,796 INFO storage.BlockManagerInfo: Added broadcast_127_piece0 in memory on algo-1:41051 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,800 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 52 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,806 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 161.0 (TID 125) in 19 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,806 INFO cluster.YarnScheduler: Removed TaskSet 161.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,807 INFO scheduler.DAGScheduler: ResultStage 161 (collect at AnalysisRunner.scala:326) finished in 0.026 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,809 INFO scheduler.DAGScheduler: Job 108 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,809 INFO cluster.YarnScheduler: Killing all running tasks in stage 161: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,811 INFO scheduler.DAGScheduler: Job 108 finished: collect at AnalysisRunner.scala:326, took 0.032487 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,855 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,856 INFO scheduler.DAGScheduler: Registering RDD 640 (countByKey at ColumnProfiler.scala:592) as input to shuffle 53\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,857 INFO scheduler.DAGScheduler: Got job 109 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,857 INFO scheduler.DAGScheduler: Final stage: ResultStage 163 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,857 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 162)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,857 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 162)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,858 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 162 (MapPartitionsRDD[640] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,866 INFO memory.MemoryStore: Block broadcast_128 stored as values in memory (estimated size 47.1 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,868 INFO memory.MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,868 INFO storage.BlockManagerInfo: Added broadcast_128_piece0 in memory on 10.0.83.226:42275 (size: 18.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,868 INFO spark.SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,869 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 162 (MapPartitionsRDD[640] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,869 INFO cluster.YarnScheduler: Adding task set 162.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,870 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 162.0 (TID 126) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,882 INFO storage.BlockManagerInfo: Added broadcast_128_piece0 in memory on algo-1:41051 (size: 18.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,902 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 162.0 (TID 126) in 32 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,902 INFO cluster.YarnScheduler: Removed TaskSet 162.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,903 INFO scheduler.DAGScheduler: ShuffleMapStage 162 (countByKey at ColumnProfiler.scala:592) finished in 0.044 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,904 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,904 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,904 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 163)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,904 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,905 INFO scheduler.DAGScheduler: Submitting ResultStage 163 (ShuffledRDD[641] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,907 INFO memory.MemoryStore: Block broadcast_129 stored as values in memory (estimated size 5.1 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,909 INFO memory.MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,909 INFO storage.BlockManagerInfo: Added broadcast_129_piece0 in memory on 10.0.83.226:42275 (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,910 INFO spark.SparkContext: Created broadcast 129 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,911 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 163 (ShuffledRDD[641] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,914 INFO cluster.YarnScheduler: Adding task set 163.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,915 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 163.0 (TID 127) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,932 INFO storage.BlockManagerInfo: Added broadcast_129_piece0 in memory on algo-1:41051 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,937 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 53 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,960 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 163.0 (TID 127) in 45 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,961 INFO cluster.YarnScheduler: Removed TaskSet 163.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,962 INFO scheduler.DAGScheduler: ResultStage 163 (countByKey at ColumnProfiler.scala:592) finished in 0.056 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,963 INFO scheduler.DAGScheduler: Job 109 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,963 INFO cluster.YarnScheduler: Killing all running tasks in stage 163: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:55,963 INFO scheduler.DAGScheduler: Job 109 finished: countByKey at ColumnProfiler.scala:592, took 0.107456 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,220 INFO scheduler.DAGScheduler: Registering RDD 646 (collect at AnalysisRunner.scala:326) as input to shuffle 54\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,220 INFO scheduler.DAGScheduler: Got map stage job 110 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,220 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 164 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,221 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,221 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,222 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 164 (MapPartitionsRDD[646] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,225 INFO memory.MemoryStore: Block broadcast_130 stored as values in memory (estimated size 100.0 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,227 INFO memory.MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 33.0 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,233 INFO storage.BlockManagerInfo: Added broadcast_130_piece0 in memory on 10.0.83.226:42275 (size: 33.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,234 INFO spark.SparkContext: Created broadcast 130 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,234 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 164 (MapPartitionsRDD[646] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,235 INFO cluster.YarnScheduler: Adding task set 164.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,236 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 164.0 (TID 128) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,244 INFO storage.BlockManagerInfo: Added broadcast_130_piece0 in memory on algo-1:41051 (size: 33.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,345 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 164.0 (TID 128) in 109 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,346 INFO cluster.YarnScheduler: Removed TaskSet 164.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,347 INFO scheduler.DAGScheduler: ShuffleMapStage 164 (collect at AnalysisRunner.scala:326) finished in 0.124 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,347 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,348 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,349 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,349 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,382 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,383 INFO scheduler.DAGScheduler: Got job 111 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,383 INFO scheduler.DAGScheduler: Final stage: ResultStage 166 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,384 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 165)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,384 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,384 INFO scheduler.DAGScheduler: Submitting ResultStage 166 (MapPartitionsRDD[649] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,391 INFO memory.MemoryStore: Block broadcast_131 stored as values in memory (estimated size 184.6 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,392 INFO memory.MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,393 INFO storage.BlockManagerInfo: Added broadcast_131_piece0 in memory on 10.0.83.226:42275 (size: 50.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,394 INFO spark.SparkContext: Created broadcast 131 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,394 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 166 (MapPartitionsRDD[649] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,394 INFO cluster.YarnScheduler: Adding task set 166.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,397 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 166.0 (TID 129) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,404 INFO storage.BlockManagerInfo: Added broadcast_131_piece0 in memory on algo-1:41051 (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,414 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 54 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,485 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 166.0 (TID 129) in 87 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,485 INFO cluster.YarnScheduler: Removed TaskSet 166.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,485 INFO scheduler.DAGScheduler: ResultStage 166 (collect at AnalysisRunner.scala:326) finished in 0.100 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,485 INFO scheduler.DAGScheduler: Job 111 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,485 INFO cluster.YarnScheduler: Killing all running tasks in stage 166: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,486 INFO scheduler.DAGScheduler: Job 111 finished: collect at AnalysisRunner.scala:326, took 0.102977 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,598 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,598 INFO scheduler.DAGScheduler: Got job 112 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,598 INFO scheduler.DAGScheduler: Final stage: ResultStage 167 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,598 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,599 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,599 INFO scheduler.DAGScheduler: Submitting ResultStage 167 (MapPartitionsRDD[659] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,611 INFO memory.MemoryStore: Block broadcast_132 stored as values in memory (estimated size 54.8 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,612 INFO memory.MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,613 INFO storage.BlockManagerInfo: Added broadcast_132_piece0 in memory on 10.0.83.226:42275 (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,613 INFO spark.SparkContext: Created broadcast 132 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,614 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 167 (MapPartitionsRDD[659] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,614 INFO cluster.YarnScheduler: Adding task set 167.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,615 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 167.0 (TID 130) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,621 INFO storage.BlockManagerInfo: Added broadcast_132_piece0 in memory on algo-1:41051 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,634 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 167.0 (TID 130) in 19 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,634 INFO cluster.YarnScheduler: Removed TaskSet 167.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,635 INFO scheduler.DAGScheduler: ResultStage 167 (treeReduce at KLLRunner.scala:107) finished in 0.035 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,635 INFO scheduler.DAGScheduler: Job 112 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,635 INFO cluster.YarnScheduler: Killing all running tasks in stage 167: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,635 INFO scheduler.DAGScheduler: Job 112 finished: treeReduce at KLLRunner.scala:107, took 0.037616 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,728 INFO scheduler.DAGScheduler: Registering RDD 664 (collect at AnalysisRunner.scala:326) as input to shuffle 55\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,729 INFO scheduler.DAGScheduler: Got map stage job 113 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,729 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 168 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,729 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,730 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,730 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 168 (MapPartitionsRDD[664] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,733 INFO memory.MemoryStore: Block broadcast_133 stored as values in memory (estimated size 90.7 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,735 INFO memory.MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,735 INFO storage.BlockManagerInfo: Added broadcast_133_piece0 in memory on 10.0.83.226:42275 (size: 27.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,736 INFO spark.SparkContext: Created broadcast 133 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,736 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 168 (MapPartitionsRDD[664] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,736 INFO cluster.YarnScheduler: Adding task set 168.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,737 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 168.0 (TID 131) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,744 INFO storage.BlockManagerInfo: Added broadcast_133_piece0 in memory on algo-1:41051 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,755 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 168.0 (TID 131) in 18 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,756 INFO scheduler.DAGScheduler: ShuffleMapStage 168 (collect at AnalysisRunner.scala:326) finished in 0.025 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,756 INFO cluster.YarnScheduler: Removed TaskSet 168.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,756 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,757 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,757 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,757 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,796 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,797 INFO scheduler.DAGScheduler: Got job 114 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,797 INFO scheduler.DAGScheduler: Final stage: ResultStage 170 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,797 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 169)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,797 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,798 INFO scheduler.DAGScheduler: Submitting ResultStage 170 (MapPartitionsRDD[667] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,799 INFO memory.MemoryStore: Block broadcast_134 stored as values in memory (estimated size 66.2 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,801 INFO memory.MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,801 INFO storage.BlockManagerInfo: Added broadcast_134_piece0 in memory on 10.0.83.226:42275 (size: 19.2 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,801 INFO spark.SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,802 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 170 (MapPartitionsRDD[667] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,802 INFO cluster.YarnScheduler: Adding task set 170.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,803 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 170.0 (TID 132) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,810 INFO storage.BlockManagerInfo: Added broadcast_134_piece0 in memory on algo-1:41051 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,814 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 55 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,819 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 170.0 (TID 132) in 16 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,819 INFO scheduler.DAGScheduler: ResultStage 170 (collect at AnalysisRunner.scala:326) finished in 0.021 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,819 INFO cluster.YarnScheduler: Removed TaskSet 170.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,819 INFO scheduler.DAGScheduler: Job 114 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,820 INFO cluster.YarnScheduler: Killing all running tasks in stage 170: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,820 INFO scheduler.DAGScheduler: Job 114 finished: collect at AnalysisRunner.scala:326, took 0.023127 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,863 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,864 INFO scheduler.DAGScheduler: Registering RDD 675 (countByKey at ColumnProfiler.scala:592) as input to shuffle 56\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,865 INFO scheduler.DAGScheduler: Got job 115 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,865 INFO scheduler.DAGScheduler: Final stage: ResultStage 172 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,865 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 171)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,865 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 171)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,865 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 171 (MapPartitionsRDD[675] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,868 INFO memory.MemoryStore: Block broadcast_135 stored as values in memory (estimated size 47.1 KiB, free 1456.8 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,869 INFO memory.MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 1456.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,870 INFO storage.BlockManagerInfo: Added broadcast_135_piece0 in memory on 10.0.83.226:42275 (size: 18.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,870 INFO spark.SparkContext: Created broadcast 135 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,870 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 171 (MapPartitionsRDD[675] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,870 INFO cluster.YarnScheduler: Adding task set 171.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,871 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 171.0 (TID 133) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,883 INFO storage.BlockManagerInfo: Added broadcast_135_piece0 in memory on algo-1:41051 (size: 18.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,897 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 171.0 (TID 133) in 26 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,897 INFO cluster.YarnScheduler: Removed TaskSet 171.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,897 INFO scheduler.DAGScheduler: ShuffleMapStage 171 (countByKey at ColumnProfiler.scala:592) finished in 0.031 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,897 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,897 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,898 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 172)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,898 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,898 INFO scheduler.DAGScheduler: Submitting ResultStage 172 (ShuffledRDD[676] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,900 INFO memory.MemoryStore: Block broadcast_136 stored as values in memory (estimated size 5.1 KiB, free 1456.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,901 INFO memory.MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1456.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,901 INFO storage.BlockManagerInfo: Added broadcast_136_piece0 in memory on 10.0.83.226:42275 (size: 3.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,901 INFO spark.SparkContext: Created broadcast 136 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,902 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 172 (ShuffledRDD[676] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,902 INFO cluster.YarnScheduler: Adding task set 172.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,902 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 172.0 (TID 134) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,908 INFO storage.BlockManagerInfo: Added broadcast_136_piece0 in memory on algo-1:41051 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,911 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 56 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,923 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 172.0 (TID 134) in 21 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,923 INFO cluster.YarnScheduler: Removed TaskSet 172.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,924 INFO scheduler.DAGScheduler: ResultStage 172 (countByKey at ColumnProfiler.scala:592) finished in 0.025 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,925 INFO scheduler.DAGScheduler: Job 115 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,925 INFO cluster.YarnScheduler: Killing all running tasks in stage 172: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,925 INFO scheduler.DAGScheduler: Job 115 finished: countByKey at ColumnProfiler.scala:592, took 0.061141 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,994 INFO scheduler.DAGScheduler: Registering RDD 681 (collect at AnalysisRunner.scala:326) as input to shuffle 57\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,994 INFO scheduler.DAGScheduler: Got map stage job 116 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,994 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 173 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,994 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,994 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:56,995 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 173 (MapPartitionsRDD[681] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,003 INFO memory.MemoryStore: Block broadcast_137 stored as values in memory (estimated size 100.0 KiB, free 1456.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,004 INFO memory.MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 32.9 KiB, free 1456.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,005 INFO storage.BlockManagerInfo: Added broadcast_137_piece0 in memory on 10.0.83.226:42275 (size: 32.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,006 INFO spark.SparkContext: Created broadcast 137 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,006 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 173 (MapPartitionsRDD[681] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,006 INFO cluster.YarnScheduler: Adding task set 173.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,007 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 173.0 (TID 135) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,016 INFO storage.BlockManagerInfo: Added broadcast_137_piece0 in memory on algo-1:41051 (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,102 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 173.0 (TID 135) in 95 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,102 INFO cluster.YarnScheduler: Removed TaskSet 173.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,103 INFO scheduler.DAGScheduler: ShuffleMapStage 173 (collect at AnalysisRunner.scala:326) finished in 0.107 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,103 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,103 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,103 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,104 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,140 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,141 INFO scheduler.DAGScheduler: Got job 117 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,141 INFO scheduler.DAGScheduler: Final stage: ResultStage 175 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,141 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 174)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,141 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,142 INFO scheduler.DAGScheduler: Submitting ResultStage 175 (MapPartitionsRDD[684] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,148 INFO memory.MemoryStore: Block broadcast_138 stored as values in memory (estimated size 184.6 KiB, free 1456.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,150 INFO memory.MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 50.2 KiB, free 1456.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,150 INFO storage.BlockManagerInfo: Added broadcast_138_piece0 in memory on 10.0.83.226:42275 (size: 50.2 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,150 INFO spark.SparkContext: Created broadcast 138 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,150 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 175 (MapPartitionsRDD[684] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,150 INFO cluster.YarnScheduler: Adding task set 175.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,152 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 175.0 (TID 136) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,157 INFO storage.BlockManagerInfo: Added broadcast_138_piece0 in memory on algo-1:41051 (size: 50.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,168 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 57 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,276 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 175.0 (TID 136) in 125 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,277 INFO cluster.YarnScheduler: Removed TaskSet 175.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,277 INFO scheduler.DAGScheduler: ResultStage 175 (collect at AnalysisRunner.scala:326) finished in 0.135 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,278 INFO scheduler.DAGScheduler: Job 117 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,279 INFO cluster.YarnScheduler: Killing all running tasks in stage 175: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,279 INFO scheduler.DAGScheduler: Job 117 finished: collect at AnalysisRunner.scala:326, took 0.138944 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,445 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,447 INFO scheduler.DAGScheduler: Got job 118 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,448 INFO scheduler.DAGScheduler: Final stage: ResultStage 176 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,448 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,454 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,454 INFO scheduler.DAGScheduler: Submitting ResultStage 176 (MapPartitionsRDD[694] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,464 INFO memory.MemoryStore: Block broadcast_139 stored as values in memory (estimated size 54.8 KiB, free 1456.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,467 INFO memory.MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 1456.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,468 INFO storage.BlockManagerInfo: Added broadcast_139_piece0 in memory on 10.0.83.226:42275 (size: 20.7 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,468 INFO spark.SparkContext: Created broadcast 139 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,469 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 176 (MapPartitionsRDD[694] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,469 INFO cluster.YarnScheduler: Adding task set 176.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,470 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 176.0 (TID 137) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,478 INFO storage.BlockManagerInfo: Added broadcast_139_piece0 in memory on algo-1:41051 (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,498 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 176.0 (TID 137) in 28 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,498 INFO cluster.YarnScheduler: Removed TaskSet 176.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,498 INFO scheduler.DAGScheduler: ResultStage 176 (treeReduce at KLLRunner.scala:107) finished in 0.043 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,501 INFO scheduler.DAGScheduler: Job 118 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,501 INFO cluster.YarnScheduler: Killing all running tasks in stage 176: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,502 INFO scheduler.DAGScheduler: Job 118 finished: treeReduce at KLLRunner.scala:107, took 0.056902 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,666 INFO scheduler.DAGScheduler: Registering RDD 699 (collect at AnalysisRunner.scala:326) as input to shuffle 58\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,666 INFO scheduler.DAGScheduler: Got map stage job 119 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,667 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 177 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,667 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,667 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,668 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 177 (MapPartitionsRDD[699] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,671 INFO memory.MemoryStore: Block broadcast_140 stored as values in memory (estimated size 90.7 KiB, free 1456.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,673 INFO memory.MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 1456.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,673 INFO storage.BlockManagerInfo: Added broadcast_140_piece0 in memory on 10.0.83.226:42275 (size: 27.9 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,674 INFO spark.SparkContext: Created broadcast 140 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,674 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 177 (MapPartitionsRDD[699] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,674 INFO cluster.YarnScheduler: Adding task set 177.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,675 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 177.0 (TID 138) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,680 INFO storage.BlockManagerInfo: Added broadcast_140_piece0 in memory on algo-1:41051 (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,691 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 177.0 (TID 138) in 16 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,691 INFO cluster.YarnScheduler: Removed TaskSet 177.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,692 INFO scheduler.DAGScheduler: ShuffleMapStage 177 (collect at AnalysisRunner.scala:326) finished in 0.023 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,692 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,693 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,693 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,693 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,730 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,731 INFO scheduler.DAGScheduler: Got job 120 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,731 INFO scheduler.DAGScheduler: Final stage: ResultStage 179 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,731 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 178)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,731 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,732 INFO scheduler.DAGScheduler: Submitting ResultStage 179 (MapPartitionsRDD[702] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,733 INFO memory.MemoryStore: Block broadcast_141 stored as values in memory (estimated size 66.2 KiB, free 1456.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,734 INFO memory.MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1456.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,735 INFO storage.BlockManagerInfo: Added broadcast_141_piece0 in memory on 10.0.83.226:42275 (size: 19.2 KiB, free: 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,735 INFO spark.SparkContext: Created broadcast 141 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,735 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 179 (MapPartitionsRDD[702] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,735 INFO cluster.YarnScheduler: Adding task set 179.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,736 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 179.0 (TID 139) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,741 INFO storage.BlockManagerInfo: Added broadcast_141_piece0 in memory on algo-1:41051 (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,743 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 58 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,748 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 179.0 (TID 139) in 12 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,748 INFO cluster.YarnScheduler: Removed TaskSet 179.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,750 INFO scheduler.DAGScheduler: ResultStage 179 (collect at AnalysisRunner.scala:326) finished in 0.018 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,750 INFO scheduler.DAGScheduler: Job 120 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,750 INFO cluster.YarnScheduler: Killing all running tasks in stage 179: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,750 INFO scheduler.DAGScheduler: Job 120 finished: collect at AnalysisRunner.scala:326, took 0.019922 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,802 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,803 INFO scheduler.DAGScheduler: Registering RDD 710 (countByKey at ColumnProfiler.scala:592) as input to shuffle 59\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,803 INFO scheduler.DAGScheduler: Got job 121 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,803 INFO scheduler.DAGScheduler: Final stage: ResultStage 181 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,803 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 180)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,804 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 180)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,805 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 180 (MapPartitionsRDD[710] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,810 INFO memory.MemoryStore: Block broadcast_142 stored as values in memory (estimated size 47.1 KiB, free 1456.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,811 INFO memory.MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 1456.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,811 INFO storage.BlockManagerInfo: Added broadcast_142_piece0 in memory on 10.0.83.226:42275 (size: 18.9 KiB, free: 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,812 INFO spark.SparkContext: Created broadcast 142 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,812 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 180 (MapPartitionsRDD[710] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,812 INFO cluster.YarnScheduler: Adding task set 180.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,813 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 180.0 (TID 140) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,818 INFO storage.BlockManagerInfo: Added broadcast_142_piece0 in memory on algo-1:41051 (size: 18.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,834 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 180.0 (TID 140) in 21 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,834 INFO cluster.YarnScheduler: Removed TaskSet 180.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,835 INFO scheduler.DAGScheduler: ShuffleMapStage 180 (countByKey at ColumnProfiler.scala:592) finished in 0.030 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,835 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,836 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,836 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 181)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,836 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,837 INFO scheduler.DAGScheduler: Submitting ResultStage 181 (ShuffledRDD[711] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,838 INFO memory.MemoryStore: Block broadcast_143 stored as values in memory (estimated size 5.1 KiB, free 1456.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,842 INFO memory.MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1456.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,842 INFO storage.BlockManagerInfo: Added broadcast_143_piece0 in memory on 10.0.83.226:42275 (size: 3.0 KiB, free: 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,843 INFO spark.SparkContext: Created broadcast 143 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,843 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 181 (ShuffledRDD[711] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,844 INFO cluster.YarnScheduler: Adding task set 181.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,845 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 181.0 (TID 141) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,851 INFO storage.BlockManagerInfo: Added broadcast_143_piece0 in memory on algo-1:41051 (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,854 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 59 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,906 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 181.0 (TID 141) in 62 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,909 INFO cluster.YarnScheduler: Removed TaskSet 181.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,911 INFO storage.BlockManagerInfo: Removed broadcast_139_piece0 on 10.0.83.226:42275 in memory (size: 20.7 KiB, free: 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,910 INFO scheduler.DAGScheduler: ResultStage 181 (countByKey at ColumnProfiler.scala:592) finished in 0.073 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,912 INFO scheduler.DAGScheduler: Job 121 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,912 INFO cluster.YarnScheduler: Killing all running tasks in stage 181: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,913 INFO scheduler.DAGScheduler: Job 121 finished: countByKey at ColumnProfiler.scala:592, took 0.110213 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,915 INFO storage.BlockManagerInfo: Removed broadcast_139_piece0 on algo-1:41051 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,917 INFO storage.BlockManagerInfo: Removed broadcast_138_piece0 on 10.0.83.226:42275 in memory (size: 50.2 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,919 INFO storage.BlockManagerInfo: Removed broadcast_138_piece0 on algo-1:41051 in memory (size: 50.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,921 INFO storage.BlockManagerInfo: Removed broadcast_137_piece0 on 10.0.83.226:42275 in memory (size: 32.9 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,922 INFO storage.BlockManagerInfo: Removed broadcast_137_piece0 on algo-1:41051 in memory (size: 32.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,924 INFO storage.BlockManagerInfo: Removed broadcast_135_piece0 on 10.0.83.226:42275 in memory (size: 18.9 KiB, free: 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,925 INFO storage.BlockManagerInfo: Removed broadcast_135_piece0 on algo-1:41051 in memory (size: 18.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,935 INFO storage.BlockManagerInfo: Removed broadcast_133_piece0 on 10.0.83.226:42275 in memory (size: 27.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,936 INFO storage.BlockManagerInfo: Removed broadcast_133_piece0 on algo-1:41051 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,939 INFO storage.BlockManagerInfo: Removed broadcast_142_piece0 on 10.0.83.226:42275 in memory (size: 18.9 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,940 INFO storage.BlockManagerInfo: Removed broadcast_142_piece0 on algo-1:41051 in memory (size: 18.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,945 INFO storage.BlockManagerInfo: Removed broadcast_134_piece0 on algo-1:41051 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,946 INFO storage.BlockManagerInfo: Removed broadcast_134_piece0 on 10.0.83.226:42275 in memory (size: 19.2 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,949 INFO storage.BlockManagerInfo: Removed broadcast_131_piece0 on 10.0.83.226:42275 in memory (size: 50.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,950 INFO storage.BlockManagerInfo: Removed broadcast_131_piece0 on algo-1:41051 in memory (size: 50.3 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,951 INFO storage.BlockManagerInfo: Removed broadcast_128_piece0 on algo-1:41051 in memory (size: 18.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,952 INFO storage.BlockManagerInfo: Removed broadcast_128_piece0 on 10.0.83.226:42275 in memory (size: 18.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,959 INFO storage.BlockManagerInfo: Removed broadcast_141_piece0 on algo-1:41051 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,962 INFO storage.BlockManagerInfo: Removed broadcast_141_piece0 on 10.0.83.226:42275 in memory (size: 19.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,967 INFO storage.BlockManagerInfo: Removed broadcast_140_piece0 on algo-1:41051 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,968 INFO storage.BlockManagerInfo: Removed broadcast_140_piece0 on 10.0.83.226:42275 in memory (size: 27.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,974 INFO storage.BlockManagerInfo: Removed broadcast_132_piece0 on 10.0.83.226:42275 in memory (size: 20.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,974 INFO storage.BlockManagerInfo: Removed broadcast_132_piece0 on algo-1:41051 in memory (size: 20.7 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,977 INFO storage.BlockManagerInfo: Removed broadcast_136_piece0 on 10.0.83.226:42275 in memory (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,977 INFO storage.BlockManagerInfo: Removed broadcast_136_piece0 on algo-1:41051 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,981 INFO storage.BlockManagerInfo: Removed broadcast_130_piece0 on algo-1:41051 in memory (size: 33.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,982 INFO storage.BlockManagerInfo: Removed broadcast_130_piece0 on 10.0.83.226:42275 in memory (size: 33.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,985 INFO storage.BlockManagerInfo: Removed broadcast_129_piece0 on algo-1:41051 in memory (size: 3.0 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,986 INFO storage.BlockManagerInfo: Removed broadcast_129_piece0 on 10.0.83.226:42275 in memory (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,989 INFO storage.BlockManagerInfo: Removed broadcast_126_piece0 on algo-1:41051 in memory (size: 27.9 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,992 INFO storage.BlockManagerInfo: Removed broadcast_126_piece0 on 10.0.83.226:42275 in memory (size: 27.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,993 INFO storage.BlockManagerInfo: Removed broadcast_127_piece0 on algo-1:41051 in memory (size: 19.2 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:57,996 INFO storage.BlockManagerInfo: Removed broadcast_127_piece0 on 10.0.83.226:42275 in memory (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,202 INFO FileUtil: Write to file constraints.json at path /opt/ml/processing/output.\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,245 INFO codegen.CodeGenerator: Code generated in 12.235007 ms\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,250 INFO scheduler.DAGScheduler: Registering RDD 716 (count at StatsGenerator.scala:66) as input to shuffle 60\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,251 INFO scheduler.DAGScheduler: Got map stage job 122 (count at StatsGenerator.scala:66) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,251 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 182 (count at StatsGenerator.scala:66)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,251 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,252 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,252 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 182 (MapPartitionsRDD[716] at count at StatsGenerator.scala:66), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,255 INFO memory.MemoryStore: Block broadcast_144 stored as values in memory (estimated size 39.6 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,256 INFO memory.MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 15.1 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,256 INFO storage.BlockManagerInfo: Added broadcast_144_piece0 in memory on 10.0.83.226:42275 (size: 15.1 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,257 INFO spark.SparkContext: Created broadcast 144 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,257 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 182 (MapPartitionsRDD[716] at count at StatsGenerator.scala:66) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,257 INFO cluster.YarnScheduler: Adding task set 182.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,258 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 182.0 (TID 142) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,266 INFO storage.BlockManagerInfo: Added broadcast_144_piece0 in memory on algo-1:41051 (size: 15.1 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,338 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 182.0 (TID 142) in 80 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,338 INFO cluster.YarnScheduler: Removed TaskSet 182.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,339 INFO scheduler.DAGScheduler: ShuffleMapStage 182 (count at StatsGenerator.scala:66) finished in 0.086 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,339 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,339 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,339 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,339 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,369 INFO codegen.CodeGenerator: Code generated in 23.707721 ms\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,390 INFO spark.SparkContext: Starting job: count at StatsGenerator.scala:66\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,390 INFO scheduler.DAGScheduler: Got job 123 (count at StatsGenerator.scala:66) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,391 INFO scheduler.DAGScheduler: Final stage: ResultStage 184 (count at StatsGenerator.scala:66)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,391 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 183)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,391 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,391 INFO scheduler.DAGScheduler: Submitting ResultStage 184 (MapPartitionsRDD[719] at count at StatsGenerator.scala:66), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,393 INFO memory.MemoryStore: Block broadcast_145 stored as values in memory (estimated size 11.1 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,394 INFO memory.MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,395 INFO storage.BlockManagerInfo: Added broadcast_145_piece0 in memory on 10.0.83.226:42275 (size: 5.5 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,395 INFO spark.SparkContext: Created broadcast 145 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,395 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 184 (MapPartitionsRDD[719] at count at StatsGenerator.scala:66) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,396 INFO cluster.YarnScheduler: Adding task set 184.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,397 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 184.0 (TID 143) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,406 INFO storage.BlockManagerInfo: Added broadcast_145_piece0 in memory on algo-1:41051 (size: 5.5 KiB, free: 2.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,409 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 60 to 10.0.83.226:44946\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,445 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 184.0 (TID 143) in 49 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,445 INFO cluster.YarnScheduler: Removed TaskSet 184.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,446 INFO scheduler.DAGScheduler: ResultStage 184 (count at StatsGenerator.scala:66) finished in 0.054 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,446 INFO scheduler.DAGScheduler: Job 123 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,446 INFO cluster.YarnScheduler: Killing all running tasks in stage 184: Stage finished\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:58,447 INFO scheduler.DAGScheduler: Job 123 finished: count at StatsGenerator.scala:66, took 0.056762 s\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:59,168 INFO FileUtil: Write to file statistics.json at path /opt/ml/processing/output.\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:59,193 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:59,216 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:59,217 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:59,227 INFO cluster.YarnClientSchedulerBackend: YARN client scheduler backend Stopped\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:59,263 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:59,334 INFO memory.MemoryStore: MemoryStore cleared\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:59,335 INFO storage.BlockManager: BlockManager stopped\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:59,339 INFO storage.BlockManagerMaster: BlockManagerMaster stopped\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:59,351 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:59,394 INFO spark.SparkContext: Successfully stopped SparkContext\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:59,395 INFO Main: Completed: Job completed successfully with no violations.\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:59,395 INFO Main: Write to file /opt/ml/output/message.\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:59,416 INFO util.ShutdownHookManager: Shutdown hook called\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:59,417 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-738fa2d0-2e96-49bd-9678-05c51cbd14e8\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:59,428 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-4a4afb9e-4f18-408d-ade4-d435bf4e7abd\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:59,539 - DefaultDataAnalyzer - INFO - Completed spark-submit with return code : 0\u001b[0m\n",
      "\u001b[34m2024-01-25 04:52:59,539 - DefaultDataAnalyzer - INFO - Spark job completed.\u001b[0m\n",
      "\n",
      "CPU times: user 1.14 s, sys: 139 ms, total: 1.28 s\n",
      "Wall time: 7min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "monitor_baseline = my_default_monitor.suggest_baseline(\n",
    "    baseline_dataset=baseline_data_uri,\n",
    "    dataset_format=DatasetFormat.csv(header=False),\n",
    "    output_s3_uri=baseline_results_uri,\n",
    "    job_name=f\"{prefix}-monitor-baseline-{datetime_stamp}\",\n",
    "    wait=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bab252e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "import boto3\n",
    "\n",
    "client = boto3.client(\"sagemaker\")\n",
    "\n",
    "\n",
    "def get_last_processing_job():\n",
    "    response = client.list_processing_jobs(\n",
    "        NameContains=f\"{prefix}-monitor-baseline-{datetime_stamp}\",\n",
    "        StatusEquals=\"Completed\",\n",
    "        SortBy=\"CreationTime\",\n",
    "        SortOrder=\"Descending\",\n",
    "        MaxResults=20,\n",
    "    )\n",
    "    pprint.pprint(response[\"ProcessingJobSummaries\"][0])\n",
    "    return response[\"ProcessingJobSummaries\"][0][\"ProcessingJobName\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f30c0d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CreationTime': datetime.datetime(2024, 1, 25, 4, 46, 9, 564000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2024, 1, 25, 4, 53, 8, 838000, tzinfo=tzlocal()),\n",
      " 'ProcessingEndTime': datetime.datetime(2024, 1, 25, 4, 53, 8, 529000, tzinfo=tzlocal()),\n",
      " 'ProcessingJobArn': 'arn:aws:sagemaker:us-west-2:846634201516:processing-job/customerchurn-monitor-baseline-2024-01-25-044606',\n",
      " 'ProcessingJobName': 'customerchurn-monitor-baseline-2024-01-25-044606',\n",
      " 'ProcessingJobStatus': 'Completed'}\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingJob\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.model_monitor.model_monitoring import ModelMonitor\n",
    "import pprint\n",
    "my_default_monitor_name = get_last_processing_job()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71d92296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AppSpecification': {'ImageUri': '159807026194.dkr.ecr.us-west-2.amazonaws.com/sagemaker-model-monitor-analyzer'},\n",
      " 'CreationTime': datetime.datetime(2024, 1, 25, 4, 46, 9, 564000, tzinfo=tzlocal()),\n",
      " 'Environment': {'dataset_format': '{\"csv\": {\"header\": false, '\n",
      "                                   '\"output_columns_position\": \"START\"}}',\n",
      "                 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input',\n",
      "                 'output_path': '/opt/ml/processing/output',\n",
      "                 'publish_cloudwatch_metrics': 'Disabled'},\n",
      " 'ExitMessage': 'Completed: Job completed successfully with no violations.',\n",
      " 'LastModifiedTime': datetime.datetime(2024, 1, 25, 4, 53, 8, 838000, tzinfo=tzlocal()),\n",
      " 'ProcessingEndTime': datetime.datetime(2024, 1, 25, 4, 53, 8, 529000, tzinfo=tzlocal()),\n",
      " 'ProcessingInputs': [{'AppManaged': False,\n",
      "                       'InputName': 'baseline_dataset_input',\n",
      "                       'S3Input': {'LocalPath': '/opt/ml/processing/input/baseline_dataset_input',\n",
      "                                   'S3CompressionType': 'None',\n",
      "                                   'S3DataDistributionType': 'FullyReplicated',\n",
      "                                   'S3DataType': 'S3Prefix',\n",
      "                                   'S3InputMode': 'File',\n",
      "                                   'S3Uri': 's3://sagemaker-us-west-2-846634201516/ml_deploy/validation'}}],\n",
      " 'ProcessingJobArn': 'arn:aws:sagemaker:us-west-2:846634201516:processing-job/customerchurn-monitor-baseline-2024-01-25-044606',\n",
      " 'ProcessingJobName': 'customerchurn-monitor-baseline-2024-01-25-044606',\n",
      " 'ProcessingJobStatus': 'Completed',\n",
      " 'ProcessingOutputConfig': {'Outputs': [{'AppManaged': False,\n",
      "                                         'OutputName': 'monitoring_output',\n",
      "                                         'S3Output': {'LocalPath': '/opt/ml/processing/output',\n",
      "                                                      'S3UploadMode': 'EndOfJob',\n",
      "                                                      'S3Uri': 's3://sagemaker-us-west-2-846634201516/monitoring/baseline/results'}}]},\n",
      " 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1,\n",
      "                                           'InstanceType': 'ml.m5.large',\n",
      "                                           'VolumeSizeInGB': 20}},\n",
      " 'ProcessingStartTime': datetime.datetime(2024, 1, 25, 4, 50, 49, 299000, tzinfo=tzlocal()),\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '1629',\n",
      "                                      'content-type': 'application/x-amz-json-1.1',\n",
      "                                      'date': 'Thu, 25 Jan 2024 05:00:19 GMT',\n",
      "                                      'x-amzn-requestid': '64f4146e-5177-4a20-83a0-509f5037ff19'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': '64f4146e-5177-4a20-83a0-509f5037ff19',\n",
      "                      'RetryAttempts': 0},\n",
      " 'RoleArn': 'arn:aws:iam::846634201516:role/AmazonMWAA-SageMaker-Role',\n",
      " 'StoppingCondition': {'MaxRuntimeInSeconds': 1800}}\n"
     ]
    }
   ],
   "source": [
    "my_default_monitor_reload = ProcessingJob.from_processing_name(sess, my_default_monitor_name)\n",
    "\n",
    "response = client.describe_processing_job(ProcessingJobName=my_default_monitor_name)\n",
    "pprint.pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "671d701a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>inferred_type</th>\n",
       "      <th>numerical_statistics.common.num_present</th>\n",
       "      <th>numerical_statistics.common.num_missing</th>\n",
       "      <th>numerical_statistics.mean</th>\n",
       "      <th>numerical_statistics.sum</th>\n",
       "      <th>numerical_statistics.std_dev</th>\n",
       "      <th>numerical_statistics.min</th>\n",
       "      <th>numerical_statistics.max</th>\n",
       "      <th>numerical_statistics.distribution.kll.buckets</th>\n",
       "      <th>numerical_statistics.distribution.kll.sketch.parameters.c</th>\n",
       "      <th>numerical_statistics.distribution.kll.sketch.parameters.k</th>\n",
       "      <th>numerical_statistics.distribution.kll.sketch.data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_c0</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1050</td>\n",
       "      <td>0</td>\n",
       "      <td>0.516190</td>\n",
       "      <td>542.000000</td>\n",
       "      <td>0.499738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_c1</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1050</td>\n",
       "      <td>0</td>\n",
       "      <td>102.530476</td>\n",
       "      <td>107657.000000</td>\n",
       "      <td>57.034288</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>[{'lower_bound': 1.0, 'upper_bound': 20.9, 'co...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_c2</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1050</td>\n",
       "      <td>0</td>\n",
       "      <td>229.809524</td>\n",
       "      <td>241300.000000</td>\n",
       "      <td>276.089982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 130.0, 'c...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[0.0, 200.0, 0.0, 0.0, 200.0, 400.0, 0.0, 100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_c3</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1050</td>\n",
       "      <td>0</td>\n",
       "      <td>5.679779</td>\n",
       "      <td>5963.768387</td>\n",
       "      <td>3.340890</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>16.504147</td>\n",
       "      <td>[{'lower_bound': 0.0029108563531714533, 'upper...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[1.0526538076293468, 1.7525156498596337, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_c4</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1050</td>\n",
       "      <td>0</td>\n",
       "      <td>3.501905</td>\n",
       "      <td>3677.000000</td>\n",
       "      <td>1.701119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.9, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[2.0, 5.0, 3.0, 5.0, 4.0, 5.0, 0.0, 6.0, 6.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>_c5</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1050</td>\n",
       "      <td>0</td>\n",
       "      <td>5.039082</td>\n",
       "      <td>5291.035826</td>\n",
       "      <td>2.121572</td>\n",
       "      <td>0.036409</td>\n",
       "      <td>12.133130</td>\n",
       "      <td>[{'lower_bound': 0.03640900288750437, 'upper_b...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[0.6993549113167711, 7.0170936431980255, 5.40...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>_c6</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1050</td>\n",
       "      <td>0</td>\n",
       "      <td>3.107619</td>\n",
       "      <td>3263.000000</td>\n",
       "      <td>2.532990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 1.3, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[2.0, 3.0, 5.0, 7.0, 8.0, 7.0, 3.0, 5.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>_c7</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1050</td>\n",
       "      <td>0</td>\n",
       "      <td>4.123123</td>\n",
       "      <td>4329.278947</td>\n",
       "      <td>1.635218</td>\n",
       "      <td>0.013675</td>\n",
       "      <td>9.193927</td>\n",
       "      <td>[{'lower_bound': 0.0136750570626889, 'upper_bo...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[5.073754840111169, 1.3198145052020855, 3.907...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>_c8</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1050</td>\n",
       "      <td>0</td>\n",
       "      <td>220.666667</td>\n",
       "      <td>231700.000000</td>\n",
       "      <td>96.789085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>550.000000</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 55.0, 'co...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[200.0, 150.0, 400.0, 300.0, 250.0, 300.0, 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>_c9</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1050</td>\n",
       "      <td>0</td>\n",
       "      <td>5.008737</td>\n",
       "      <td>5259.174012</td>\n",
       "      <td>1.009469</td>\n",
       "      <td>1.648514</td>\n",
       "      <td>8.181336</td>\n",
       "      <td>[{'lower_bound': 1.6485135544570038, 'upper_bo...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[5.823936374928548, 5.2857977513777135, 4.111...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name inferred_type  numerical_statistics.common.num_present  \\\n",
       "0  _c0    Fractional                                     1050   \n",
       "1  _c1    Fractional                                     1050   \n",
       "2  _c2    Fractional                                     1050   \n",
       "3  _c3    Fractional                                     1050   \n",
       "4  _c4    Fractional                                     1050   \n",
       "5  _c5    Fractional                                     1050   \n",
       "6  _c6    Fractional                                     1050   \n",
       "7  _c7    Fractional                                     1050   \n",
       "8  _c8    Fractional                                     1050   \n",
       "9  _c9    Fractional                                     1050   \n",
       "\n",
       "   numerical_statistics.common.num_missing  numerical_statistics.mean  \\\n",
       "0                                        0                   0.516190   \n",
       "1                                        0                 102.530476   \n",
       "2                                        0                 229.809524   \n",
       "3                                        0                   5.679779   \n",
       "4                                        0                   3.501905   \n",
       "5                                        0                   5.039082   \n",
       "6                                        0                   3.107619   \n",
       "7                                        0                   4.123123   \n",
       "8                                        0                 220.666667   \n",
       "9                                        0                   5.008737   \n",
       "\n",
       "   numerical_statistics.sum  numerical_statistics.std_dev  \\\n",
       "0                542.000000                      0.499738   \n",
       "1             107657.000000                     57.034288   \n",
       "2             241300.000000                    276.089982   \n",
       "3               5963.768387                      3.340890   \n",
       "4               3677.000000                      1.701119   \n",
       "5               5291.035826                      2.121572   \n",
       "6               3263.000000                      2.532990   \n",
       "7               4329.278947                      1.635218   \n",
       "8             231700.000000                     96.789085   \n",
       "9               5259.174012                      1.009469   \n",
       "\n",
       "   numerical_statistics.min  numerical_statistics.max  \\\n",
       "0                  0.000000                  1.000000   \n",
       "1                  1.000000                200.000000   \n",
       "2                  0.000000               1300.000000   \n",
       "3                  0.002911                 16.504147   \n",
       "4                  0.000000                  9.000000   \n",
       "5                  0.036409                 12.133130   \n",
       "6                  0.000000                 13.000000   \n",
       "7                  0.013675                  9.193927   \n",
       "8                  0.000000                550.000000   \n",
       "9                  1.648514                  8.181336   \n",
       "\n",
       "       numerical_statistics.distribution.kll.buckets  \\\n",
       "0  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "1  [{'lower_bound': 1.0, 'upper_bound': 20.9, 'co...   \n",
       "2  [{'lower_bound': 0.0, 'upper_bound': 130.0, 'c...   \n",
       "3  [{'lower_bound': 0.0029108563531714533, 'upper...   \n",
       "4  [{'lower_bound': 0.0, 'upper_bound': 0.9, 'cou...   \n",
       "5  [{'lower_bound': 0.03640900288750437, 'upper_b...   \n",
       "6  [{'lower_bound': 0.0, 'upper_bound': 1.3, 'cou...   \n",
       "7  [{'lower_bound': 0.0136750570626889, 'upper_bo...   \n",
       "8  [{'lower_bound': 0.0, 'upper_bound': 55.0, 'co...   \n",
       "9  [{'lower_bound': 1.6485135544570038, 'upper_bo...   \n",
       "\n",
       "   numerical_statistics.distribution.kll.sketch.parameters.c  \\\n",
       "0                                               0.64           \n",
       "1                                               0.64           \n",
       "2                                               0.64           \n",
       "3                                               0.64           \n",
       "4                                               0.64           \n",
       "5                                               0.64           \n",
       "6                                               0.64           \n",
       "7                                               0.64           \n",
       "8                                               0.64           \n",
       "9                                               0.64           \n",
       "\n",
       "   numerical_statistics.distribution.kll.sketch.parameters.k  \\\n",
       "0                                             2048.0           \n",
       "1                                             2048.0           \n",
       "2                                             2048.0           \n",
       "3                                             2048.0           \n",
       "4                                             2048.0           \n",
       "5                                             2048.0           \n",
       "6                                             2048.0           \n",
       "7                                             2048.0           \n",
       "8                                             2048.0           \n",
       "9                                             2048.0           \n",
       "\n",
       "   numerical_statistics.distribution.kll.sketch.data  \n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "1  [[1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0,...  \n",
       "2  [[0.0, 200.0, 0.0, 0.0, 200.0, 400.0, 0.0, 100...  \n",
       "3  [[1.0526538076293468, 1.7525156498596337, 0.02...  \n",
       "4  [[2.0, 5.0, 3.0, 5.0, 4.0, 5.0, 0.0, 6.0, 6.0,...  \n",
       "5  [[0.6993549113167711, 7.0170936431980255, 5.40...  \n",
       "6  [[2.0, 3.0, 5.0, 7.0, 8.0, 7.0, 3.0, 5.0, 1.0,...  \n",
       "7  [[5.073754840111169, 1.3198145052020855, 3.907...  \n",
       "8  [[200.0, 150.0, 400.0, 300.0, 250.0, 300.0, 20...  \n",
       "9  [[5.823936374928548, 5.2857977513777135, 4.111...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "baseline_job = my_default_monitor.latest_baselining_job\n",
    "schema_df = pd.json_normalize(baseline_job.baseline_statistics().body_dict[\"features\"])\n",
    "schema_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e027df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>inferred_type</th>\n",
       "      <th>completeness</th>\n",
       "      <th>num_constraints.is_non_negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_c0</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_c1</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_c2</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_c3</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_c4</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>_c5</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>_c6</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>_c7</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>_c8</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>_c9</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name inferred_type  completeness  num_constraints.is_non_negative\n",
       "0  _c0    Fractional           1.0                             True\n",
       "1  _c1    Fractional           1.0                             True\n",
       "2  _c2    Fractional           1.0                             True\n",
       "3  _c3    Fractional           1.0                             True\n",
       "4  _c4    Fractional           1.0                             True\n",
       "5  _c5    Fractional           1.0                             True\n",
       "6  _c6    Fractional           1.0                             True\n",
       "7  _c7    Fractional           1.0                             True\n",
       "8  _c8    Fractional           1.0                             True\n",
       "9  _c9    Fractional           1.0                             True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constraints_df = pd.json_normalize(baseline_job.suggested_constraints().body_dict[\"features\"])\n",
    "constraints_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30424db5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
